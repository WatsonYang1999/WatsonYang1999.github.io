<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

  
  <!-- Mermaid -->
  <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: 'default',
      securityLevel: 'loose',
      themeVariables: {
        primaryColor: '#0f4c75',
        primaryTextColor: '#fff',
        primaryBorderColor: '#0f4c75',
        lineColor: '#0f4c75',
        secondaryColor: '#006ba6',
        tertiaryColor: '#fff'
      }
    });
  </script>
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Mental/First Principle" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/21/Mental/First%20Principle/" class="article-date">
  <time class="dt-published" datetime="2025-07-21T07:14:26.872Z" itemprop="datePublished">2025-07-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>最近接触并研究了一下马斯克所说的第一性原理</p>
<p>简要来说，所谓的first principles是一种从根源上审视项目&#x2F;目标&#x2F;人生&#x2F;或者任何我们关注的事物的一种方法论。</p>
<p>我觉得最关键的地方有两个<br>1.只从你需要拆解的事物的本身出发，而不受任何类比的思维方式的干扰。<br>2.在于分解和分治， 让困难的事情变得可以量化可以操作。</p>
<ol>
<li><p>解释一下为什么要避免类比<br>“600刀的电池真正的成本只需要80刀”</p>
</li>
<li><p>解释一下怎么分解，分治<br>“造火箭只需要27个步骤”</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/21/Mental/First%20Principle/" data-id="cmdpf31a1000nq0ongd76bqno" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-System/vLLM_safetensors模型加载与计算图转换详细分析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/16/System/vLLM_safetensors%E6%A8%A1%E5%9E%8B%E5%8A%A0%E8%BD%BD%E4%B8%8E%E8%AE%A1%E7%AE%97%E5%9B%BE%E8%BD%AC%E6%8D%A2%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2025-07-16T02:11:51.912Z" itemprop="datePublished">2025-07-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="vLLM-Safetensors-模型加载与计算图转换详细分析"><a href="#vLLM-Safetensors-模型加载与计算图转换详细分析" class="headerlink" title="vLLM Safetensors 模型加载与计算图转换详细分析"></a>vLLM Safetensors 模型加载与计算图转换详细分析</h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>vLLM 中 safetensors 模型的加载和计算图转换是一个复杂的多阶段过程，涉及模型发现、权重加载、架构实例化、权重绑定和计算图优化等多个步骤。</p>
<h2 id="2-核心组件架构"><a href="#2-核心组件架构" class="headerlink" title="2. 核心组件架构"></a>2. 核心组件架构</h2><h3 id="2-1-模型加载器层次结构"><a href="#2-1-模型加载器层次结构" class="headerlink" title="2.1 模型加载器层次结构"></a>2.1 模型加载器层次结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">BaseModelLoader (抽象基类)</span><br><span class="line">├── DefaultModelLoader (默认实现)</span><br><span class="line">├── TensorizerLoader (张量器加载器)</span><br><span class="line">├── ShardedStateLoader (分片状态加载器)</span><br><span class="line">├── BitsAndBytesModelLoader (量化模型加载器)</span><br><span class="line">└── GGUFModelLoader (GGUF格式加载器)</span><br></pre></td></tr></table></figure>

<h3 id="2-2-关键文件结构"><a href="#2-2-关键文件结构" class="headerlink" title="2.2 关键文件结构"></a>2.2 关键文件结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vllm/model_executor/model_loader/</span><br><span class="line">├── __init__.py                 # 模型加载器工厂</span><br><span class="line">├── base_loader.py              # 基础加载器抽象类</span><br><span class="line">├── default_loader.py           # 默认加载器实现</span><br><span class="line">├── weight_utils.py             # 权重工具函数</span><br><span class="line">├── utils.py                    # 模型初始化工具</span><br><span class="line">└── registry.py                 # 模型注册表</span><br></pre></td></tr></table></figure>

<h2 id="3-详细流程分析"><a href="#3-详细流程分析" class="headerlink" title="3. 详细流程分析"></a>3. 详细流程分析</h2><h3 id="3-1-模型加载器选择"><a href="#3-1-模型加载器选择" class="headerlink" title="3.1 模型加载器选择"></a>3.1 模型加载器选择</h3><p>在 <code>__init__.py</code> 中的 <code>get_model_loader()</code> 函数负责根据 <code>LoadConfig</code> 选择合适的加载器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_model_loader</span>(<span class="params">load_config: LoadConfig</span>) -&gt; BaseModelLoader:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;根据加载格式选择模型加载器&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> load_config.load_format == LoadFormat.SAFETENSORS:</span><br><span class="line">        <span class="keyword">return</span> DefaultModelLoader(load_config)</span><br><span class="line">    <span class="keyword">elif</span> load_config.load_format == LoadFormat.FASTSAFETENSORS:</span><br><span class="line">        <span class="keyword">return</span> DefaultModelLoader(load_config)</span><br><span class="line">    <span class="comment"># ... 其他格式</span></span><br><span class="line">    <span class="keyword">return</span> DefaultModelLoader(load_config)  <span class="comment"># 默认加载器</span></span><br></pre></td></tr></table></figure>

<h3 id="3-2-模型架构识别"><a href="#3-2-模型架构识别" class="headerlink" title="3.2 模型架构识别"></a>3.2 模型架构识别</h3><p>通过 <code>ModelRegistry</code> 根据 HuggingFace 配置识别模型架构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在 registry.py 中</span></span><br><span class="line">_TEXT_GENERATION_MODELS = &#123;</span><br><span class="line">    <span class="string">&quot;LlamaForCausalLM&quot;</span>: (<span class="string">&quot;llama&quot;</span>, <span class="string">&quot;LlamaForCausalLM&quot;</span>),</span><br><span class="line">    <span class="string">&quot;MistralForCausalLM&quot;</span>: (<span class="string">&quot;llama&quot;</span>, <span class="string">&quot;LlamaForCausalLM&quot;</span>),</span><br><span class="line">    <span class="string">&quot;GemmaForCausalLM&quot;</span>: (<span class="string">&quot;gemma&quot;</span>, <span class="string">&quot;GemmaForCausalLM&quot;</span>),</span><br><span class="line">    <span class="comment"># ... 更多模型映射</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-3-权重文件发现与准备"><a href="#3-3-权重文件发现与准备" class="headerlink" title="3.3 权重文件发现与准备"></a>3.3 权重文件发现与准备</h3><p>在 <code>DefaultModelLoader._prepare_weights()</code> 中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_prepare_weights</span>(<span class="params">self, model_name_or_path: <span class="built_in">str</span>, revision: <span class="type">Optional</span>[<span class="built_in">str</span>], </span></span><br><span class="line"><span class="params">                     fall_back_to_pt: <span class="built_in">bool</span>, allow_patterns_overrides: <span class="type">Optional</span>[<span class="built_in">list</span>[<span class="built_in">str</span>]]</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;准备权重文件&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1. 确定加载格式</span></span><br><span class="line">    <span class="keyword">if</span> load_format == LoadFormat.SAFETENSORS:</span><br><span class="line">        use_safetensors = <span class="literal">True</span></span><br><span class="line">        allow_patterns = [<span class="string">&quot;*.safetensors&quot;</span>]</span><br><span class="line">    <span class="keyword">elif</span> load_format == LoadFormat.AUTO:</span><br><span class="line">        allow_patterns = [<span class="string">&quot;*.safetensors&quot;</span>, <span class="string">&quot;*.bin&quot;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 下载或发现权重文件</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> is_local:</span><br><span class="line">        hf_folder = download_weights_from_hf(...)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        hf_folder = model_name_or_path</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 收集匹配的权重文件</span></span><br><span class="line">    hf_weights_files = []</span><br><span class="line">    <span class="keyword">for</span> pattern <span class="keyword">in</span> allow_patterns:</span><br><span class="line">        hf_weights_files += glob.glob(os.path.join(hf_folder, pattern))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. 处理分片文件去重</span></span><br><span class="line">    <span class="keyword">if</span> use_safetensors:</span><br><span class="line">        hf_weights_files = filter_duplicate_safetensors_files(...)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> hf_folder, hf_weights_files, use_safetensors</span><br></pre></td></tr></table></figure>

<h3 id="3-4-权重迭代器创建"><a href="#3-4-权重迭代器创建" class="headerlink" title="3.4 权重迭代器创建"></a>3.4 权重迭代器创建</h3><p>在 <code>DefaultModelLoader._get_weights_iterator()</code> 中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_get_weights_iterator</span>(<span class="params">self, source: <span class="string">&quot;Source&quot;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;创建权重迭代器&quot;&quot;&quot;</span></span><br><span class="line">    hf_folder, hf_weights_files, use_safetensors = <span class="variable language_">self</span>._prepare_weights(...)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> use_safetensors:</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.load_config.load_format == LoadFormat.FASTSAFETENSORS:</span><br><span class="line">            <span class="comment"># 使用快速 safetensors 加载器</span></span><br><span class="line">            weights_iterator = fastsafetensors_weights_iterator(</span><br><span class="line">                hf_weights_files, <span class="variable language_">self</span>.load_config.use_tqdm_on_load)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 使用标准 safetensors 加载器</span></span><br><span class="line">            weights_iterator = safetensors_weights_iterator(</span><br><span class="line">                hf_weights_files, <span class="variable language_">self</span>.load_config.use_tqdm_on_load)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> weights_iterator</span><br></pre></td></tr></table></figure>

<h3 id="3-5-Safetensors-权重加载"><a href="#3-5-Safetensors-权重加载" class="headerlink" title="3.5 Safetensors 权重加载"></a>3.5 Safetensors 权重加载</h3><p>在 <code>weight_utils.py</code> 中的 <code>safetensors_weights_iterator()</code> 函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">safetensors_weights_iterator</span>(<span class="params"></span></span><br><span class="line"><span class="params">    hf_weights_files: <span class="built_in">list</span>[<span class="built_in">str</span>], use_tqdm_on_load: <span class="built_in">bool</span></span></span><br><span class="line"><span class="params"></span>) -&gt; Generator[<span class="built_in">tuple</span>[<span class="built_in">str</span>, torch.Tensor], <span class="literal">None</span>, <span class="literal">None</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;迭代加载 safetensors 权重&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> st_file <span class="keyword">in</span> tqdm(hf_weights_files, desc=<span class="string">&quot;Loading safetensors checkpoint shards&quot;</span>):</span><br><span class="line">        <span class="comment"># 使用 safetensors 库的 safe_open 函数</span></span><br><span class="line">        <span class="keyword">with</span> safe_open(st_file, framework=<span class="string">&quot;pt&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> name <span class="keyword">in</span> f.keys():</span><br><span class="line">                <span class="comment"># 懒加载每个张量</span></span><br><span class="line">                param = f.get_tensor(name)</span><br><span class="line">                <span class="keyword">yield</span> name, param</span><br></pre></td></tr></table></figure>

<h3 id="3-6-模型实例化"><a href="#3-6-模型实例化" class="headerlink" title="3.6 模型实例化"></a>3.6 模型实例化</h3><p>在 <code>base_loader.py</code> 的 <code>load_model()</code> 方法中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_model</span>(<span class="params">self, vllm_config: VllmConfig, model_config: ModelConfig</span>) -&gt; nn.Module:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;加载模型的主要入口点&quot;&quot;&quot;</span></span><br><span class="line">    device_config = vllm_config.device_config</span><br><span class="line">    target_device = torch.device(device_config.device)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> set_default_torch_dtype(model_config.dtype):</span><br><span class="line">        <span class="keyword">with</span> target_device:</span><br><span class="line">            <span class="comment"># 1. 初始化模型架构</span></span><br><span class="line">            model = initialize_model(vllm_config=vllm_config, model_config=model_config)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 加载权重到模型</span></span><br><span class="line">        <span class="variable language_">self</span>.load_weights(model, model_config)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 后处理（量化、设备转移等）</span></span><br><span class="line">        process_weights_after_loading(model, model_config, target_device)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>

<h3 id="3-7-模型初始化"><a href="#3-7-模型初始化" class="headerlink" title="3.7 模型初始化"></a>3.7 模型初始化</h3><p>在 <code>utils.py</code> 的 <code>initialize_model()</code> 函数中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_model</span>(<span class="params">vllm_config: VllmConfig, model_config: ModelConfig</span>) -&gt; nn.Module:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;初始化模型架构&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1. 获取模型架构类</span></span><br><span class="line">    model_class, _ = get_model_architecture(model_config)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 配置量化</span></span><br><span class="line">    <span class="keyword">if</span> vllm_config.quant_config <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        configure_quant_config(vllm_config.quant_config, model_class)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 检查构造函数签名</span></span><br><span class="line">    signatures = inspect.signature(model_class.__init__)</span><br><span class="line">    all_params = [param.name <span class="keyword">for</span> param <span class="keyword">in</span> signatures.parameters.values()]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. 创建模型实例</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;vllm_config&quot;</span> <span class="keyword">in</span> all_params <span class="keyword">and</span> <span class="string">&quot;prefix&quot;</span> <span class="keyword">in</span> all_params:</span><br><span class="line">        <span class="comment"># 新式模型类</span></span><br><span class="line">        <span class="keyword">return</span> model_class(vllm_config=vllm_config, prefix=prefix)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 兼容旧式模型类</span></span><br><span class="line">        kwargs = build_legacy_kwargs(...)</span><br><span class="line">        <span class="keyword">return</span> model_class(**kwargs)</span><br></pre></td></tr></table></figure>

<h3 id="3-8-权重绑定到模型"><a href="#3-8-权重绑定到模型" class="headerlink" title="3.8 权重绑定到模型"></a>3.8 权重绑定到模型</h3><p>在 <code>DefaultModelLoader.load_weights()</code> 中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_weights</span>(<span class="params">self, model: nn.Module, model_config: ModelConfig</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;将权重加载到模型中&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1. 获取需要加载的权重名称</span></span><br><span class="line">    weights_to_load = &#123;name <span class="keyword">for</span> name, _ <span class="keyword">in</span> model.named_parameters()&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 调用模型的 load_weights 方法</span></span><br><span class="line">    loaded_weights = model.load_weights(</span><br><span class="line">        <span class="variable language_">self</span>.get_all_weights(model_config, model))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 验证权重是否完全加载</span></span><br><span class="line">    <span class="keyword">if</span> model_config.quantization <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> loaded_weights <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        weights_not_loaded = weights_to_load - loaded_weights</span><br><span class="line">        <span class="keyword">if</span> weights_not_loaded:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Following weights were not initialized: <span class="subst">&#123;weights_not_loaded&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="4-计算图构建过程"><a href="#4-计算图构建过程" class="headerlink" title="4. 计算图构建过程"></a>4. 计算图构建过程</h2><h3 id="4-1-模型层次结构"><a href="#4-1-模型层次结构" class="headerlink" title="4.1 模型层次结构"></a>4.1 模型层次结构</h3><p>vLLM 中的模型通常遵循以下层次结构：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ModelForCausalLM</span><br><span class="line">├── Embeddings Layer</span><br><span class="line">├── Transformer Layers</span><br><span class="line">│   ├── Attention Layer</span><br><span class="line">│   ├── MLP Layer</span><br><span class="line">│   └── Layer Norm</span><br><span class="line">└── LM Head</span><br></pre></td></tr></table></figure>

<h3 id="4-2-权重映射与绑定"><a href="#4-2-权重映射与绑定" class="headerlink" title="4.2 权重映射与绑定"></a>4.2 权重映射与绑定</h3><p>每个模型类都实现了 <code>load_weights()</code> 方法来处理权重映射：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_weights</span>(<span class="params">self, weights: Iterable[<span class="type">Tuple</span>[<span class="built_in">str</span>, torch.Tensor]]</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;加载权重到模型参数&quot;&quot;&quot;</span></span><br><span class="line">    loaded_weights = <span class="built_in">set</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> name, loaded_weight <span class="keyword">in</span> weights:</span><br><span class="line">        <span class="comment"># 1. 权重名称映射</span></span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">in</span> <span class="variable language_">self</span>.params_dict:</span><br><span class="line">            param = <span class="variable language_">self</span>.params_dict[name]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 2. 权重形状检查和调整</span></span><br><span class="line">            <span class="keyword">if</span> param.shape != loaded_weight.shape:</span><br><span class="line">                loaded_weight = <span class="variable language_">self</span>._adjust_weight_shape(param, loaded_weight)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 3. 权重赋值</span></span><br><span class="line">            param.data.copy_(loaded_weight)</span><br><span class="line">            loaded_weights.add(name)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loaded_weights</span><br></pre></td></tr></table></figure>

<h3 id="4-3-计算图优化"><a href="#4-3-计算图优化" class="headerlink" title="4.3 计算图优化"></a>4.3 计算图优化</h3><p>在权重加载完成后，vLLM 会进行计算图优化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">process_weights_after_loading</span>(<span class="params">model: nn.Module, model_config: ModelConfig, </span></span><br><span class="line"><span class="params">                                  target_device: torch.device</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;权重加载后处理&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1. 量化处理</span></span><br><span class="line">    <span class="keyword">if</span> model_config.quantization <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        apply_quantization(model, model_config.quantization)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 设备转移</span></span><br><span class="line">    model.to(target_device)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 特殊层处理</span></span><br><span class="line">    <span class="keyword">for</span> _, module <span class="keyword">in</span> model.named_modules():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(module, QKVCrossParallelLinear):</span><br><span class="line">            module.process_after_load()</span><br></pre></td></tr></table></figure>

<h2 id="5-性能优化特性"><a href="#5-性能优化特性" class="headerlink" title="5. 性能优化特性"></a>5. 性能优化特性</h2><h3 id="5-1-懒加载机制"><a href="#5-1-懒加载机制" class="headerlink" title="5.1 懒加载机制"></a>5.1 懒加载机制</h3><ul>
<li><strong>按需加载</strong>: 使用 <code>safe_open</code> 实现张量的懒加载</li>
<li><strong>内存效率</strong>: 避免同时加载所有权重到内存</li>
<li><strong>流式处理</strong>: 通过迭代器模式支持大模型加载</li>
</ul>
<h3 id="5-2-分片文件处理"><a href="#5-2-分片文件处理" class="headerlink" title="5.2 分片文件处理"></a>5.2 分片文件处理</h3><ul>
<li><strong>自动发现</strong>: 自动识别和合并分片的 safetensors 文件</li>
<li><strong>去重机制</strong>: 避免重复加载相同的权重文件</li>
<li><strong>索引文件</strong>: 使用 <code>model.safetensors.index.json</code> 进行高效文件管理</li>
</ul>
<h3 id="5-3-多格式支持"><a href="#5-3-多格式支持" class="headerlink" title="5.3 多格式支持"></a>5.3 多格式支持</h3><ul>
<li><strong>标准 safetensors</strong>: 使用 <code>safetensors</code> 库</li>
<li><strong>快速 safetensors</strong>: 使用 <code>fastsafetensors</code> 优化库</li>
<li><strong>RunAI 流式</strong>: 支持 <code>runai-model-streamer</code> 高性能加载</li>
</ul>
<h2 id="6-关键技术点"><a href="#6-关键技术点" class="headerlink" title="6. 关键技术点"></a>6. 关键技术点</h2><h3 id="6-1-内存管理"><a href="#6-1-内存管理" class="headerlink" title="6.1 内存管理"></a>6.1 内存管理</h3><ul>
<li><strong>设备感知</strong>: 根据目标设备优化内存分配</li>
<li><strong>数据类型</strong>: 支持多种精度（fp16, fp32, int8 等）</li>
<li><strong>内存映射</strong>: 利用系统内存映射优化大文件访问</li>
</ul>
<h3 id="6-2-并行处理"><a href="#6-2-并行处理" class="headerlink" title="6.2 并行处理"></a>6.2 并行处理</h3><ul>
<li><strong>张量并行</strong>: 支持模型权重的张量并行分布</li>
<li><strong>流水线并行</strong>: 支持模型层的流水线并行</li>
<li><strong>异步加载</strong>: 支持异步权重加载提高效率</li>
</ul>
<h3 id="6-3-错误处理"><a href="#6-3-错误处理" class="headerlink" title="6.3 错误处理"></a>6.3 错误处理</h3><ul>
<li><strong>权重验证</strong>: 检查权重完整性和匹配性</li>
<li><strong>优雅降级</strong>: 在 safetensors 不可用时回退到 .pt 文件</li>
<li><strong>详细日志</strong>: 提供详细的加载过程日志</li>
</ul>
<h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><p>vLLM 的 safetensors 模型加载和计算图转换过程是一个高度优化的系统，通过以下关键技术实现了高效的模型加载：</p>
<ol>
<li><strong>模块化设计</strong>: 通过加载器抽象实现多格式支持</li>
<li><strong>懒加载机制</strong>: 优化内存使用和加载性能</li>
<li><strong>智能缓存</strong>: 避免重复下载和处理</li>
<li><strong>并行优化</strong>: 支持分布式模型加载</li>
<li><strong>错误恢复</strong>: 提供多种备用加载方案</li>
</ol>
<p>这个设计使得 vLLM 能够高效地处理各种规模的模型，从小型模型到数百GB的大型语言模型。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/16/System/vLLM_safetensors%E6%A8%A1%E5%9E%8B%E5%8A%A0%E8%BD%BD%E4%B8%8E%E8%AE%A1%E7%AE%97%E5%9B%BE%E8%BD%AC%E6%8D%A2%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/" data-id="cmdpf31ao002fq0on9lxhar1x" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-System/vLLM_PagedAttention_实现详细分析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/16/System/vLLM_PagedAttention_%E5%AE%9E%E7%8E%B0%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2025-07-16T02:11:51.911Z" itemprop="datePublished">2025-07-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="vLLM-Paged-Attention-架构与实现深度分析"><a href="#vLLM-Paged-Attention-架构与实现深度分析" class="headerlink" title="vLLM Paged Attention 架构与实现深度分析"></a>vLLM Paged Attention 架构与实现深度分析</h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>Paged Attention 是 vLLM 的核心创新，它通过将 KV 缓存组织成固定大小的页（block）来实现高效的内存管理。这种设计大幅提升了 GPU 内存利用率，并支持动态序列长度处理。</p>
<h2 id="2-核心组件架构"><a href="#2-核心组件架构" class="headerlink" title="2. 核心组件架构"></a>2. 核心组件架构</h2><h3 id="2-1-PagedAttention-类层次结构"><a href="#2-1-PagedAttention-类层次结构" class="headerlink" title="2.1 PagedAttention 类层次结构"></a>2.1 PagedAttention 类层次结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PagedAttention (主要实现)</span><br><span class="line">├── HPUPagedAttention (HPU 平台特化)</span><br><span class="line">├── AITERPagedAttention (ROCm AITER 优化)</span><br><span class="line">└── 平台特定实现</span><br></pre></td></tr></table></figure>

<h3 id="2-2-Paged-Attention-系统架构图"><a href="#2-2-Paged-Attention-系统架构图" class="headerlink" title="2.2 Paged Attention 系统架构图"></a>2.2 Paged Attention 系统架构图</h3><pre class="mermaid">graph TB
    subgraph "Paged Attention 系统架构"
        subgraph "内存管理层"
            BM[BlockManager<br/>块管理器]
            BA[BlockAllocator<br/>块分配器]
            BT[BlockTable<br/>块表]
            BP[BlockPool<br/>块池]
        end
        
        subgraph "计算层"
            PA[PagedAttention<br/>分页注意力]
            PA_V1[PagedAttention V1<br/>短序列优化]
            PA_V2[PagedAttention V2<br/>长序列优化]
            PA_Prefix[Prefix Attention<br/>前缀注意力]
        end
        
        subgraph "存储层"
            KV_Cache[KV Cache<br/>键值缓存]
            Key_Blocks[Key Blocks<br/>键块]
            Value_Blocks[Value Blocks<br/>值块]
            Block_Mapping[Block Mapping<br/>块映射]
        end
        
        subgraph "平台特化层"
            CUDA_Ops[CUDA Operations<br/>CUDA操作]
            ROCm_Ops[ROCm Operations<br/>ROCm操作]
            HPU_Ops[HPU Operations<br/>HPU操作]
        end
    end
    
    %% 连接关系
    BM --> BA
    BA --> BP
    BM --> BT
    BT --> Block_Mapping
    
    PA --> PA_V1
    PA --> PA_V2
    PA --> PA_Prefix
    
    PA_V1 --> CUDA_Ops
    PA_V2 --> CUDA_Ops
    PA_Prefix --> CUDA_Ops
    
    PA_V1 --> ROCm_Ops
    PA_V2 --> ROCm_Ops
    
    PA_V1 --> HPU_Ops
    PA_V2 --> HPU_Ops
    
    KV_Cache --> Key_Blocks
    KV_Cache --> Value_Blocks
    Block_Mapping --> Key_Blocks
    Block_Mapping --> Value_Blocks
    
    BT --> KV_Cache
    PA --> KV_Cache</pre>

<h3 id="2-4-关键数据结构"><a href="#2-4-关键数据结构" class="headerlink" title="2.4 关键数据结构"></a>2.4 关键数据结构</h3><h4 id="PagedAttentionMetadata"><a href="#PagedAttentionMetadata" class="headerlink" title="PagedAttentionMetadata"></a>PagedAttentionMetadata</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PagedAttentionMetadata</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;PagedAttention 的元数据&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># (batch_size,) 每个序列的长度（已见过的所有 token）</span></span><br><span class="line">    seq_lens_tensor: <span class="type">Optional</span>[torch.Tensor]</span><br><span class="line">    <span class="comment"># 批次中最大解码序列长度，若为 prefill-only 批次则为 0</span></span><br><span class="line">    max_decode_seq_len: <span class="built_in">int</span></span><br><span class="line">    <span class="comment"># (batch_size, max_blocks_per_seq) 每个序列的块地址</span></span><br><span class="line">    <span class="comment"># 例如 [0, 1, 2] 表示 token 存储在 KV 缓存的第 0、1、2 块中</span></span><br><span class="line">    block_tables: <span class="type">Optional</span>[torch.Tensor]</span><br></pre></td></tr></table></figure>

<h3 id="2-5-内存布局设计"><a href="#2-5-内存布局设计" class="headerlink" title="2.5 内存布局设计"></a>2.5 内存布局设计</h3><h4 id="KV-缓存形状"><a href="#KV-缓存形状" class="headerlink" title="KV 缓存形状"></a>KV 缓存形状</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_kv_cache_shape</span>(<span class="params">num_blocks: <span class="built_in">int</span>, block_size: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                       num_kv_heads: <span class="built_in">int</span>, head_size: <span class="built_in">int</span></span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">int</span>, ...]:</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">2</span>, num_blocks, block_size * num_kv_heads * head_size)</span><br></pre></td></tr></table></figure>

<p>KV 缓存被组织为：</p>
<ul>
<li><strong>维度 0</strong>: K&#x2F;V 分离 (0 &#x3D; Key, 1 &#x3D; Value)</li>
<li><strong>维度 1</strong>: 物理块数量</li>
<li><strong>维度 2</strong>: 每块的实际存储 (block_size × num_kv_heads × head_size)</li>
</ul>
<h4 id="内存布局与块管理图"><a href="#内存布局与块管理图" class="headerlink" title="内存布局与块管理图"></a>内存布局与块管理图</h4><pre class="mermaid">graph TB
    subgraph "KV Cache 内存布局"
        subgraph "物理内存视图"
            PM[Physical Memory<br/>物理内存]
            Block_0[Block 0<br/>块 0]
            Block_1[Block 1<br/>块 1]
            Block_2[Block 2<br/>块 2]
            Block_N[Block N<br/>块 N]
        end
        
        subgraph "逻辑视图"
            KV_Cache[KV Cache<br/>键值缓存]
            Key_Cache[Key Cache<br/>键缓存]
            Value_Cache[Value Cache<br/>值缓存]
        end
        
        subgraph "块表映射"
            BT[Block Table<br/>块表]
            Seq_1[Sequence 1<br/>序列 1]
            Seq_2[Sequence 2<br/>序列 2]
            Seq_3[Sequence 3<br/>序列 3]
        end
        
        subgraph "序列到块的映射"
            Token_0[Token 0-15<br/>令牌 0-15]
            Token_1[Token 16-31<br/>令牌 16-31]
            Token_2[Token 32-47<br/>令牌 32-47]
        end
    end
    
    %% 物理内存连接
    PM --> Block_0
    PM --> Block_1
    PM --> Block_2
    PM --> Block_N
    
    %% 逻辑视图连接
    KV_Cache --> Key_Cache
    KV_Cache --> Value_Cache
    
    %% 块表映射
    BT --> Seq_1
    BT --> Seq_2
    BT --> Seq_3
    
    %% 序列到块的映射
    Seq_1 --> Token_0
    Seq_1 --> Token_1
    Seq_2 --> Token_1
    Seq_2 --> Token_2
    Seq_3 --> Token_0
    
    %% 块到物理内存的映射
    Token_0 --> Block_0
    Token_1 --> Block_1
    Token_2 --> Block_2
    
    %% 样式
    classDef blockStyle fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef cacheStyle fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef tableStyle fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    
    class Block_0,Block_1,Block_2,Block_N blockStyle
    class Key_Cache,Value_Cache,KV_Cache cacheStyle
    class BT,Seq_1,Seq_2,Seq_3 tableStyle</pre>

<h2 id="3-核心算法实现"><a href="#3-核心算法实现" class="headerlink" title="3. 核心算法实现"></a>3. 核心算法实现</h2><h3 id="3-1-KV-缓存分割与重塑"><a href="#3-1-KV-缓存分割与重塑" class="headerlink" title="3.1 KV 缓存分割与重塑"></a>3.1 KV 缓存分割与重塑</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_kv_cache</span>(<span class="params">kv_cache: torch.Tensor, num_kv_heads: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                   head_size: <span class="built_in">int</span></span>) -&gt; <span class="type">Tuple</span>[torch.Tensor, torch.Tensor]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;将 KV 缓存分割为 Key 和 Value 缓存&quot;&quot;&quot;</span></span><br><span class="line">    x = <span class="number">16</span> // kv_cache.element_size()  <span class="comment"># 内存对齐优化</span></span><br><span class="line">    num_blocks = kv_cache.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Key 缓存重塑：支持量化存储</span></span><br><span class="line">    key_cache = kv_cache[<span class="number">0</span>].view(num_blocks, num_kv_heads, head_size // x, -<span class="number">1</span>, x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Value 缓存重塑：连续存储</span></span><br><span class="line">    value_cache = kv_cache[<span class="number">1</span>].view(num_blocks, num_kv_heads, head_size, -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> key_cache, value_cache</span><br></pre></td></tr></table></figure>

<h3 id="3-2-写入分页缓存"><a href="#3-2-写入分页缓存" class="headerlink" title="3.2 写入分页缓存"></a>3.2 写入分页缓存</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_to_paged_cache</span>(<span class="params">key: torch.Tensor, value: torch.Tensor,</span></span><br><span class="line"><span class="params">                         key_cache: torch.Tensor, value_cache: torch.Tensor,</span></span><br><span class="line"><span class="params">                         slot_mapping: torch.Tensor, kv_cache_dtype: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                         k_scale: torch.Tensor, v_scale: torch.Tensor</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;将新的 KV 写入分页缓存&quot;&quot;&quot;</span></span><br><span class="line">    ops.reshape_and_cache(key, value, key_cache, value_cache, </span><br><span class="line">                          slot_mapping.flatten(), kv_cache_dtype, </span><br><span class="line">                          k_scale, v_scale)</span><br></pre></td></tr></table></figure>

<h3 id="3-3-前向解码过程"><a href="#3-3-前向解码过程" class="headerlink" title="3.3 前向解码过程"></a>3.3 前向解码过程</h3><h4 id="版本选择策略"><a href="#版本选择策略" class="headerlink" title="版本选择策略"></a>版本选择策略</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_decode</span>(<span class="params">...</span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;解码阶段的 Paged Attention 计算&quot;&quot;&quot;</span></span><br><span class="line">    max_num_partitions = (max_seq_len + _PARTITION_SIZE - <span class="number">1</span>) // _PARTITION_SIZE</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 启发式版本选择</span></span><br><span class="line">    use_v1 = (max_seq_len &lt;= <span class="number">8192</span> </span><br><span class="line">              <span class="keyword">and</span> (max_num_partitions == <span class="number">1</span> <span class="keyword">or</span> num_seqs * num_heads &gt; <span class="number">512</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> use_v1:</span><br><span class="line">        <span class="comment"># 使用 PagedAttention V1 - 适合短序列或高并发</span></span><br><span class="line">        ops.paged_attention_v1(...)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 使用 PagedAttention V2 - 适合长序列，避免共享内存不足</span></span><br><span class="line">        ops.paged_attention_v2(...)</span><br></pre></td></tr></table></figure>

<h4 id="PagedAttention-V1-vs-V2"><a href="#PagedAttention-V1-vs-V2" class="headerlink" title="PagedAttention V1 vs V2"></a>PagedAttention V1 vs V2</h4><p><strong>V1 特点</strong>:</p>
<ul>
<li>单次计算完成</li>
<li>适合短序列 (≤8192 tokens)</li>
<li>高并发时性能更好</li>
<li>共享内存使用较少</li>
</ul>
<p><strong>V2 特点</strong>:</p>
<ul>
<li>分片计算 + 规约操作</li>
<li>适合长序列 (&gt;8192 tokens)</li>
<li>避免共享内存溢出</li>
<li>需要额外的临时缓冲区</li>
</ul>
<h3 id="3-4-V2-算法详细实现"><a href="#3-4-V2-算法详细实现" class="headerlink" title="3.4 V2 算法详细实现"></a>3.4 V2 算法详细实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># V2 需要的临时缓冲区</span></span><br><span class="line">tmp_output = torch.empty(</span><br><span class="line">    size=(num_seqs, num_heads, max_num_partitions, head_size),</span><br><span class="line">    dtype=output.dtype, device=output.device)</span><br><span class="line">exp_sums = torch.empty(</span><br><span class="line">    size=(num_seqs, num_heads, max_num_partitions),</span><br><span class="line">    dtype=torch.float32, device=output.device)</span><br><span class="line">max_logits = torch.empty_like(exp_sums)</span><br><span class="line"></span><br><span class="line">ops.paged_attention_v2(output, exp_sums, max_logits, tmp_output, ...)</span><br></pre></td></tr></table></figure>

<h3 id="3-5-Paged-Attention-计算流程图"><a href="#3-5-Paged-Attention-计算流程图" class="headerlink" title="3.5 Paged Attention 计算流程图"></a>3.5 Paged Attention 计算流程图</h3><pre class="mermaid">flowchart TD
    Start([开始 Paged Attention]) --> Check_Version{选择算法版本}
    
    Check_Version -->|短序列 ≤8192| V1[PagedAttention V1<br/>单次计算]
    Check_Version -->|长序列 >8192| V2[PagedAttention V2<br/>分片计算]
    
    subgraph "V1 算法流程"
        V1 --> V1_Init[初始化输出张量]
        V1_Init --> V1_Compute[单次注意力计算]
        V1_Compute --> V1_Finish[完成计算]
    end
    
    subgraph "V2 算法流程"
        V2 --> V2_Init[初始化临时缓冲区]
        V2_Init --> V2_Partition[分片计算]
        V2_Partition --> V2_Reduce[规约操作]
        V2_Reduce --> V2_Finish[完成计算]
    end
    
    subgraph "共同步骤"
        V1_Finish --> Common_Steps[后处理步骤]
        V2_Finish --> Common_Steps
        Common_Steps --> Output_Process[输出处理]
        Output_Process --> End([结束])
    end
    
    subgraph "内存管理"
        Block_Alloc[块分配]
        Cache_Write[缓存写入]
        Block_Table[块表更新]
    end
    
    V1_Compute --> Block_Alloc
    V2_Partition --> Block_Alloc
    Block_Alloc --> Cache_Write
    Cache_Write --> Block_Table
    
    %% 样式定义
    classDef v1Style fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef v2Style fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef commonStyle fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef memoryStyle fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    
    class V1,V1_Init,V1_Compute,V1_Finish v1Style
    class V2,V2_Init,V2_Partition,V2_Reduce,V2_Finish v2Style
    class Common_Steps,Output_Process commonStyle
    class Block_Alloc,Cache_Write,Block_Table memoryStyle</pre>

<h2 id="4-内存管理系统"><a href="#4-内存管理系统" class="headerlink" title="4. 内存管理系统"></a>4. 内存管理系统</h2><h3 id="4-1-Block-分配器架构"><a href="#4-1-Block-分配器架构" class="headerlink" title="4.1 Block 分配器架构"></a>4.1 Block 分配器架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DeviceAwareBlockAllocator (设备感知分配器)</span><br><span class="line">├── CpuGpuBlockAllocator (CPU/GPU 联合分配器)</span><br><span class="line">    ├── PrefixCachingBlockAllocator (前缀缓存分配器)</span><br><span class="line">    └── NaiveBlockAllocator (朴素分配器)</span><br></pre></td></tr></table></figure>

<h3 id="4-2-BlockSpaceManager"><a href="#4-2-BlockSpaceManager" class="headerlink" title="4.2 BlockSpaceManager"></a>4.2 BlockSpaceManager</h3><h4 id="核心职责"><a href="#核心职责" class="headerlink" title="核心职责"></a>核心职责</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SelfAttnBlockSpaceManager</span>(<span class="title class_ inherited__">BlockSpaceManager</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;管理 KV 缓存的块空间分配器</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    核心功能：</span></span><br><span class="line"><span class="string">    - 分配、交换、释放内存块</span></span><br><span class="line"><span class="string">    - 支持前缀缓存、fork/copy-on-write</span></span><br><span class="line"><span class="string">    - 滑动窗口内存分配</span></span><br><span class="line"><span class="string">    - Lookahead slot 管理（用于投机解码）</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block_size: <span class="built_in">int</span>, num_gpu_blocks: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 num_cpu_blocks: <span class="built_in">int</span>, watermark: <span class="built_in">float</span> = <span class="number">0.01</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.block_allocator = CpuGpuBlockAllocator.create(</span><br><span class="line">            allocator_type=<span class="string">&quot;prefix_caching&quot;</span> <span class="keyword">if</span> enable_caching <span class="keyword">else</span> <span class="string">&quot;naive&quot;</span>,</span><br><span class="line">            num_gpu_blocks=num_gpu_blocks,</span><br><span class="line">            num_cpu_blocks=num_cpu_blocks,</span><br><span class="line">            block_size=block_size)</span><br></pre></td></tr></table></figure>

<h3 id="4-3-BlockTable-实现"><a href="#4-3-BlockTable-实现" class="headerlink" title="4.3 BlockTable 实现"></a>4.3 BlockTable 实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BlockTable</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;管理特定序列的块表&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">allocate</span>(<span class="params">self, token_ids: <span class="type">List</span>[<span class="built_in">int</span>], device: Device = Device.GPU</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;为 token 序列分配内存块&quot;&quot;&quot;</span></span><br><span class="line">        blocks = <span class="variable language_">self</span>._allocate_blocks_for_token_ids(</span><br><span class="line">            prev_block=<span class="literal">None</span>, token_ids=token_ids, device=device)</span><br><span class="line">        <span class="variable language_">self</span>.update(blocks)</span><br><span class="line">        <span class="variable language_">self</span>._num_full_slots = <span class="built_in">len</span>(token_ids)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">append_token_ids</span>(<span class="params">self, token_ids: <span class="type">List</span>[<span class="built_in">int</span>], </span></span><br><span class="line"><span class="params">                         num_lookahead_slots: <span class="built_in">int</span> = <span class="number">0</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;追加新的 token 到块表&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 动态扩展块表以容纳新 token</span></span><br></pre></td></tr></table></figure>

<h3 id="4-4-前缀缓存优化"><a href="#4-4-前缀缓存优化" class="headerlink" title="4.4 前缀缓存优化"></a>4.4 前缀缓存优化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrefixCachingBlockAllocator</span>(<span class="title class_ inherited__">BlockAllocator</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;实现前缀缓存的块分配器&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">allocate_immutable_block</span>(<span class="params">self, prev_block: <span class="type">Optional</span>[Block], </span></span><br><span class="line"><span class="params">                                 token_ids: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; Block:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;分配不可变块，重用缓存块（如果可能）&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 1. 计算内容哈希</span></span><br><span class="line">        block = <span class="variable language_">self</span>._block_pool.init_block(prev_block, token_ids, ...)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 查找缓存块</span></span><br><span class="line">        cached_block_id = <span class="variable language_">self</span>._cached_blocks.get(block.content_hash, <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> cached_block_id <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 缓存命中：重用已有块</span></span><br><span class="line">            block.block_id = cached_block_id</span><br><span class="line">            <span class="variable language_">self</span>._incr_refcount_cached_block(block)</span><br><span class="line">            <span class="keyword">return</span> block</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 缓存未命中：分配新块</span></span><br><span class="line">        block = <span class="variable language_">self</span>.allocate_mutable_block(prev_block)</span><br><span class="line">        block.append_token_ids(token_ids)</span><br><span class="line">        <span class="keyword">return</span> block</span><br></pre></td></tr></table></figure>

<h2 id="5-底层-CUDA-内核接口"><a href="#5-底层-CUDA-内核接口" class="headerlink" title="5. 底层 CUDA 内核接口"></a>5. 底层 CUDA 内核接口</h2><h3 id="5-1-C-操作接口"><a href="#5-1-C-操作接口" class="headerlink" title="5.1 C++ 操作接口"></a>5.1 C++ 操作接口</h3><h4 id="Paged-Attention-V1"><a href="#Paged-Attention-V1" class="headerlink" title="Paged Attention V1"></a>Paged Attention V1</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">paged_attention_v1</span>(<span class="params"></span></span><br><span class="line"><span class="params">    out: torch.Tensor,              <span class="comment"># 输出 [num_seqs, num_heads, head_size]</span></span></span><br><span class="line"><span class="params">    query: torch.Tensor,            <span class="comment"># 查询 [num_seqs, num_heads, head_size]  </span></span></span><br><span class="line"><span class="params">    key_cache: torch.Tensor,        <span class="comment"># Key 缓存</span></span></span><br><span class="line"><span class="params">    value_cache: torch.Tensor,      <span class="comment"># Value 缓存</span></span></span><br><span class="line"><span class="params">    num_kv_heads: <span class="built_in">int</span>,              <span class="comment"># KV 头数量</span></span></span><br><span class="line"><span class="params">    scale: <span class="built_in">float</span>,                   <span class="comment"># 注意力缩放因子</span></span></span><br><span class="line"><span class="params">    block_tables: torch.Tensor,     <span class="comment"># 块表 [num_seqs, max_blocks_per_seq]</span></span></span><br><span class="line"><span class="params">    seq_lens: torch.Tensor,         <span class="comment"># 序列长度 [num_seqs]</span></span></span><br><span class="line"><span class="params">    block_size: <span class="built_in">int</span>,                <span class="comment"># 块大小</span></span></span><br><span class="line"><span class="params">    max_seq_len: <span class="built_in">int</span>,               <span class="comment"># 最大序列长度</span></span></span><br><span class="line"><span class="params">    alibi_slopes: <span class="type">Optional</span>[torch.Tensor],  <span class="comment"># ALiBi 偏置斜率</span></span></span><br><span class="line"><span class="params">    kv_cache_dtype: <span class="built_in">str</span>,            <span class="comment"># KV 缓存数据类型</span></span></span><br><span class="line"><span class="params">    <span class="comment"># ... 其他参数</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span>:</span><br></pre></td></tr></table></figure>

<h4 id="Paged-Attention-V2"><a href="#Paged-Attention-V2" class="headerlink" title="Paged Attention V2"></a>Paged Attention V2</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">paged_attention_v2</span>(<span class="params"></span></span><br><span class="line"><span class="params">    out: torch.Tensor,              <span class="comment"># 最终输出</span></span></span><br><span class="line"><span class="params">    exp_sum: torch.Tensor,          <span class="comment"># 指数和 [num_seqs, num_heads, max_partitions]</span></span></span><br><span class="line"><span class="params">    max_logits: torch.Tensor,       <span class="comment"># 最大 logits [num_seqs, num_heads, max_partitions]</span></span></span><br><span class="line"><span class="params">    tmp_out: torch.Tensor,          <span class="comment"># 临时输出 [num_seqs, num_heads, max_partitions, head_size]</span></span></span><br><span class="line"><span class="params">    <span class="comment"># ... 其他参数与 V1 相同</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span>:</span><br></pre></td></tr></table></figure>

<h3 id="5-2-KV-缓存操作"><a href="#5-2-KV-缓存操作" class="headerlink" title="5.2 KV 缓存操作"></a>5.2 KV 缓存操作</h3><h4 id="reshape-and-cache"><a href="#reshape-and-cache" class="headerlink" title="reshape_and_cache"></a>reshape_and_cache</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">reshape_and_cache</span>(<span class="params"></span></span><br><span class="line"><span class="params">    key: torch.Tensor,              <span class="comment"># 输入 Key [num_tokens, num_heads, head_size]</span></span></span><br><span class="line"><span class="params">    value: torch.Tensor,            <span class="comment"># 输入 Value [num_tokens, num_heads, head_size]</span></span></span><br><span class="line"><span class="params">    key_cache: torch.Tensor,        <span class="comment"># Key 缓存</span></span></span><br><span class="line"><span class="params">    value_cache: torch.Tensor,      <span class="comment"># Value 缓存  </span></span></span><br><span class="line"><span class="params">    slot_mapping: torch.Tensor,     <span class="comment"># 插槽映射 [num_tokens]</span></span></span><br><span class="line"><span class="params">    kv_cache_dtype: <span class="built_in">str</span>,            <span class="comment"># 缓存数据类型</span></span></span><br><span class="line"><span class="params">    k_scale: torch.Tensor,          <span class="comment"># Key 量化缩放</span></span></span><br><span class="line"><span class="params">    v_scale: torch.Tensor,          <span class="comment"># Value 量化缩放</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;将新的 KV 重塑并缓存到分页缓存中&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="6-平台特化实现"><a href="#6-平台特化实现" class="headerlink" title="6. 平台特化实现"></a>6. 平台特化实现</h2><h3 id="6-1-ROCm-AITER-优化"><a href="#6-1-ROCm-AITER-优化" class="headerlink" title="6.1 ROCm AITER 优化"></a>6.1 ROCm AITER 优化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AITERPagedAttention</span>(<span class="title class_ inherited__">PagedAttention</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;ROCm 平台的 AITER 优化实现&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">write_to_paged_cache</span>(<span class="params">...</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;使用 ROCm AITER 的优化缓存写入&quot;&quot;&quot;</span></span><br><span class="line">        rocm_aiter.reshape_and_cache_with_pertoken_quant(...)</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_decode</span>(<span class="params">...</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;使用块稀疏分页注意力进行优化&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> blocksparse_vert_stride &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 使用块稀疏 paged attention</span></span><br><span class="line">            <span class="keyword">return</span> PagedAttention.forward_decode(...)</span><br></pre></td></tr></table></figure>

<h3 id="6-2-HPU-平台实现"><a href="#6-2-HPU-平台实现" class="headerlink" title="6.2 HPU 平台实现"></a>6.2 HPU 平台实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">HPUPagedAttentionMetadata</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;HPU 平台的 PagedAttention 元数据&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># HPU 特定的元数据结构</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HPUPagedAttention</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;HPU 平台的 PagedAttention 实现&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">write_to_paged_cache</span>(<span class="params">...</span>):</span><br><span class="line">        cache_ops.reshape_and_cache(...)  <span class="comment"># HPU 特化操作</span></span><br></pre></td></tr></table></figure>

<h2 id="7-性能优化特性"><a href="#7-性能优化特性" class="headerlink" title="7. 性能优化特性"></a>7. 性能优化特性</h2><h3 id="7-1-内存对齐优化"><a href="#7-1-内存对齐优化" class="headerlink" title="7.1 内存对齐优化"></a>7.1 内存对齐优化</h3><ul>
<li><strong>16字节对齐</strong>: Key 缓存使用 16 字节对齐以优化内存访问</li>
<li><strong>量化支持</strong>: 支持 INT8&#x2F;FP8 量化以减少内存占用</li>
<li><strong>零拷贝操作</strong>: 块交换使用零拷贝提升性能</li>
</ul>
<h3 id="7-2-块稀疏注意力"><a href="#7-2-块稀疏注意力" class="headerlink" title="7.2 块稀疏注意力"></a>7.2 块稀疏注意力</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 支持块稀疏模式以处理长序列</span></span><br><span class="line">blocksparse_local_blocks: <span class="built_in">int</span> = <span class="number">0</span>      <span class="comment"># 局部块数量</span></span><br><span class="line">blocksparse_vert_stride: <span class="built_in">int</span> = <span class="number">0</span>       <span class="comment"># 垂直步幅  </span></span><br><span class="line">blocksparse_block_size: <span class="built_in">int</span> = <span class="number">64</span>       <span class="comment"># 稀疏块大小</span></span><br><span class="line">blocksparse_head_sliding_step: <span class="built_in">int</span> = <span class="number">0</span> <span class="comment"># 头部滑动步长</span></span><br></pre></td></tr></table></figure>

<h3 id="7-3-分片计算优化"><a href="#7-3-分片计算优化" class="headerlink" title="7.3 分片计算优化"></a>7.3 分片计算优化</h3><ul>
<li><strong>分区大小</strong>: 默认 512 tokens&#x2F;partition，平衡内存与计算</li>
<li><strong>动态分区</strong>: 根据序列长度自动调整分区数量</li>
<li><strong>内存重用</strong>: V2 算法中的临时缓冲区可重用</li>
</ul>
<h2 id="8-前缀注意力支持"><a href="#8-前缀注意力支持" class="headerlink" title="8. 前缀注意力支持"></a>8. 前缀注意力支持</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_prefix</span>(<span class="params">query: torch.Tensor, key: torch.Tensor, value: torch.Tensor,</span></span><br><span class="line"><span class="params">                   kv_cache_dtype: <span class="built_in">str</span>, key_cache: torch.Tensor, </span></span><br><span class="line"><span class="params">                   value_cache: torch.Tensor, block_tables: torch.Tensor,</span></span><br><span class="line"><span class="params">                   query_start_loc: torch.Tensor, seq_lens_tensor: torch.Tensor,</span></span><br><span class="line"><span class="params">                   max_query_len: <span class="built_in">int</span>, alibi_slopes: <span class="type">Optional</span>[torch.Tensor],</span></span><br><span class="line"><span class="params">                   sliding_window: <span class="type">Optional</span>[<span class="built_in">int</span>]</span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;前缀阶段的注意力计算&quot;&quot;&quot;</span></span><br><span class="line">    output = torch.empty_like(query)</span><br><span class="line">    context_attention_fwd(query, key, value, output, kv_cache_dtype,</span><br><span class="line">                          key_cache, value_cache, block_tables, </span><br><span class="line">                          query_start_loc, seq_lens_tensor, ...)</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<h2 id="9-块操作接口"><a href="#9-块操作接口" class="headerlink" title="9. 块操作接口"></a>9. 块操作接口</h2><h3 id="9-1-块交换"><a href="#9-1-块交换" class="headerlink" title="9.1 块交换"></a>9.1 块交换</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod  </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swap_blocks</span>(<span class="params">src_kv_cache: torch.Tensor, dst_kv_cache: torch.Tensor,</span></span><br><span class="line"><span class="params">                src_to_dst: torch.Tensor</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;在 CPU/GPU 之间交换块&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 分别处理 Key 和 Value 缓存</span></span><br><span class="line">    ops.swap_blocks(src_kv_cache[<span class="number">0</span>], dst_kv_cache[<span class="number">0</span>], src_to_dst)</span><br><span class="line">    ops.swap_blocks(src_kv_cache[<span class="number">1</span>], dst_kv_cache[<span class="number">1</span>], src_to_dst)</span><br></pre></td></tr></table></figure>

<h3 id="9-2-块复制"><a href="#9-2-块复制" class="headerlink" title="9.2 块复制"></a>9.2 块复制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">copy_blocks</span>(<span class="params">kv_caches: <span class="type">List</span>[torch.Tensor], </span></span><br><span class="line"><span class="params">                src_to_dists: torch.Tensor</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;复制块（用于 fork 操作）&quot;&quot;&quot;</span></span><br><span class="line">    key_caches = [kv_cache[<span class="number">0</span>] <span class="keyword">for</span> kv_cache <span class="keyword">in</span> kv_caches]</span><br><span class="line">    value_caches = [kv_cache[<span class="number">1</span>] <span class="keyword">for</span> kv_cache <span class="keyword">in</span> kv_caches]</span><br><span class="line">    ops.copy_blocks(key_caches, value_caches, src_to_dists)</span><br></pre></td></tr></table></figure>

<h2 id="10-关键技术创新"><a href="#10-关键技术创新" class="headerlink" title="10. 关键技术创新"></a>10. 关键技术创新</h2><h3 id="10-1-动态内存管理"><a href="#10-1-动态内存管理" class="headerlink" title="10.1 动态内存管理"></a>10.1 动态内存管理</h3><ul>
<li><strong>按需分配</strong>: 根据实际序列长度动态分配块</li>
<li><strong>内存池化</strong>: 使用 BlockPool 避免频繁的内存分配&#x2F;释放</li>
<li><strong>引用计数</strong>: 支持块的安全共享和释放</li>
</ul>
<h3 id="10-2-前缀缓存"><a href="#10-2-前缀缓存" class="headerlink" title="10.2 前缀缓存"></a>10.2 前缀缓存</h3><ul>
<li><strong>内容哈希</strong>: 基于内容计算哈希值实现前缀重用</li>
<li><strong>Copy-on-Write</strong>: 支持序列 fork 时的写时复制</li>
<li><strong>LRU 淘汰</strong>: 内存压力下的智能块淘汰策略</li>
</ul>
<h3 id="10-3-多设备支持"><a href="#10-3-多设备支持" class="headerlink" title="10.3 多设备支持"></a>10.3 多设备支持</h3><ul>
<li><strong>设备感知</strong>: 统一接口管理 CPU&#x2F;GPU 内存</li>
<li><strong>异步传输</strong>: 支持 CPU&#x2F;GPU 间的异步块传输</li>
<li><strong>平台优化</strong>: 针对不同硬件平台的专门优化</li>
</ul>
<h2 id="11-总结"><a href="#11-总结" class="headerlink" title="11. 总结"></a>11. 总结</h2><p>vLLM 的 Paged Attention 实现是一个高度优化的系统，通过以下关键技术实现了高效的内存管理：</p>
<ol>
<li><strong>分页内存管理</strong>: 将 KV 缓存组织成固定大小的页，实现灵活的内存分配</li>
<li><strong>版本化算法</strong>: V1&#x2F;V2 算法针对不同场景进行优化</li>
<li><strong>前缀缓存</strong>: 通过内容哈希实现计算结果的重用</li>
<li><strong>多平台支持</strong>: 针对不同硬件平台的特化实现</li>
<li><strong>块操作优化</strong>: 高效的块交换、复制和管理机制</li>
</ol>
<p>这个设计使得 vLLM 能够在保持高性能的同时，大幅提升 GPU 内存利用率，支持更大的批次大小和更长的序列处理。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/16/System/vLLM_PagedAttention_%E5%AE%9E%E7%8E%B0%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/" data-id="cmdpf31ao002eq0ondxpy3hep" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-System/PD分离架构KV_Cache跨节点传输技术分析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/16/System/PD%E5%88%86%E7%A6%BB%E6%9E%B6%E6%9E%84KV_Cache%E8%B7%A8%E8%8A%82%E7%82%B9%E4%BC%A0%E8%BE%93%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2025-07-16T02:11:51.910Z" itemprop="datePublished">2025-07-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="PD分离架构KV-Cache跨节点传输技术深度分析"><a href="#PD分离架构KV-Cache跨节点传输技术深度分析" class="headerlink" title="PD分离架构KV Cache跨节点传输技术深度分析"></a>PD分离架构KV Cache跨节点传输技术深度分析</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>本文深入分析TensorRT-LLM、vLLM和SGLang三个主流LLM服务框架中Prefill-Decode (PD) 分离架构的KV Cache跨节点传输功能实现。PD分离架构通过将计算密集型的预填充(Prefill)和内存密集型的解码(Decode)阶段分离到不同节点，实现了更好的资源利用和性能优化。</p>
<h2 id="核心技术挑战"><a href="#核心技术挑战" class="headerlink" title="核心技术挑战"></a>核心技术挑战</h2><h3 id="1-网络通信挑战"><a href="#1-网络通信挑战" class="headerlink" title="1. 网络通信挑战"></a>1. 网络通信挑战</h3><ul>
<li><strong>高带宽需求</strong>: KV Cache数据量巨大，需要高效的网络传输</li>
<li><strong>低延迟要求</strong>: 传输延迟直接影响首Token时间(TTFT)</li>
<li><strong>并发传输</strong>: 多个请求同时传输KV Cache的并发处理</li>
</ul>
<h3 id="2-数据序列化挑战"><a href="#2-数据序列化挑战" class="headerlink" title="2. 数据序列化挑战"></a>2. 数据序列化挑战</h3><ul>
<li><strong>Tensor序列化</strong>: 需要高效的张量序列化&#x2F;反序列化机制</li>
<li><strong>内存布局</strong>: 不同设备和内存布局的兼容性</li>
<li><strong>数据完整性</strong>: 网络传输过程中的数据完整性保证</li>
</ul>
<h3 id="3-系统架构挑战"><a href="#3-系统架构挑战" class="headerlink" title="3. 系统架构挑战"></a>3. 系统架构挑战</h3><ul>
<li><strong>节点发现</strong>: 动态的节点发现和连接管理</li>
<li><strong>负载均衡</strong>: 多个Prefill&#x2F;Decode节点的负载均衡</li>
<li><strong>容错处理</strong>: 节点故障时的容错和恢复机制</li>
</ul>
<h2 id="TensorRT-LLM实现分析"><a href="#TensorRT-LLM实现分析" class="headerlink" title="TensorRT-LLM实现分析"></a>TensorRT-LLM实现分析</h2><h3 id="核心架构"><a href="#核心架构" class="headerlink" title="核心架构"></a>核心架构</h3><p>TensorRT-LLM采用了<strong>分层Cache传输架构</strong>，支持多种通信后端：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 核心传输管理器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CacheTransceiver</span> &#123;</span><br><span class="line">    <span class="keyword">enum class</span> <span class="title class_">CommType</span> &#123;</span><br><span class="line">        UCX,    <span class="comment">// UCX通信</span></span><br><span class="line">        NIXL,   <span class="comment">// NIXL通信  </span></span><br><span class="line">        MPI     <span class="comment">// MPI通信</span></span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    std::unique_ptr&lt;DataResponder&gt; mDataResponder;</span><br><span class="line">    std::unique_ptr&lt;DataRequester&gt; mDataRequester;</span><br><span class="line">    std::unique_ptr&lt;executor::kv_cache::ConnectionManager&gt; mManager;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="网络通信实现"><a href="#网络通信实现" class="headerlink" title="网络通信实现"></a>网络通信实现</h3><h4 id="1-多协议支持"><a href="#1-多协议支持" class="headerlink" title="1. 多协议支持"></a>1. 多协议支持</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通信协议选择</span></span><br><span class="line"><span class="keyword">if</span> (common::<span class="built_in">getEnvUseUCXKvCache</span>()) &#123;</span><br><span class="line">    commType = CacheTransceiver::CommType::UCX;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (common::<span class="built_in">getEnvUseNixlKvCache</span>()) &#123;</span><br><span class="line">    commType = CacheTransceiver::CommType::NIXL;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (common::<span class="built_in">getEnvUseMPIKvCache</span>()) &#123;</span><br><span class="line">    commType = CacheTransceiver::CommType::MPI;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-Zero-Copy优化"><a href="#2-Zero-Copy优化" class="headerlink" title="2. Zero-Copy优化"></a>2. Zero-Copy优化</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Zero-Copy传输优化</span></span><br><span class="line"><span class="keyword">if</span> (common::<span class="built_in">getEnvTryZCopyForKVCacheTransfer</span>() &amp;&amp; </span><br><span class="line">    destConfig == selfConfig) &#123;</span><br><span class="line">    <span class="comment">// 直接GPU到GPU传输，避免CPU拷贝</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> <span class="type">const</span>&amp; connection : connections) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> <span class="type">const</span>&amp; block : outputBuffers) &#123;</span><br><span class="line">            TransferHelper::<span class="built_in">recvBuffer</span>(*connection, *block, reqId);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-并行传输"><a href="#3-并行传输" class="headerlink" title="3. 并行传输"></a>3. 并行传输</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 并发传输优化</span></span><br><span class="line">std::vector&lt;std::future&lt;<span class="type">void</span>&gt;&gt; futures;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; sendConcurrencyNum; i++) &#123;</span><br><span class="line">    futures.<span class="built_in">push_back</span>(std::<span class="built_in">async</span>(std::launch::async, </span><br><span class="line">        sendBufferFun, deviceId, i));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="序列化机制"><a href="#序列化机制" class="headerlink" title="序列化机制"></a>序列化机制</h3><h4 id="1-请求信息序列化"><a href="#1-请求信息序列化" class="headerlink" title="1. 请求信息序列化"></a>1. 请求信息序列化</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 序列化请求信息</span></span><br><span class="line"><span class="function">RequestInfo <span class="title">requestInfo</span><span class="params">(requestId, mSelfState)</span></span>;</span><br><span class="line">std::ostringstream oss;</span><br><span class="line">RequestInfo::<span class="built_in">serialize</span>(info, oss);</span><br><span class="line"><span class="keyword">auto</span> <span class="type">const</span>&amp; serializedInfo = oss.<span class="built_in">str</span>();</span><br></pre></td></tr></table></figure>

<h4 id="2-分块传输"><a href="#2-分块传输" class="headerlink" title="2. 分块传输"></a>2. 分块传输</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 分块传输大型KV Cache</span></span><br><span class="line"><span class="keyword">auto</span> <span class="type">const</span> targetBufferSize = allCacheBlockSize / targetNum;</span><br><span class="line"><span class="keyword">auto</span> result = mCacheTransBufferManager-&gt;<span class="built_in">getOrAllocateSendBuffers</span>(</span><br><span class="line">    cacheBufferId, bufferTargetNum, targetBufferSize, bufferManager);</span><br></pre></td></tr></table></figure>

<h3 id="性能优化策略"><a href="#性能优化策略" class="headerlink" title="性能优化策略"></a>性能优化策略</h3><h4 id="1-传输重叠"><a href="#1-传输重叠" class="headerlink" title="1. 传输重叠"></a>1. 传输重叠</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 支持传输与计算重叠</span></span><br><span class="line"><span class="keyword">if</span> (common::<span class="built_in">getEnvDisableKVCacheTransferOverlap</span>()) &#123;</span><br><span class="line">    mCacheTransceiver-&gt;<span class="built_in">requestAndReceiveSync</span>(newGenReq.<span class="built_in">get</span>());</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    mCacheTransceiver-&gt;<span class="built_in">requestAndReceiveAsync</span>(newGenReq.<span class="built_in">get</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-选择性传输"><a href="#2-选择性传输" class="headerlink" title="2. 选择性传输"></a>2. 选择性传输</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 选择性Cache传输，只传输新分配的块</span></span><br><span class="line"><span class="keyword">if</span> (!disableSelectiveCacheTransfer) &#123;</span><br><span class="line">    <span class="keyword">auto</span> blockRange = BlockRange::<span class="built_in">fromNewlyAllocatedBlockIds</span>(</span><br><span class="line">        *cacheManager, llmRequest.mRequestId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="vLLM实现分析"><a href="#vLLM实现分析" class="headerlink" title="vLLM实现分析"></a>vLLM实现分析</h2><h3 id="核心架构-1"><a href="#核心架构-1" class="headerlink" title="核心架构"></a>核心架构</h3><p>vLLM采用了<strong>三层抽象架构</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 三层抽象</span></span><br><span class="line"><span class="number">1.</span> KV pipe: FIFO管道，用于tensor传输</span><br><span class="line"><span class="number">2.</span> KV lookup buffer: 查找缓冲区，键值对存储</span><br><span class="line"><span class="number">3.</span> KV connector: 连接器，集成vLLM模型执行</span><br></pre></td></tr></table></figure>

<h3 id="网络通信实现-1"><a href="#网络通信实现-1" class="headerlink" title="网络通信实现"></a>网络通信实现</h3><h4 id="1-多连接器支持"><a href="#1-多连接器支持" class="headerlink" title="1. 多连接器支持"></a>1. 多连接器支持</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 支持多种连接器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KVTransferConfig</span>:</span><br><span class="line">    kv_connector: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span>  <span class="comment"># &quot;PyNcclConnector&quot;, &quot;SharedStorageConnector&quot;</span></span><br><span class="line">    kv_role: <span class="type">Optional</span>[KVRole] = <span class="literal">None</span>   <span class="comment"># &quot;kv_producer&quot;, &quot;kv_consumer&quot;, &quot;kv_both&quot;</span></span><br><span class="line">    kv_rank: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span>      <span class="comment"># 节点rank</span></span><br><span class="line">    kv_parallel_size: <span class="built_in">int</span> = <span class="number">1</span>          <span class="comment"># 并行实例数</span></span><br></pre></td></tr></table></figure>

<h4 id="2-分布式KV传输"><a href="#2-分布式KV传输" class="headerlink" title="2. 分布式KV传输"></a>2. 分布式KV传输</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分布式KV传输示例</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_prefill</span>(<span class="params">prefill_done</span>):</span><br><span class="line">    ktc = KVTransferConfig(</span><br><span class="line">        kv_connector=<span class="string">&quot;PyNcclConnector&quot;</span>,</span><br><span class="line">        kv_role=<span class="string">&quot;kv_producer&quot;</span>,</span><br><span class="line">        kv_rank=<span class="number">0</span>,</span><br><span class="line">        kv_parallel_size=<span class="number">2</span>,</span><br><span class="line">    )</span><br><span class="line">    llm = LLM(model=<span class="string">&quot;meta-llama/Meta-Llama-3.1-8B-Instruct&quot;</span>,</span><br><span class="line">              kv_transfer_config=ktc)</span><br></pre></td></tr></table></figure>

<h3 id="序列化机制-1"><a href="#序列化机制-1" class="headerlink" title="序列化机制"></a>序列化机制</h3><h4 id="1-高效Tensor序列化"><a href="#1-高效Tensor序列化" class="headerlink" title="1. 高效Tensor序列化"></a>1. 高效Tensor序列化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MsgpackEncoder</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_encode_tensor</span>(<span class="params">self, obj: torch.Tensor</span>) -&gt; <span class="type">Any</span>:</span><br><span class="line">        <span class="comment"># 大张量使用零拷贝</span></span><br><span class="line">        <span class="keyword">if</span> obj.numel() * obj.element_size() &gt;= <span class="variable language_">self</span>.size_threshold:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>._encode_large_tensor(obj)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>._encode_small_tensor(obj)</span><br></pre></td></tr></table></figure>

<h4 id="2-多模态数据序列化"><a href="#2-多模态数据序列化" class="headerlink" title="2. 多模态数据序列化"></a>2. 多模态数据序列化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 支持多模态数据的序列化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">enc_hook</span>(<span class="params">self, obj: <span class="type">Any</span></span>) -&gt; <span class="type">Any</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, torch.Tensor):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._encode_tensor(obj)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(obj, np.ndarray):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._encode_ndarray(obj)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(obj, MultiModalKwargs):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._encode_multimodal(obj)</span><br></pre></td></tr></table></figure>

<h3 id="传输优化"><a href="#传输优化" class="headerlink" title="传输优化"></a>传输优化</h3><h4 id="1-零拷贝传输"><a href="#1-零拷贝传输" class="headerlink" title="1. 零拷贝传输"></a>1. 零拷贝传输</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用零拷贝技术减少内存拷贝</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MsgpackEncoder</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, obj: <span class="type">Any</span></span>) -&gt; <span class="type">Sequence</span>[bytestr]:</span><br><span class="line">        <span class="comment"># 收集直接缓冲区指针，避免数据拷贝</span></span><br><span class="line">        <span class="variable language_">self</span>.aux_buffers = bufs = [<span class="string">b&#x27;&#x27;</span>]</span><br><span class="line">        bufs[<span class="number">0</span>] = <span class="variable language_">self</span>.encoder.encode(obj)</span><br><span class="line">        <span class="keyword">return</span> bufs</span><br></pre></td></tr></table></figure>

<h4 id="2-异步传输"><a href="#2-异步传输" class="headerlink" title="2. 异步传输"></a>2. 异步传输</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 异步KV传输</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">recv_kv_caches_and_hidden_states</span>(<span class="params">self, model_executable, </span></span><br><span class="line"><span class="params">                                          model_input, kv_caches</span>):</span><br><span class="line">    <span class="comment"># 异步接收KV缓存</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">await</span> <span class="variable language_">self</span>.connector.recv_kv_caches_and_hidden_states(</span><br><span class="line">        model_executable, model_input, kv_caches)</span><br></pre></td></tr></table></figure>

<h2 id="SGLang实现分析"><a href="#SGLang实现分析" class="headerlink" title="SGLang实现分析"></a>SGLang实现分析</h2><h3 id="核心架构-2"><a href="#核心架构-2" class="headerlink" title="核心架构"></a>核心架构</h3><p>SGLang采用了<strong>模块化传输引擎架构</strong>，支持Mooncake和NIXL两种传输引擎：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 传输引擎选择</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransferBackend</span>(<span class="title class_ inherited__">Enum</span>):</span><br><span class="line">    MOONCAKE = <span class="string">&quot;mooncake&quot;</span></span><br><span class="line">    NIXL = <span class="string">&quot;nixl&quot;</span></span><br><span class="line">    ASCEND = <span class="string">&quot;ascend&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="网络通信实现-2"><a href="#网络通信实现-2" class="headerlink" title="网络通信实现"></a>网络通信实现</h3><h4 id="1-RDMA高速传输"><a href="#1-RDMA高速传输" class="headerlink" title="1. RDMA高速传输"></a>1. RDMA高速传输</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NIXL RDMA传输实现</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NixlKVManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">send_kvcache</span>(<span class="params">self, peer_name: <span class="built_in">str</span>, prefill_kv_indices, </span></span><br><span class="line"><span class="params">                     dst_kv_ptrs, dst_kv_indices, dst_gpu_id, notif: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="comment"># 分组连续传输</span></span><br><span class="line">        prefill_kv_blocks, dst_kv_blocks = group_concurrent_contiguous(</span><br><span class="line">            prefill_kv_indices, dst_kv_indices)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建RDMA传输描述符</span></span><br><span class="line">        src_descs = <span class="variable language_">self</span>.agent.get_xfer_descs(src_addrs, <span class="string">&quot;VRAM&quot;</span>)</span><br><span class="line">        dst_descs = <span class="variable language_">self</span>.agent.get_xfer_descs(dst_addrs, <span class="string">&quot;VRAM&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 执行RDMA传输</span></span><br><span class="line">        xfer_handle = <span class="variable language_">self</span>.agent.initialize_xfer(</span><br><span class="line">            <span class="string">&quot;WRITE&quot;</span>, src_descs, dst_descs, peer_name, notif)</span><br></pre></td></tr></table></figure>

<h4 id="2-多节点协调"><a href="#2-多节点协调" class="headerlink" title="2. 多节点协调"></a>2. 多节点协调</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多节点协调机制</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CommonKVManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args, disaggregation_mode, server_args</span>):</span><br><span class="line">        <span class="variable language_">self</span>.bootstrap_port = server_args.disaggregation_bootstrap_port</span><br><span class="line">        <span class="variable language_">self</span>.connection_pool = &#123;&#125;</span><br><span class="line">        <span class="variable language_">self</span>.prefill_tp_size_table = &#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> disaggregation_mode == DisaggregationMode.PREFILL:</span><br><span class="line">            <span class="variable language_">self</span>._register_to_bootstrap()</span><br><span class="line">        <span class="keyword">elif</span> disaggregation_mode == DisaggregationMode.DECODE:</span><br><span class="line">            <span class="variable language_">self</span>._init_decode_connections()</span><br></pre></td></tr></table></figure>

<h3 id="传输优化策略"><a href="#传输优化策略" class="headerlink" title="传输优化策略"></a>传输优化策略</h3><h4 id="1-分层传输"><a href="#1-分层传输" class="headerlink" title="1. 分层传输"></a>1. 分层传输</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Mooncake分层传输</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_layer_tp_aware</span>(<span class="params">layer_params</span>):</span><br><span class="line">    <span class="keyword">for</span> layer_id <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">        <span class="comment"># 逐层传输，减少内存峰值</span></span><br><span class="line">        status = <span class="variable language_">self</span>.engine.batch_transfer_sync(</span><br><span class="line">            session_id, src_addr_list, dst_addr_list, length_list)</span><br></pre></td></tr></table></figure>

<h4 id="2-并发传输"><a href="#2-并发传输" class="headerlink" title="2. 并发传输"></a>2. 并发传输</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 并发传输优化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_kvcache_slice</span>(<span class="params">self, session_id, prefill_kv_indices, </span></span><br><span class="line"><span class="params">                       dst_kv_ptrs, dst_kv_indices</span>):</span><br><span class="line">    <span class="comment"># 使用线程池并发传输</span></span><br><span class="line">    futures = [executor.submit(process_layer, src_ptr, dst_ptr, item_len)</span><br><span class="line">               <span class="keyword">for</span> (src_ptr, dst_ptr, item_len) <span class="keyword">in</span> layers_params]</span><br></pre></td></tr></table></figure>

<h3 id="容错与监控"><a href="#容错与监控" class="headerlink" title="容错与监控"></a>容错与监控</h3><h4 id="1-心跳机制"><a href="#1-心跳机制" class="headerlink" title="1. 心跳机制"></a>1. 心跳机制</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 心跳检测机制</span></span><br><span class="line">SGLANG_DISAGGREGATION_HEARTBEAT_INTERVAL = <span class="number">5.0</span>  <span class="comment"># 心跳间隔</span></span><br><span class="line">SGLANG_DISAGGREGATION_HEARTBEAT_MAX_FAILURE = <span class="number">2</span>  <span class="comment"># 最大失败次数</span></span><br></pre></td></tr></table></figure>

<h4 id="2-超时处理"><a href="#2-超时处理" class="headerlink" title="2. 超时处理"></a>2. 超时处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 超时处理配置</span></span><br><span class="line">SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT = <span class="number">300</span>    <span class="comment"># 启动超时</span></span><br><span class="line">SGLANG_DISAGGREGATION_WAITING_TIMEOUT = <span class="number">300</span>      <span class="comment"># 等待超时</span></span><br></pre></td></tr></table></figure>

<h2 id="跨框架技术对比"><a href="#跨框架技术对比" class="headerlink" title="跨框架技术对比"></a>跨框架技术对比</h2><h3 id="1-通信协议支持"><a href="#1-通信协议支持" class="headerlink" title="1. 通信协议支持"></a>1. 通信协议支持</h3><table>
<thead>
<tr>
<th>框架</th>
<th>支持协议</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>TensorRT-LLM</td>
<td>UCX、NIXL、MPI</td>
<td>多协议支持，企业级稳定性</td>
</tr>
<tr>
<td>vLLM</td>
<td>PyNCCL、SharedStorage</td>
<td>简洁易用，Python生态</td>
</tr>
<tr>
<td>SGLang</td>
<td>Mooncake、NIXL</td>
<td>高性能RDMA，云原生</td>
</tr>
</tbody></table>
<h3 id="2-序列化机制"><a href="#2-序列化机制" class="headerlink" title="2. 序列化机制"></a>2. 序列化机制</h3><table>
<thead>
<tr>
<th>框架</th>
<th>序列化方式</th>
<th>优势</th>
</tr>
</thead>
<tbody><tr>
<td>TensorRT-LLM</td>
<td>原生C++序列化</td>
<td>高性能，内存效率高</td>
</tr>
<tr>
<td>vLLM</td>
<td>Msgpack + 零拷贝</td>
<td>跨语言兼容，灵活性好</td>
</tr>
<tr>
<td>SGLang</td>
<td>SafeTensors</td>
<td>安全性高，格式标准化</td>
</tr>
</tbody></table>
<h3 id="3-性能优化策略"><a href="#3-性能优化策略" class="headerlink" title="3. 性能优化策略"></a>3. 性能优化策略</h3><table>
<thead>
<tr>
<th>优化技术</th>
<th>TensorRT-LLM</th>
<th>vLLM</th>
<th>SGLang</th>
</tr>
</thead>
<tbody><tr>
<td>Zero-Copy</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>异步传输</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>并行传输</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>选择性传输</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>分层传输</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>RDMA支持</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
</tr>
</tbody></table>
<h2 id="核心代码实现详解"><a href="#核心代码实现详解" class="headerlink" title="核心代码实现详解"></a>核心代码实现详解</h2><h3 id="TensorRT-LLM传输核心"><a href="#TensorRT-LLM传输核心" class="headerlink" title="TensorRT-LLM传输核心"></a>TensorRT-LLM传输核心</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">CacheFormatter::formatOutput</span><span class="params">(LlmRequest <span class="type">const</span>&amp; llmRequest,</span></span></span><br><span class="line"><span class="params"><span class="function">    std::vector&lt;executor::kv_cache::Connection <span class="type">const</span>*&gt; <span class="type">const</span>&amp; connections,</span></span></span><br><span class="line"><span class="params"><span class="function">    CacheState <span class="type">const</span>&amp; selfConfig, SizeType32 selfIdx, </span></span></span><br><span class="line"><span class="params"><span class="function">    CacheState <span class="type">const</span>&amp; destConfig, runtime::BufferManager <span class="type">const</span>&amp; bufferManager)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 1. 获取传输块范围</span></span><br><span class="line">    <span class="keyword">auto</span> blockRange = <span class="built_in">getBlockRangeForSending</span>(mCacheManager, llmRequest);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 2. 检查是否支持零拷贝</span></span><br><span class="line">    <span class="keyword">if</span> (common::<span class="built_in">getEnvTryZCopyForKVCacheTransfer</span>() &amp;&amp; </span><br><span class="line">        destConfig == selfConfig) &#123;</span><br><span class="line">        <span class="comment">// 零拷贝传输</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> <span class="type">const</span>&amp; connection : connections) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">auto</span> <span class="type">const</span>&amp; block : inputKvCacheBlocks) &#123;</span><br><span class="line">                TransferHelper::<span class="built_in">sendBuffer</span>(*connection, *block, reqId);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 3. 分块传输</span></span><br><span class="line">    <span class="keyword">auto</span> targetBufferSize = allCacheBlockSize / targetNum;</span><br><span class="line">    <span class="keyword">auto</span> result = mCacheTransBufferManager-&gt;<span class="built_in">getOrAllocateSendBuffers</span>(</span><br><span class="line">        cacheBufferId, bufferTargetNum, targetBufferSize, bufferManager);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 4. 并行传输</span></span><br><span class="line">    std::vector&lt;std::future&lt;<span class="type">void</span>&gt;&gt; futures;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; sendConcurrencyNum; i++) &#123;</span><br><span class="line">        futures.<span class="built_in">push_back</span>(std::<span class="built_in">async</span>(std::launch::async, </span><br><span class="line">            sendBufferFun, deviceId, i));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="vLLM传输核心"><a href="#vLLM传输核心" class="headerlink" title="vLLM传输核心"></a>vLLM传输核心</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KVTransferAgent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">send_kv_caches_and_hidden_states</span>(<span class="params">self, model_executable, </span></span><br><span class="line"><span class="params">                                        model_input, kv_caches, </span></span><br><span class="line"><span class="params">                                        hidden_or_intermediate_states</span>):</span><br><span class="line">        <span class="comment"># 调用底层连接器传输</span></span><br><span class="line">        <span class="variable language_">self</span>.connector.send_kv_caches_and_hidden_states(</span><br><span class="line">            model_executable, model_input, kv_caches, </span><br><span class="line">            hidden_or_intermediate_states)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recv_kv_caches_and_hidden_states</span>(<span class="params">self, model_executable, </span></span><br><span class="line"><span class="params">                                       model_input, kv_caches</span>):</span><br><span class="line">        <span class="comment"># 接收KV缓存和隐藏状态</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.connector.recv_kv_caches_and_hidden_states(</span><br><span class="line">            model_executable, model_input, kv_caches)</span><br></pre></td></tr></table></figure>

<h3 id="SGLang传输核心"><a href="#SGLang传输核心" class="headerlink" title="SGLang传输核心"></a>SGLang传输核心</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MooncakeKVManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">send_kvcache</span>(<span class="params">self, session_id, prefill_kv_indices, </span></span><br><span class="line"><span class="params">                     dst_kv_ptrs, dst_kv_indices, executor</span>):</span><br><span class="line">        <span class="comment"># 分组连续块</span></span><br><span class="line">        prefill_kv_blocks, dst_kv_blocks = group_concurrent_contiguous(</span><br><span class="line">            prefill_kv_indices, dst_kv_indices)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 并行传输层</span></span><br><span class="line">        futures = [executor.submit(<span class="variable language_">self</span>.process_layer, src_ptr, dst_ptr, item_len)</span><br><span class="line">                   <span class="keyword">for</span> (src_ptr, dst_ptr, item_len) <span class="keyword">in</span> layers_params]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 等待传输完成</span></span><br><span class="line">        <span class="keyword">for</span> future <span class="keyword">in</span> concurrent.futures.as_completed(futures):</span><br><span class="line">            status = future.result()</span><br><span class="line">            <span class="keyword">if</span> status != <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">raise</span> TransferException(<span class="string">f&quot;Transfer failed: <span class="subst">&#123;status&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="技术发展趋势"><a href="#技术发展趋势" class="headerlink" title="技术发展趋势"></a>技术发展趋势</h2><h3 id="1-硬件加速"><a href="#1-硬件加速" class="headerlink" title="1. 硬件加速"></a>1. 硬件加速</h3><ul>
<li><strong>RDMA集成</strong>: 更深度的RDMA硬件加速集成</li>
<li><strong>专用硬件</strong>: 专门的KV Cache传输硬件</li>
<li><strong>内存池化</strong>: 跨节点内存池化技术</li>
</ul>
<h3 id="2-协议优化"><a href="#2-协议优化" class="headerlink" title="2. 协议优化"></a>2. 协议优化</h3><ul>
<li><strong>自定义协议</strong>: 针对LLM优化的专用传输协议</li>
<li><strong>压缩传输</strong>: 智能压缩算法减少传输数据量</li>
<li><strong>差异传输</strong>: 只传输变化的KV Cache部分</li>
</ul>
<h3 id="3-系统架构"><a href="#3-系统架构" class="headerlink" title="3. 系统架构"></a>3. 系统架构</h3><ul>
<li><strong>弹性伸缩</strong>: 动态节点伸缩支持</li>
<li><strong>多级缓存</strong>: 分层的KV Cache存储架构</li>
<li><strong>边缘计算</strong>: 边缘节点的KV Cache共享</li>
</ul>
<h2 id="最佳实践建议"><a href="#最佳实践建议" class="headerlink" title="最佳实践建议"></a>最佳实践建议</h2><h3 id="1-框架选择"><a href="#1-框架选择" class="headerlink" title="1. 框架选择"></a>1. 框架选择</h3><ul>
<li><strong>TensorRT-LLM</strong>: 适合企业级部署，需要高稳定性</li>
<li><strong>vLLM</strong>: 适合研究和快速原型开发</li>
<li><strong>SGLang</strong>: 适合高性能场景，需要RDMA支持</li>
</ul>
<h3 id="2-网络配置"><a href="#2-网络配置" class="headerlink" title="2. 网络配置"></a>2. 网络配置</h3><ul>
<li><strong>带宽</strong>: 至少10Gbps，推荐40Gbps以上</li>
<li><strong>延迟</strong>: 尽量使用低延迟网络设备</li>
<li><strong>拓扑</strong>: 采用胖树或全连接网络拓扑</li>
</ul>
<h3 id="3-调优参数"><a href="#3-调优参数" class="headerlink" title="3. 调优参数"></a>3. 调优参数</h3><ul>
<li><strong>并发度</strong>: 根据网络带宽调整并发传输数</li>
<li><strong>块大小</strong>: 平衡内存占用和传输效率</li>
<li><strong>超时设置</strong>: 根据网络条件设置合适的超时值</li>
</ul>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>三个框架都实现了各具特色的PD分离架构KV Cache跨节点传输功能：</p>
<ol>
<li><strong>TensorRT-LLM</strong>提供了最完整的企业级解决方案，支持多种通信协议和丰富的优化策略</li>
<li><strong>vLLM</strong>采用了简洁的三层抽象架构，具有良好的可扩展性和易用性</li>
<li><strong>SGLang</strong>专注于高性能场景，提供了先进的RDMA传输和云原生支持</li>
</ol>
<p>在实际应用中，应根据具体需求选择合适的框架，并结合硬件特性进行针对性优化。随着技术的发展，预计未来会有更多创新的传输技术和系统架构出现。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/16/System/PD%E5%88%86%E7%A6%BB%E6%9E%B6%E6%9E%84KV_Cache%E8%B7%A8%E8%8A%82%E7%82%B9%E4%BC%A0%E8%BE%93%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/" data-id="cmdpf31aj001yq0on9jx1c5di" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-System/KVCache池化技术深度分析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/16/System/KVCache%E6%B1%A0%E5%8C%96%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2025-07-16T02:11:51.904Z" itemprop="datePublished">2025-07-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="KV-Cache池化技术深度分析"><a href="#KV-Cache池化技术深度分析" class="headerlink" title="KV Cache池化技术深度分析"></a>KV Cache池化技术深度分析</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>KV Cache池化是LLM服务框架中的核心内存管理技术，通过预分配和复用内存块来避免频繁的内存分配&#x2F;释放操作，显著提升推理性能。本文深入分析TensorRT-LLM、vLLM和SGLang三个主流框架的KV Cache池化实现。</p>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li><a href="#%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86">核心技术原理</a></li>
<li><a href="#tensorrt-llm%E6%B1%A0%E5%8C%96%E6%9E%B6%E6%9E%84">TensorRT-LLM池化架构</a></li>
<li><a href="#vllm%E6%B1%A0%E5%8C%96%E6%9E%B6%E6%9E%84">vLLM池化架构</a></li>
<li><a href="#sglang%E6%B1%A0%E5%8C%96%E6%9E%B6%E6%9E%84">SGLang池化架构</a></li>
<li><a href="#%E6%8A%80%E6%9C%AF%E5%AF%B9%E6%AF%94%E5%88%86%E6%9E%90">技术对比分析</a></li>
<li><a href="#%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5">性能优化策略</a></li>
<li><a href="#%E5%AE%9E%E7%8E%B0%E5%BB%BA%E8%AE%AE">实现建议</a></li>
</ol>
<h2 id="核心技术原理"><a href="#核心技术原理" class="headerlink" title="核心技术原理"></a>核心技术原理</h2><h3 id="池化基本概念"><a href="#池化基本概念" class="headerlink" title="池化基本概念"></a>池化基本概念</h3><p>KV Cache池化基于以下核心思想：</p>
<ul>
<li><strong>预分配</strong>: 系统启动时预分配大块连续内存</li>
<li><strong>块管理</strong>: 将内存划分为固定大小的块（Block&#x2F;Page）</li>
<li><strong>复用机制</strong>: 通过引用计数和LRU策略实现块的复用</li>
<li><strong>内存对齐</strong>: 确保内存访问的高效性</li>
</ul>
<h3 id="内存层次结构"><a href="#内存层次结构" class="headerlink" title="内存层次结构"></a>内存层次结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Application Layer</span><br><span class="line">    ↓</span><br><span class="line">Block Manager Layer    ←── 池化核心层</span><br><span class="line">    ↓</span><br><span class="line">Physical Memory Layer</span><br></pre></td></tr></table></figure>

<h2 id="TensorRT-LLM池化架构"><a href="#TensorRT-LLM池化架构" class="headerlink" title="TensorRT-LLM池化架构"></a>TensorRT-LLM池化架构</h2><h3 id="整体设计"><a href="#整体设计" class="headerlink" title="整体设计"></a>整体设计</h3><p>TensorRT-LLM采用<strong>分层Block管理架构</strong>，实现了企业级的内存池化方案：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 核心类层次结构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WindowBlockManager</span> &#123;</span><br><span class="line">    <span class="comment">// 内存池管理</span></span><br><span class="line">    std::vector&lt;KVCacheBlockPool&gt; mPools;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Block追踪</span></span><br><span class="line">    std::vector&lt;BlockPtr&gt; mAllBlocksById;</span><br><span class="line">    BlockMap mContextBlocksByHash;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 空闲Block管理</span></span><br><span class="line">    std::shared_ptr&lt;BaseEvictionPolicy&gt; mEvictionPolicy;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 内存统计</span></span><br><span class="line">    SizeType32 mNumPrimaryBlocks;</span><br><span class="line">    SizeType32 mNumSecondaryBlocks;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="关键特性"><a href="#关键特性" class="headerlink" title="关键特性"></a>关键特性</h3><h4 id="1-多层内存池设计"><a href="#1-多层内存池设计" class="headerlink" title="1. 多层内存池设计"></a>1. <strong>多层内存池设计</strong></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KVCacheBlockPool</span> &#123;</span><br><span class="line">    <span class="comment">// 快速内存池（GPU）</span></span><br><span class="line">    runtime::ITensor::SharedPtr primaryPtr;</span><br><span class="line">    <span class="comment">// 慢速内存池（CPU/NVMe）</span></span><br><span class="line">    runtime::ITensor::SharedPtr secondaryPtr;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 内存池元数据</span></span><br><span class="line">    SizeType32 numLayers;</span><br><span class="line">    SizeType32 numKvHeads;</span><br><span class="line">    SizeType32 tokensPerBlock;</span><br><span class="line">    SizeType32 blockSize;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="2-智能Block管理"><a href="#2-智能Block管理" class="headerlink" title="2. 智能Block管理"></a>2. <strong>智能Block管理</strong></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KVCacheBlock</span> &#123;</span><br><span class="line">    <span class="comment">// 双重引用计数</span></span><br><span class="line">    <span class="type">int32_t</span> mRefCount;                  <span class="comment">// 运行时引用计数</span></span><br><span class="line">    <span class="type">int32_t</span> mSchedulingRefCount;        <span class="comment">// 调度期引用计数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 企业级特性</span></span><br><span class="line">    executor::RetentionPriority mPriority;    <span class="comment">// 优先级</span></span><br><span class="line">    std::chrono::milliseconds mDurationMs;    <span class="comment">// 生存时间</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 链表指针（用于LRU）</span></span><br><span class="line">    std::shared_ptr&lt;KVCacheBlock&gt; mPrevBlock;</span><br><span class="line">    NextBlockMap mNextBlocks;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="3-高级驱逐策略"><a href="#3-高级驱逐策略" class="headerlink" title="3. 高级驱逐策略"></a>3. <strong>高级驱逐策略</strong></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LRUEvictionPolicy</span> : <span class="keyword">public</span> BaseEvictionPolicy &#123;</span><br><span class="line">    <span class="comment">// 按优先级分层的LRU队列</span></span><br><span class="line">    std::vector&lt;std::vector&lt;FreeBlocksQueue&gt;&gt; mFreeQueues;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 分级内存管理</span></span><br><span class="line">    std::vector&lt;SizeType32&gt; mNumFreeBlocksPerLevel;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 企业级优先级支持</span></span><br><span class="line">    executor::RetentionPriority mSecondaryOffloadMinPriority;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="内存分配流程"><a href="#内存分配流程" class="headerlink" title="内存分配流程"></a>内存分配流程</h3><ol>
<li><p><strong>初始化阶段</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 预分配内存池</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">WindowBlockManager::allocatePools</span><span class="params">(<span class="type">bool</span> useUvm)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; pool : mPools) &#123;</span><br><span class="line">        <span class="comment">// 分配主内存池</span></span><br><span class="line">        pool.primaryPtr = mBufferManager.<span class="built_in">gpuSync</span>(cacheShape, poolDtype);</span><br><span class="line">        <span class="comment">// 分配辅助内存池</span></span><br><span class="line">        <span class="keyword">if</span> (mNumSecondaryBlocks &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            pool.secondaryPtr = BufferManager::<span class="built_in">pinned</span>(cacheShapeOffload, poolDtype);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Block分配</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">BlockPtr <span class="title">WindowBlockManager::allocateBlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 从空闲队列获取Block</span></span><br><span class="line">    <span class="keyword">auto</span> block = mEvictionPolicy-&gt;<span class="built_in">allocate</span>();</span><br><span class="line">    <span class="keyword">if</span> (block) &#123;</span><br><span class="line">        block-&gt;<span class="built_in">incRefCount</span>();</span><br><span class="line">        <span class="keyword">return</span> block;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 触发驱逐</span></span><br><span class="line">    <span class="keyword">return</span> mEvictionPolicy-&gt;<span class="built_in">evictAndAllocate</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Block释放</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">WindowBlockManager::freeBlock</span><span class="params">(BlockPtr block)</span> </span>&#123;</span><br><span class="line">    block-&gt;<span class="built_in">decRefCount</span>();</span><br><span class="line">    <span class="keyword">if</span> (!block-&gt;<span class="built_in">hasRefs</span>()) &#123;</span><br><span class="line">        mEvictionPolicy-&gt;<span class="built_in">free</span>(block);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="vLLM池化架构"><a href="#vLLM池化架构" class="headerlink" title="vLLM池化架构"></a>vLLM池化架构</h2><h3 id="整体设计-1"><a href="#整体设计-1" class="headerlink" title="整体设计"></a>整体设计</h3><p>vLLM采用<strong>模块化Block池架构</strong>，注重简洁性和可扩展性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BlockPool</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_gpu_blocks: <span class="built_in">int</span>, enable_caching: <span class="built_in">bool</span></span>):</span><br><span class="line">        <span class="comment"># 预分配所有Block对象</span></span><br><span class="line">        <span class="variable language_">self</span>.blocks: <span class="built_in">list</span>[KVCacheBlock] = [</span><br><span class="line">            KVCacheBlock(idx) <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(num_gpu_blocks)</span><br><span class="line">        ]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 双向链表管理空闲Block</span></span><br><span class="line">        <span class="variable language_">self</span>.free_block_queue = FreeKVCacheBlockQueue(<span class="variable language_">self</span>.blocks)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 缓存Block哈希映射</span></span><br><span class="line">        <span class="variable language_">self</span>.cached_block_hash_to_block: <span class="built_in">dict</span>[BlockHashWithGroupId, </span><br><span class="line">                                             <span class="built_in">dict</span>[<span class="built_in">int</span>, KVCacheBlock]] = defaultdict(<span class="built_in">dict</span>)</span><br></pre></td></tr></table></figure>

<h3 id="关键特性-1"><a href="#关键特性-1" class="headerlink" title="关键特性"></a>关键特性</h3><h4 id="1-高效Block数据结构"><a href="#1-高效Block数据结构" class="headerlink" title="1. 高效Block数据结构"></a>1. <strong>高效Block数据结构</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KVCacheBlock</span>:</span><br><span class="line">    block_id: <span class="built_in">int</span>                    <span class="comment"># 块ID</span></span><br><span class="line">    block_hash: BlockHash           <span class="comment"># 块哈希（用于prefix caching）</span></span><br><span class="line">    ref_cnt: <span class="built_in">int</span>                    <span class="comment"># 引用计数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 双向链表指针（内嵌设计，避免额外Python对象）</span></span><br><span class="line">    prev_free_block: <span class="type">Optional</span>[<span class="string">&quot;KVCacheBlock&quot;</span>] = <span class="literal">None</span></span><br><span class="line">    next_free_block: <span class="type">Optional</span>[<span class="string">&quot;KVCacheBlock&quot;</span>] = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 状态标志</span></span><br><span class="line">    is_null: <span class="built_in">bool</span> = <span class="literal">False</span></span><br><span class="line">    is_computed: <span class="built_in">bool</span> = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h4 id="2-智能空闲队列管理"><a href="#2-智能空闲队列管理" class="headerlink" title="2. 智能空闲队列管理"></a>2. <strong>智能空闲队列管理</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FreeKVCacheBlockQueue</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, blocks: <span class="built_in">list</span>[KVCacheBlock]</span>):</span><br><span class="line">        <span class="comment"># 构建双向链表</span></span><br><span class="line">        <span class="variable language_">self</span>.head = blocks[<span class="number">0</span>] <span class="keyword">if</span> blocks <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.tail = blocks[-<span class="number">1</span>] <span class="keyword">if</span> blocks <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 链接所有Block</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(blocks) - <span class="number">1</span>):</span><br><span class="line">            blocks[i].next_free_block = blocks[i + <span class="number">1</span>]</span><br><span class="line">            blocks[i + <span class="number">1</span>].prev_free_block = blocks[i]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">popleft</span>(<span class="params">self</span>) -&gt; KVCacheBlock:</span><br><span class="line">        <span class="comment"># O(1)复杂度的Block分配</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.head:</span><br><span class="line">            block = <span class="variable language_">self</span>.head</span><br><span class="line">            <span class="variable language_">self</span>._remove_from_free_queue(block)</span><br><span class="line">            <span class="keyword">return</span> block</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">append</span>(<span class="params">self, block: KVCacheBlock</span>):</span><br><span class="line">        <span class="comment"># O(1)复杂度的Block释放</span></span><br><span class="line">        <span class="variable language_">self</span>._add_to_free_queue_tail(block)</span><br></pre></td></tr></table></figure>

<h4 id="3-多级KV-Cache管理"><a href="#3-多级KV-Cache管理" class="headerlink" title="3. 多级KV Cache管理"></a>3. <strong>多级KV Cache管理</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KVCacheManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, kv_cache_config: KVCacheConfig</span>):</span><br><span class="line">        <span class="comment"># 协调器管理不同类型的KV Cache</span></span><br><span class="line">        <span class="variable language_">self</span>.coordinator = get_kv_cache_coordinator(</span><br><span class="line">            kv_cache_config=kv_cache_config,</span><br><span class="line">            enable_caching=enable_caching,</span><br><span class="line">            caching_hash_fn=<span class="variable language_">self</span>.caching_hash_fn,</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 统一Block池</span></span><br><span class="line">        <span class="variable language_">self</span>.block_pool = <span class="variable language_">self</span>.coordinator.block_pool</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 请求到Block哈希的映射</span></span><br><span class="line">        <span class="variable language_">self</span>.req_to_block_hashes: defaultdict[<span class="built_in">str</span>, <span class="built_in">list</span>[BlockHash]] = defaultdict(<span class="built_in">list</span>)</span><br></pre></td></tr></table></figure>

<h3 id="内存分配流程-1"><a href="#内存分配流程-1" class="headerlink" title="内存分配流程"></a>内存分配流程</h3><ol>
<li><p><strong>Block分配</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">allocate_slots</span>(<span class="params">self, request: Request, num_tokens: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[KVCacheBlock]:</span><br><span class="line">    blocks = []</span><br><span class="line">    num_blocks_needed = cdiv(num_tokens, <span class="variable language_">self</span>.block_size)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks_needed):</span><br><span class="line">        <span class="comment"># 尝试从缓存中获取</span></span><br><span class="line">        block = <span class="variable language_">self</span>._try_get_cached_block(request)</span><br><span class="line">        <span class="keyword">if</span> block <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 从空闲队列分配</span></span><br><span class="line">            block = <span class="variable language_">self</span>.block_pool.allocate()</span><br><span class="line">            <span class="keyword">if</span> block <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="comment"># 触发驱逐</span></span><br><span class="line">                block = <span class="variable language_">self</span>.block_pool.evict_and_allocate()</span><br><span class="line">        </span><br><span class="line">        blocks.append(block)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> blocks</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Prefix Caching优化</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_computed_blocks</span>(<span class="params">self, request: Request</span>) -&gt; <span class="type">List</span>[KVCacheBlock]:</span><br><span class="line">    block_hashes = <span class="variable language_">self</span>._compute_block_hashes(request)</span><br><span class="line">    computed_blocks = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> block_hash <span class="keyword">in</span> block_hashes:</span><br><span class="line">        cached_block = <span class="variable language_">self</span>.block_pool.get_cached_block(block_hash)</span><br><span class="line">        <span class="keyword">if</span> cached_block:</span><br><span class="line">            computed_blocks.append(cached_block)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span>  <span class="comment"># 缓存未命中，停止查找</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> computed_blocks</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="SGLang池化架构"><a href="#SGLang池化架构" class="headerlink" title="SGLang池化架构"></a>SGLang池化架构</h2><h3 id="整体设计-2"><a href="#整体设计-2" class="headerlink" title="整体设计"></a>整体设计</h3><p>SGLang采用<strong>三层内存池架构</strong>，是三个框架中最复杂的设计：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 三层架构</span></span><br><span class="line">ReqToTokenPool          <span class="comment"># 请求到Token位置的映射</span></span><br><span class="line">    ↓</span><br><span class="line">TokenToKVPoolAllocator  <span class="comment"># Token索引到KV Cache数据的分配器</span></span><br><span class="line">    ↓</span><br><span class="line">KVCache                 <span class="comment"># 物理KV Cache存储</span></span><br></pre></td></tr></table></figure>

<h3 id="关键特性-2"><a href="#关键特性-2" class="headerlink" title="关键特性"></a>关键特性</h3><h4 id="1-分层内存池设计"><a href="#1-分层内存池设计" class="headerlink" title="1. 分层内存池设计"></a>1. <strong>分层内存池设计</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReqToTokenPool</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;第一层：请求到Token位置映射&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, max_context_len: <span class="built_in">int</span>, device: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.req_to_token = torch.zeros(</span><br><span class="line">            (size, max_context_len), dtype=torch.int32, device=device</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.free_slots = <span class="built_in">list</span>(<span class="built_in">range</span>(size))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">alloc</span>(<span class="params">self, need_size: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> need_size &gt; <span class="built_in">len</span>(<span class="variable language_">self</span>.free_slots):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        select_index = <span class="variable language_">self</span>.free_slots[:need_size]</span><br><span class="line">        <span class="variable language_">self</span>.free_slots = <span class="variable language_">self</span>.free_slots[need_size:]</span><br><span class="line">        <span class="keyword">return</span> select_index</span><br></pre></td></tr></table></figure>

<h4 id="2-多类型KV-Cache支持"><a href="#2-多类型KV-Cache支持" class="headerlink" title="2. 多类型KV Cache支持"></a>2. <strong>多类型KV Cache支持</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MHATokenToKVPool</span>(<span class="title class_ inherited__">KVCache</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;多头注意力KV Cache&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, head_num: <span class="built_in">int</span>, head_dim: <span class="built_in">int</span>, layer_num: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="comment"># 支持自定义内存池</span></span><br><span class="line">        <span class="variable language_">self</span>.enable_custom_mem_pool = get_bool_env_var(<span class="string">&quot;SGLANG_MOONCAKE_CUSTOM_MEM_POOL&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.enable_custom_mem_pool:</span><br><span class="line">            <span class="keyword">from</span> mooncake.allocator <span class="keyword">import</span> NVLinkAllocator</span><br><span class="line">            allocator = NVLinkAllocator.get_allocator(<span class="variable language_">self</span>.device)</span><br><span class="line">            <span class="variable language_">self</span>.custom_mem_pool = torch.cuda.MemPool(allocator.allocator())</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建K/V缓冲区</span></span><br><span class="line">        <span class="variable language_">self</span>.k_buffer = [torch.zeros((size + page_size, head_num, head_dim), </span><br><span class="line">                                    dtype=store_dtype, device=device) </span><br><span class="line">                        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(layer_num)]</span><br><span class="line">        <span class="variable language_">self</span>.v_buffer = [torch.zeros((size + page_size, head_num, head_dim), </span><br><span class="line">                                    dtype=store_dtype, device=device) </span><br><span class="line">                        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(layer_num)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLATokenToKVPool</span>(<span class="title class_ inherited__">KVCache</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;MLA架构KV Cache&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, kv_lora_rank: <span class="built_in">int</span>, qk_rope_head_dim: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.kv_buffer = [torch.zeros((size + page_size, <span class="number">1</span>, kv_lora_rank + qk_rope_head_dim),</span><br><span class="line">                                     dtype=store_dtype, device=device) </span><br><span class="line">                         <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(layer_num)]</span><br></pre></td></tr></table></figure>

<h4 id="3-智能分配器"><a href="#3-智能分配器" class="headerlink" title="3. 智能分配器"></a>3. <strong>智能分配器</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TokenToKVPoolAllocator</span>(<span class="title class_ inherited__">BaseTokenToKVPoolAllocator</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Token级别的KV Cache分配器&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, dtype: torch.dtype, device: <span class="built_in">str</span>, kvcache: KVCache</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(size, <span class="number">1</span>, dtype, device, kvcache)</span><br><span class="line">        <span class="variable language_">self</span>.clear()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">alloc</span>(<span class="params">self, need_size: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="keyword">if</span> need_size &gt; <span class="built_in">len</span>(<span class="variable language_">self</span>.free_pages):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        select_index = <span class="variable language_">self</span>.free_pages[:need_size]</span><br><span class="line">        <span class="variable language_">self</span>.free_pages = <span class="variable language_">self</span>.free_pages[need_size:]</span><br><span class="line">        <span class="keyword">return</span> select_index</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">free</span>(<span class="params">self, free_index: torch.Tensor</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.is_not_in_free_group:</span><br><span class="line">            <span class="variable language_">self</span>.free_pages = torch.cat((<span class="variable language_">self</span>.free_pages, free_index))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.free_group.append(free_index)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PagedTokenToKVPoolAllocator</span>(<span class="title class_ inherited__">BaseTokenToKVPoolAllocator</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;页级别的KV Cache分配器&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, page_size: <span class="built_in">int</span>, dtype: torch.dtype, device: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(size, page_size, dtype, device, kvcache)</span><br><span class="line">        <span class="variable language_">self</span>.num_pages = size // page_size</span><br><span class="line">        <span class="variable language_">self</span>.clear()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">alloc</span>(<span class="params">self, need_size: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="comment"># 页对齐分配</span></span><br><span class="line">        num_pages = need_size // <span class="variable language_">self</span>.page_size</span><br><span class="line">        <span class="keyword">if</span> num_pages &gt; <span class="built_in">len</span>(<span class="variable language_">self</span>.free_pages):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        out_pages = <span class="variable language_">self</span>.free_pages[:num_pages]</span><br><span class="line">        <span class="variable language_">self</span>.free_pages = <span class="variable language_">self</span>.free_pages[num_pages:]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成连续的页内索引</span></span><br><span class="line">        out_indices = (out_pages[:, <span class="literal">None</span>] * <span class="variable language_">self</span>.page_size + </span><br><span class="line">                      torch.arange(<span class="variable language_">self</span>.page_size, device=<span class="variable language_">self</span>.device)).reshape(-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out_indices</span><br></pre></td></tr></table></figure>

<h4 id="4-高级缓存策略"><a href="#4-高级缓存策略" class="headerlink" title="4. 高级缓存策略"></a>4. <strong>高级缓存策略</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SWARadixCache</span>(<span class="title class_ inherited__">BasePrefixCache</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;滑动窗口注意力 + Radix Cache&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, sliding_window_size: <span class="built_in">int</span>, page_size: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.sliding_window_size = sliding_window_size</span><br><span class="line">        <span class="variable language_">self</span>.page_size = page_size</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 双LRU列表管理</span></span><br><span class="line">        <span class="variable language_">self</span>.full_lru_list = LRUList(swa=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.swa_lru_list = LRUList(swa=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 不同类型的统计计数</span></span><br><span class="line">        <span class="variable language_">self</span>.full_evictable_size_ = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.swa_evictable_size_ = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.full_protected_size_ = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.swa_protected_size_ = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cache_req</span>(<span class="params">self, req: Req</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 智能缓存决策</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.should_cache_full_attention(req):</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>._cache_full_attention(req)</span><br><span class="line">        <span class="keyword">elif</span> <span class="variable language_">self</span>.should_cache_swa_attention(req):</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>._cache_swa_attention(req)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>._cache_with_eviction(req)</span><br></pre></td></tr></table></figure>

<h3 id="内存分配流程-2"><a href="#内存分配流程-2" class="headerlink" title="内存分配流程"></a>内存分配流程</h3><ol>
<li><p><strong>三层分配</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">allocate_memory_for_request</span>(<span class="params">self, request</span>):</span><br><span class="line">    <span class="comment"># 第一层：分配请求槽</span></span><br><span class="line">    req_slots = <span class="variable language_">self</span>.req_to_token_pool.alloc(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> req_slots <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第二层：分配Token索引</span></span><br><span class="line">    token_indices = <span class="variable language_">self</span>.token_to_kv_pool_allocator.alloc(request.num_tokens)</span><br><span class="line">    <span class="keyword">if</span> token_indices <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>.req_to_token_pool.free(req_slots)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第三层：物理KV Cache已预分配</span></span><br><span class="line">    <span class="comment"># 更新映射关系</span></span><br><span class="line">    <span class="variable language_">self</span>.req_to_token_pool.write(req_slots, token_indices)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> req_slots, token_indices</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>智能驱逐</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evict_if_needed</span>(<span class="params">self, required_size: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">while</span> <span class="variable language_">self</span>.available_size() &lt; required_size:</span><br><span class="line">        <span class="comment"># 优先驱逐SWA层的数据</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.swa_evictable_size_ &gt; <span class="number">0</span>:</span><br><span class="line">            evicted = <span class="variable language_">self</span>.swa_lru_list.evict_lru()</span><br><span class="line">            <span class="variable language_">self</span>.swa_evictable_size_ -= evicted.size</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 然后驱逐Full Attention层的数据</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="variable language_">self</span>.full_evictable_size_ &gt; <span class="number">0</span>:</span><br><span class="line">            evicted = <span class="variable language_">self</span>.full_lru_list.evict_lru()</span><br><span class="line">            <span class="variable language_">self</span>.full_evictable_size_ -= evicted.size</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> OutOfMemoryError(<span class="string">&quot;No evictable memory available&quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="技术对比分析"><a href="#技术对比分析" class="headerlink" title="技术对比分析"></a>技术对比分析</h2><h3 id="架构复杂度对比"><a href="#架构复杂度对比" class="headerlink" title="架构复杂度对比"></a>架构复杂度对比</h3><table>
<thead>
<tr>
<th>特性</th>
<th>TensorRT-LLM</th>
<th>vLLM</th>
<th>SGLang</th>
</tr>
</thead>
<tbody><tr>
<td><strong>架构层数</strong></td>
<td>2层</td>
<td>2层</td>
<td>3层</td>
</tr>
<tr>
<td><strong>内存池类型</strong></td>
<td>Primary&#x2F;Secondary</td>
<td>GPU&#x2F;CPU</td>
<td>Device&#x2F;Host&#x2F;Custom</td>
</tr>
<tr>
<td><strong>Block管理</strong></td>
<td>WindowBlockManager</td>
<td>BlockPool</td>
<td>多类型Allocator</td>
</tr>
<tr>
<td><strong>驱逐策略</strong></td>
<td>多级LRU + 优先级</td>
<td>标准LRU</td>
<td>双LRU + 滑动窗口</td>
</tr>
</tbody></table>
<h3 id="性能特性对比"><a href="#性能特性对比" class="headerlink" title="性能特性对比"></a>性能特性对比</h3><table>
<thead>
<tr>
<th>特性</th>
<th>TensorRT-LLM</th>
<th>vLLM</th>
<th>SGLang</th>
</tr>
</thead>
<tbody><tr>
<td><strong>分配复杂度</strong></td>
<td>O(1)</td>
<td>O(1)</td>
<td>O(1)</td>
</tr>
<tr>
<td><strong>释放复杂度</strong></td>
<td>O(1)</td>
<td>O(1)</td>
<td>O(1)</td>
</tr>
<tr>
<td><strong>内存开销</strong></td>
<td>低</td>
<td>中</td>
<td>高</td>
</tr>
<tr>
<td><strong>缓存命中率</strong></td>
<td>高</td>
<td>中</td>
<td>高</td>
</tr>
<tr>
<td><strong>企业特性</strong></td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
</tr>
</tbody></table>
<h3 id="适用场景对比"><a href="#适用场景对比" class="headerlink" title="适用场景对比"></a>适用场景对比</h3><table>
<thead>
<tr>
<th>场景</th>
<th>TensorRT-LLM</th>
<th>vLLM</th>
<th>SGLang</th>
</tr>
</thead>
<tbody><tr>
<td><strong>生产环境</strong></td>
<td>优秀</td>
<td>良好</td>
<td>优秀</td>
</tr>
<tr>
<td><strong>研究原型</strong></td>
<td>一般</td>
<td>优秀</td>
<td>良好</td>
</tr>
<tr>
<td><strong>多模态</strong></td>
<td>支持</td>
<td>支持</td>
<td>原生支持</td>
</tr>
<tr>
<td><strong>大规模部署</strong></td>
<td>优秀</td>
<td>良好</td>
<td>优秀</td>
</tr>
<tr>
<td><strong>内存受限</strong></td>
<td>优秀</td>
<td>良好</td>
<td>优秀</td>
</tr>
</tbody></table>
<h2 id="性能优化策略"><a href="#性能优化策略" class="headerlink" title="性能优化策略"></a>性能优化策略</h2><h3 id="1-内存预分配优化"><a href="#1-内存预分配优化" class="headerlink" title="1. 内存预分配优化"></a>1. <strong>内存预分配优化</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于历史统计的智能预分配</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SmartPreAllocator</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, history_window=<span class="number">1000</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.request_size_history = deque(maxlen=history_window)</span><br><span class="line">        <span class="variable language_">self</span>.allocation_patterns = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_allocation_size</span>(<span class="params">self, request_type</span>):</span><br><span class="line">        <span class="comment"># 基于历史模式预测分配大小</span></span><br><span class="line">        <span class="keyword">if</span> request_type <span class="keyword">in</span> <span class="variable language_">self</span>.allocation_patterns:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.allocation_patterns[request_type].mean()</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.default_allocation_size</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_patterns</span>(<span class="params">self, request_type, actual_size</span>):</span><br><span class="line">        <span class="keyword">if</span> request_type <span class="keyword">not</span> <span class="keyword">in</span> <span class="variable language_">self</span>.allocation_patterns:</span><br><span class="line">            <span class="variable language_">self</span>.allocation_patterns[request_type] = deque(maxlen=<span class="number">100</span>)</span><br><span class="line">        <span class="variable language_">self</span>.allocation_patterns[request_type].append(actual_size)</span><br></pre></td></tr></table></figure>

<h3 id="2-多级缓存策略"><a href="#2-多级缓存策略" class="headerlink" title="2. 多级缓存策略"></a>2. <strong>多级缓存策略</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">HierarchicalCache</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.l1_cache = FastCache(size=<span class="number">1024</span>)      <span class="comment"># GPU内存</span></span><br><span class="line">        <span class="variable language_">self</span>.l2_cache = MediumCache(size=<span class="number">4096</span>)    <span class="comment"># CPU内存</span></span><br><span class="line">        <span class="variable language_">self</span>.l3_cache = SlowCache(size=<span class="number">16384</span>)     <span class="comment"># SSD缓存</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_with_promotion</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="comment"># L1缓存命中</span></span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> <span class="variable language_">self</span>.l1_cache:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.l1_cache[key]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># L2缓存命中，提升到L1</span></span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> <span class="variable language_">self</span>.l2_cache:</span><br><span class="line">            value = <span class="variable language_">self</span>.l2_cache.pop(key)</span><br><span class="line">            <span class="variable language_">self</span>.l1_cache[key] = value</span><br><span class="line">            <span class="keyword">return</span> value</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># L3缓存命中，提升到L2</span></span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> <span class="variable language_">self</span>.l3_cache:</span><br><span class="line">            value = <span class="variable language_">self</span>.l3_cache.pop(key)</span><br><span class="line">            <span class="variable language_">self</span>.l2_cache[key] = value</span><br><span class="line">            <span class="keyword">return</span> value</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>

<h3 id="3-智能驱逐算法"><a href="#3-智能驱逐算法" class="headerlink" title="3. 智能驱逐算法"></a>3. <strong>智能驱逐算法</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AdaptiveEvictionPolicy</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.access_frequency = &#123;&#125;</span><br><span class="line">        <span class="variable language_">self</span>.access_recency = &#123;&#125;</span><br><span class="line">        <span class="variable language_">self</span>.eviction_cost = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">calculate_eviction_score</span>(<span class="params">self, block</span>):</span><br><span class="line">        <span class="comment"># 综合考虑频率、时间、成本</span></span><br><span class="line">        frequency_score = <span class="variable language_">self</span>.access_frequency.get(block.<span class="built_in">id</span>, <span class="number">0</span>)</span><br><span class="line">        recency_score = time.time() - <span class="variable language_">self</span>.access_recency.get(block.<span class="built_in">id</span>, <span class="number">0</span>)</span><br><span class="line">        cost_score = <span class="variable language_">self</span>.eviction_cost.get(block.<span class="built_in">id</span>, <span class="number">1.0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加权计算最终得分</span></span><br><span class="line">        <span class="keyword">return</span> (frequency_score * <span class="number">0.4</span> + </span><br><span class="line">                recency_score * <span class="number">0.3</span> + </span><br><span class="line">                cost_score * <span class="number">0.3</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_eviction_candidate</span>(<span class="params">self, blocks</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">min</span>(blocks, key=<span class="variable language_">self</span>.calculate_eviction_score)</span><br></pre></td></tr></table></figure>

<h2 id="实现建议"><a href="#实现建议" class="headerlink" title="实现建议"></a>实现建议</h2><h3 id="1-选择合适的架构"><a href="#1-选择合适的架构" class="headerlink" title="1. 选择合适的架构"></a>1. <strong>选择合适的架构</strong></h3><ul>
<li><strong>简单场景</strong>: 参考vLLM的简洁设计</li>
<li><strong>复杂场景</strong>: 参考SGLang的多层架构</li>
<li><strong>生产环境</strong>: 参考TensorRT-LLM的企业特性</li>
</ul>
<h3 id="2-关键设计原则"><a href="#2-关键设计原则" class="headerlink" title="2. 关键设计原则"></a>2. <strong>关键设计原则</strong></h3><ul>
<li><strong>内存对齐</strong>: 确保内存访问效率</li>
<li><strong>引用计数</strong>: 避免内存泄漏</li>
<li><strong>批量操作</strong>: 减少分配&#x2F;释放开销</li>
<li><strong>预测分配</strong>: 基于历史模式优化</li>
</ul>
<h3 id="3-性能监控"><a href="#3-性能监控" class="headerlink" title="3. 性能监控"></a>3. <strong>性能监控</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PoolPerformanceMonitor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.allocation_time = []</span><br><span class="line">        <span class="variable language_">self</span>.deallocation_time = []</span><br><span class="line">        <span class="variable language_">self</span>.cache_hit_rate = []</span><br><span class="line">        <span class="variable language_">self</span>.memory_utilization = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">record_allocation</span>(<span class="params">self, start_time, end_time, success</span>):</span><br><span class="line">        <span class="variable language_">self</span>.allocation_time.append(end_time - start_time)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_performance_summary</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;avg_allocation_time&#x27;</span>: np.mean(<span class="variable language_">self</span>.allocation_time),</span><br><span class="line">            <span class="string">&#x27;cache_hit_rate&#x27;</span>: np.mean(<span class="variable language_">self</span>.cache_hit_rate),</span><br><span class="line">            <span class="string">&#x27;memory_utilization&#x27;</span>: np.mean(<span class="variable language_">self</span>.memory_utilization),</span><br><span class="line">            <span class="string">&#x27;allocation_success_rate&#x27;</span>: <span class="variable language_">self</span>.calculate_success_rate()</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>三个框架的KV Cache池化机制各有特色：</p>
<ul>
<li><strong>TensorRT-LLM</strong>: 企业级特性完备，适合生产环境</li>
<li><strong>vLLM</strong>: 设计简洁优雅，开发友好</li>
<li><strong>SGLang</strong>: 功能最全面，支持复杂场景</li>
</ul>
<p>选择建议：</p>
<ol>
<li><strong>生产部署</strong>: TensorRT-LLM</li>
<li><strong>快速原型</strong>: vLLM</li>
<li><strong>复杂需求</strong>: SGLang</li>
<li><strong>定制开发</strong>: 结合三者优势进行设计</li>
</ol>
<p>关键是根据具体需求选择合适的架构，并在实现时注重性能监控和优化。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/16/System/KVCache%E6%B1%A0%E5%8C%96%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90/" data-id="cmdpf31ad001hq0onaiw6g48q" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-System/Continuous_Batching与请求调度优化分析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/16/System/Continuous_Batching%E4%B8%8E%E8%AF%B7%E6%B1%82%E8%B0%83%E5%BA%A6%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2025-07-16T02:11:51.902Z" itemprop="datePublished">2025-07-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Continuous-Batching与请求调度优化分析"><a href="#Continuous-Batching与请求调度优化分析" class="headerlink" title="Continuous Batching与请求调度优化分析"></a>Continuous Batching与请求调度优化分析</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Continuous Batching（连续批处理）是现代LLM推理框架的核心技术，允许动态地将新到达的请求加入正在执行的批次中，而不需要等待当前批次完成。本文深入分析TensorRT-LLM、vLLM和SGLang三个框架的Continuous Batching实现和请求调度优化策略。</p>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li><a href="#continuous-batching%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86">Continuous Batching核心原理</a></li>
<li><a href="#tensorrt-llm%E8%B0%83%E5%BA%A6%E6%9E%B6%E6%9E%84">TensorRT-LLM调度架构</a></li>
<li><a href="#vllm%E8%B0%83%E5%BA%A6%E6%9E%B6%E6%9E%84">vLLM调度架构</a></li>
<li><a href="#sglang%E8%B0%83%E5%BA%A6%E6%9E%B6%E6%9E%84">SGLang调度架构</a></li>
<li><a href="#%E8%B0%83%E5%BA%A6%E5%BC%80%E9%94%80%E4%BC%98%E5%8C%96%E5%AF%B9%E6%AF%94">调度开销优化对比</a></li>
<li><a href="#%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%AD%96%E7%95%A5">性能调优策略</a></li>
<li><a href="#%E5%AE%9E%E7%8E%B0%E5%BB%BA%E8%AE%AE">实现建议</a></li>
</ol>
<h2 id="Continuous-Batching核心原理"><a href="#Continuous-Batching核心原理" class="headerlink" title="Continuous Batching核心原理"></a>Continuous Batching核心原理</h2><h3 id="传统批处理-vs-连续批处理"><a href="#传统批处理-vs-连续批处理" class="headerlink" title="传统批处理 vs 连续批处理"></a>传统批处理 vs 连续批处理</h3><p><strong>传统批处理（Static Batching）</strong>:</p>
<ul>
<li>批次固定，所有请求同时开始和结束</li>
<li>需要填充（padding）到最大长度</li>
<li>资源利用率低，延迟高</li>
</ul>
<p><strong>连续批处理（Continuous Batching）</strong>:</p>
<ul>
<li>动态批次，请求可以异步加入和离开</li>
<li>无需padding，内存利用率高</li>
<li>支持不同长度的序列共存</li>
</ul>
<h3 id="关键技术挑战"><a href="#关键技术挑战" class="headerlink" title="关键技术挑战"></a>关键技术挑战</h3><ol>
<li><strong>调度开销</strong>: 频繁的请求调度带来的CPU开销</li>
<li><strong>内存管理</strong>: 动态的内存分配和释放</li>
<li><strong>负载均衡</strong>: 不同长度请求的混合调度</li>
<li><strong>资源争抢</strong>: GPU计算资源的高效利用</li>
</ol>
<h2 id="TensorRT-LLM调度架构"><a href="#TensorRT-LLM调度架构" class="headerlink" title="TensorRT-LLM调度架构"></a>TensorRT-LLM调度架构</h2><h3 id="核心设计理念"><a href="#核心设计理念" class="headerlink" title="核心设计理念"></a>核心设计理念</h3><p>TensorRT-LLM采用<strong>分层调度架构</strong>，将调度过程分解为多个层次：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 调度层次结构</span></span><br><span class="line">CapacityScheduler     <span class="comment">// 容量调度器 - 确定可调度的请求</span></span><br><span class="line">    ↓</span><br><span class="line">MicroBatchScheduler   <span class="comment">// 微批调度器 - 组织微批次</span></span><br><span class="line">    ↓</span><br><span class="line">AssignReqSeqSlots     <span class="comment">// 序列槽分配器 - 分配执行槽位</span></span><br><span class="line">    ↓</span><br><span class="line">AllocateKvCache       <span class="comment">// KV缓存分配器 - 分配内存资源</span></span><br></pre></td></tr></table></figure>

<h3 id="关键组件实现"><a href="#关键组件实现" class="headerlink" title="关键组件实现"></a>关键组件实现</h3><h4 id="1-容量调度器（CapacityScheduler）"><a href="#1-容量调度器（CapacityScheduler）" class="headerlink" title="1. 容量调度器（CapacityScheduler）"></a>1. <strong>容量调度器（CapacityScheduler）</strong></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CapacityScheduler</span> &#123;</span><br><span class="line">    <span class="comment">// 多种调度策略</span></span><br><span class="line">    std::variant&lt;</span><br><span class="line">        MaxRequestsScheduler,     // 最大请求数策略</span><br><span class="line">        MaxUtilizationScheduler,  // 最大利用率策略</span><br><span class="line">        GuaranteedNoEvictScheduler, // 保证不驱逐策略</span><br><span class="line">        StaticBatchScheduler      // 静态批次策略</span><br><span class="line">    &gt; mScheduler;</span><br><span class="line">    </span><br><span class="line">    <span class="function">std::tuple&lt;RequestVector, RequestVector, RequestVector&gt; <span class="title">operator</span><span class="params">()</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        RequestList <span class="type">const</span>&amp; activeRequests,</span></span></span><br><span class="line"><span class="params"><span class="function">        OptionalRef&lt;kv_cache_manager::BaseKVCacheManager&gt; kvCacheManager,</span></span></span><br><span class="line"><span class="params"><span class="function">        OptionalRef&lt;BasePeftCacheManager <span class="type">const</span>&gt; peftCacheManager,</span></span></span><br><span class="line"><span class="params"><span class="function">        OptionalRef&lt;kv_cache_manager::BaseKVCacheManager <span class="type">const</span>&gt; crossKvCacheManager</span></span></span><br><span class="line"><span class="params"><span class="function">    )</span> <span class="type">const</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="2-微批调度器（MicroBatchScheduler）"><a href="#2-微批调度器（MicroBatchScheduler）" class="headerlink" title="2. 微批调度器（MicroBatchScheduler）"></a>2. <strong>微批调度器（MicroBatchScheduler）</strong></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MicroBatchScheduler</span> &#123;</span><br><span class="line">    <span class="function">std::tuple&lt;RequestVector, RequestVector&gt; <span class="title">operator</span><span class="params">()</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        RequestVector&amp; activeRequests,</span></span></span><br><span class="line"><span class="params"><span class="function">        ReqIdsSet <span class="type">const</span>&amp; inflightReqIds,</span></span></span><br><span class="line"><span class="params"><span class="function">        SizeType32 maxBatchSizeRuntime,</span></span></span><br><span class="line"><span class="params"><span class="function">        std::optional&lt;SizeType32&gt; maxNumTokensRuntime</span></span></span><br><span class="line"><span class="params"><span class="function">    )</span> <span class="type">const</span></span>;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 上下文分块配置</span></span><br><span class="line">    std::optional&lt;ContextChunkingConfig&gt; mCtxChunkConfig;</span><br><span class="line">    LlmRequestState_t mNoScheduleUntilState;</span><br><span class="line">    LlmRequestState_t mNoScheduleAfterState;</span><br><span class="line">    std::optional&lt;SizeType32&gt; mMaxContextLength;</span><br><span class="line">    <span class="type">bool</span> mCtxGenFusion;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="3-请求状态管理"><a href="#3-请求状态管理" class="headerlink" title="3. 请求状态管理"></a>3. <strong>请求状态管理</strong></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum class</span> <span class="title class_">LlmRequestState</span> : <span class="type">int32_t</span> &#123;</span><br><span class="line">    kUNKNOWN = <span class="number">0</span>,</span><br><span class="line">    kENCODER_INIT = <span class="number">1</span>,</span><br><span class="line">    kDISAGG_GENERATION_INIT = <span class="number">8</span>,</span><br><span class="line">    kDISAGG_GENERATION_TRANS_IN_PROGRESS = <span class="number">9</span>,</span><br><span class="line">    kCONTEXT_INIT = <span class="number">10</span>,</span><br><span class="line">    kDISAGG_CONTEXT_INIT_AND_TRANS = <span class="number">11</span>,</span><br><span class="line">    kDISAGG_GENERATION_TRANS_COMPLETE = <span class="number">12</span>,</span><br><span class="line">    kGENERATION_IN_PROGRESS = <span class="number">13</span>,</span><br><span class="line">    kGENERATION_TO_COMPLETE = <span class="number">14</span>,</span><br><span class="line">    kGENERATION_COMPLETE = <span class="number">20</span>,</span><br><span class="line">    kDISAGG_CONTEXT_TRANS_IN_PROGRESS = <span class="number">21</span>,</span><br><span class="line">    kDISAGG_CONTEXT_COMPLETE = <span class="number">22</span>,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="调度流程"><a href="#调度流程" class="headerlink" title="调度流程"></a>调度流程</h3><ol>
<li><p><strong>请求分类</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将请求分为不同类型</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> <span class="type">const</span>&amp; req : activeRequests) &#123;</span><br><span class="line">    <span class="keyword">if</span> (req-&gt;<span class="built_in">isGenerationInProgressState</span>()) &#123;</span><br><span class="line">        scheduledRequests.<span class="built_in">emplace_back</span>(req);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (req-&gt;<span class="built_in">isDisaggGenerationInitState</span>()) &#123;</span><br><span class="line">        pendingDisGenInitRequests.<span class="built_in">emplace_back</span>(req);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        pendingRequests.<span class="built_in">emplace_back</span>(req);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>资源检查</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 检查KV Cache和PEFT缓存资源</span></span><br><span class="line"><span class="type">bool</span> enoughBlocks = reservedBlocks.<span class="built_in">enoughAvailableBlocks</span>(*req);</span><br><span class="line"><span class="type">bool</span> enoughCrossBlocks = reservedCrossBlocks ? </span><br><span class="line">    reservedCrossBlocks-&gt;<span class="built_in">enoughAvailableBlocks</span>(*req) : <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">auto</span> neededPeftPages = isNewTask &amp;&amp; peftCacheManager ? </span><br><span class="line">    peftCacheManager-&gt;<span class="built_in">determineNumPages</span>(req) : <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>调度决策</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (enoughBlocks &amp;&amp; enoughCrossBlocks &amp;&amp; neededPeftPages &lt;= availablePeftPages) &#123;</span><br><span class="line">    scheduledRequests.<span class="built_in">emplace_back</span>(req);</span><br><span class="line">    <span class="comment">// 更新资源状态</span></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (!enoughBlocks || !enoughCrossBlocks) &#123;</span><br><span class="line">    <span class="keyword">break</span>; <span class="comment">// 资源不足，停止调度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="优化策略"><a href="#优化策略" class="headerlink" title="优化策略"></a>优化策略</h3><h4 id="1-调度开销优化"><a href="#1-调度开销优化" class="headerlink" title="1. 调度开销优化"></a>1. <strong>调度开销优化</strong></h4><ul>
<li><strong>批次重用</strong>: 避免频繁创建和销毁批次对象</li>
<li><strong>状态缓存</strong>: 缓存调度状态以减少计算开销</li>
<li><strong>预分配</strong>: 预分配内存池减少动态分配</li>
</ul>
<h4 id="2-内存优化"><a href="#2-内存优化" class="headerlink" title="2. 内存优化"></a>2. <strong>内存优化</strong></h4><ul>
<li><strong>分层内存管理</strong>: Primary&#x2F;Secondary双层内存设计</li>
<li><strong>延迟分配</strong>: 按需分配KV Cache内存</li>
<li><strong>智能驱逐</strong>: 基于优先级的LRU驱逐策略</li>
</ul>
<h2 id="vLLM调度架构"><a href="#vLLM调度架构" class="headerlink" title="vLLM调度架构"></a>vLLM调度架构</h2><h3 id="核心设计理念-1"><a href="#核心设计理念-1" class="headerlink" title="核心设计理念"></a>核心设计理念</h3><p>vLLM采用<strong>统一调度器架构</strong>，通过单一调度器处理所有类型的请求：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Scheduler</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.waiting = deque()     <span class="comment"># 等待队列</span></span><br><span class="line">        <span class="variable language_">self</span>.running = deque()     <span class="comment"># 运行队列</span></span><br><span class="line">        <span class="variable language_">self</span>.swapped = deque()     <span class="comment"># 交换队列</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">schedule</span>(<span class="params">self</span>) -&gt; SchedulerOutputs:</span><br><span class="line">        <span class="comment"># 统一调度逻辑</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h3 id="关键组件实现-1"><a href="#关键组件实现-1" class="headerlink" title="关键组件实现"></a>关键组件实现</h3><h4 id="1-调度预算管理"><a href="#1-调度预算管理" class="headerlink" title="1. 调度预算管理"></a>1. <strong>调度预算管理</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SchedulingBudget</span>:</span><br><span class="line">    token_budget: <span class="built_in">int</span>                                    <span class="comment"># Token预算</span></span><br><span class="line">    max_num_seqs: <span class="built_in">int</span>                                   <span class="comment"># 最大序列数</span></span><br><span class="line">    _request_ids_num_batched_tokens: <span class="type">Set</span>[<span class="built_in">str</span>]          <span class="comment"># 已批处理的请求ID</span></span><br><span class="line">    _request_ids_num_curr_seqs: <span class="type">Set</span>[<span class="built_in">str</span>]               <span class="comment"># 当前序列的请求ID</span></span><br><span class="line">    _num_cached_tokens: <span class="built_in">int</span> = <span class="number">0</span>                        <span class="comment"># 缓存Token数量</span></span><br><span class="line">    _num_batched_tokens: <span class="built_in">int</span> = <span class="number">0</span>                       <span class="comment"># 批处理Token数量</span></span><br><span class="line">    _num_curr_seqs: <span class="built_in">int</span> = <span class="number">0</span>                           <span class="comment"># 当前序列数量</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">can_schedule</span>(<span class="params">self, *, num_new_tokens: <span class="built_in">int</span>, num_new_seqs: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="keyword">return</span> (<span class="variable language_">self</span>.num_batched_tokens + num_new_tokens &lt;= <span class="variable language_">self</span>.token_budget</span><br><span class="line">                <span class="keyword">and</span> <span class="variable language_">self</span>.num_curr_seqs + num_new_seqs &lt;= <span class="variable language_">self</span>.max_num_seqs)</span><br></pre></td></tr></table></figure>

<h4 id="2-双模式调度策略"><a href="#2-双模式调度策略" class="headerlink" title="2. 双模式调度策略"></a>2. <strong>双模式调度策略</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">schedule</span>(<span class="params">self</span>) -&gt; SchedulerOutputs:</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.scheduler_config.chunked_prefill_enabled:</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._schedule_chunked_prefill()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._schedule_default()</span><br></pre></td></tr></table></figure>

<h4 id="3-分块预填充调度"><a href="#3-分块预填充调度" class="headerlink" title="3. 分块预填充调度"></a>3. <strong>分块预填充调度</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_schedule_chunked_prefill</span>(<span class="params">self</span>) -&gt; SchedulerOutputs:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    分块预填充调度策略：</span></span><br><span class="line"><span class="string">    1. 优先调度解码请求</span></span><br><span class="line"><span class="string">    2. 调度分块预填充请求</span></span><br><span class="line"><span class="string">    3. 调度交换请求</span></span><br><span class="line"><span class="string">    4. 调度新的预填充请求</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 解码请求优先</span></span><br><span class="line">    running_scheduled = <span class="variable language_">self</span>._schedule_running(</span><br><span class="line">        budget, curr_loras, enable_chunking=<span class="literal">True</span>, </span><br><span class="line">        partial_prefill_metadata=partial_prefill_metadata</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 交换请求</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(running_scheduled.preempted) + <span class="built_in">len</span>(running_scheduled.swapped_out) == <span class="number">0</span>:</span><br><span class="line">        swapped_in = <span class="variable language_">self</span>._schedule_swapped(budget, curr_loras)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 预填充请求</span></span><br><span class="line">    prefills = <span class="variable language_">self</span>._schedule_prefills(</span><br><span class="line">        budget, curr_loras, enable_chunking=<span class="literal">True</span>,</span><br><span class="line">        partial_prefill_metadata=partial_prefill_metadata</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<h3 id="vLLM-V1架构优化"><a href="#vLLM-V1架构优化" class="headerlink" title="vLLM V1架构优化"></a>vLLM V1架构优化</h3><h4 id="1-统一Token调度"><a href="#1-统一Token调度" class="headerlink" title="1. 统一Token调度"></a>1. <strong>统一Token调度</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Scheduler</span>(<span class="title class_ inherited__">SchedulerInterface</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">schedule</span>(<span class="params">self</span>) -&gt; SchedulerOutput:</span><br><span class="line">        <span class="comment"># 统一的Token调度逻辑</span></span><br><span class="line">        <span class="comment"># 没有传统的&quot;解码阶段&quot;和&quot;预填充阶段&quot;区分</span></span><br><span class="line">        <span class="comment"># 每个请求都有num_computed_tokens和num_tokens_with_spec</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 调度运行中的请求</span></span><br><span class="line">        <span class="keyword">for</span> request <span class="keyword">in</span> <span class="variable language_">self</span>.running:</span><br><span class="line">            num_new_tokens = (request.num_tokens_with_spec - </span><br><span class="line">                            request.num_computed_tokens)</span><br><span class="line">            <span class="comment"># 分配KV Cache槽位</span></span><br><span class="line">            new_blocks = <span class="variable language_">self</span>.kv_cache_manager.allocate_slots(</span><br><span class="line">                request, num_new_tokens, </span><br><span class="line">                num_lookahead_tokens=<span class="variable language_">self</span>.num_lookahead_tokens</span><br><span class="line">            )</span><br></pre></td></tr></table></figure>

<h4 id="2-抢占式调度"><a href="#2-抢占式调度" class="headerlink" title="2. 抢占式调度"></a>2. <strong>抢占式调度</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">schedule</span>(<span class="params">self</span>) -&gt; SchedulerOutput:</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        new_blocks = <span class="variable language_">self</span>.kv_cache_manager.allocate_slots(...)</span><br><span class="line">        <span class="keyword">if</span> new_blocks <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 内存不足，抢占最低优先级请求</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.policy == SchedulingPolicy.PRIORITY:</span><br><span class="line">                preempted_req = <span class="built_in">max</span>(</span><br><span class="line">                    <span class="variable language_">self</span>.running,</span><br><span class="line">                    key=<span class="keyword">lambda</span> r: (r.priority, r.arrival_time),</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                preempted_req = <span class="variable language_">self</span>.running.pop()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 释放资源并重新调度</span></span><br><span class="line">            <span class="variable language_">self</span>.kv_cache_manager.free(preempted_req)</span><br><span class="line">            preempted_req.status = RequestStatus.PREEMPTED</span><br></pre></td></tr></table></figure>

<h3 id="优化策略-1"><a href="#优化策略-1" class="headerlink" title="优化策略"></a>优化策略</h3><h4 id="1-批次队列优化"><a href="#1-批次队列优化" class="headerlink" title="1. 批次队列优化"></a>1. <strong>批次队列优化</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">step_with_batch_queue</span>(<span class="params">self</span>) -&gt; <span class="built_in">tuple</span>[<span class="type">Optional</span>[<span class="built_in">dict</span>[<span class="built_in">int</span>, EngineCoreOutputs]], <span class="built_in">bool</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用批次队列优化调度：</span></span><br><span class="line"><span class="string">    1. 非阻塞调度新批次</span></span><br><span class="line"><span class="string">    2. 异步执行模型推理</span></span><br><span class="line"><span class="string">    3. 流水线化处理</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.batch_queue.full():</span><br><span class="line">        scheduler_output = <span class="variable language_">self</span>.scheduler.schedule()</span><br><span class="line">        <span class="keyword">if</span> scheduler_output.total_num_scheduled_tokens &gt; <span class="number">0</span>:</span><br><span class="line">            future = <span class="variable language_">self</span>.model_executor.execute_model(scheduler_output)</span><br><span class="line">            <span class="variable language_">self</span>.batch_queue.put_nowait((future, scheduler_output))</span><br></pre></td></tr></table></figure>

<h4 id="2-预填充分块优化"><a href="#2-预填充分块优化" class="headerlink" title="2. 预填充分块优化"></a>2. <strong>预填充分块优化</strong></h4><ul>
<li><strong>动态分块</strong>: 根据可用资源动态调整分块大小</li>
<li><strong>优先级调度</strong>: 解码请求优先，保证低延迟</li>
<li><strong>资源预留</strong>: 为运行请求预留资源，避免饥饿</li>
</ul>
<h2 id="SGLang调度架构"><a href="#SGLang调度架构" class="headerlink" title="SGLang调度架构"></a>SGLang调度架构</h2><h3 id="核心设计理念-2"><a href="#核心设计理念-2" class="headerlink" title="核心设计理念"></a>核心设计理念</h3><p>SGLang采用<strong>事件驱动调度架构</strong>，支持多种运行模式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Scheduler</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.waiting_queue = []           <span class="comment"># 等待队列</span></span><br><span class="line">        <span class="variable language_">self</span>.running_batch = ScheduleBatch()  <span class="comment"># 运行批次</span></span><br><span class="line">        <span class="variable language_">self</span>.cur_batch = <span class="literal">None</span>            <span class="comment"># 当前批次</span></span><br><span class="line">        <span class="variable language_">self</span>.last_batch = <span class="literal">None</span>           <span class="comment"># 上次批次</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">event_loop_normal</span>(<span class="params">self</span>):         <span class="comment"># 标准事件循环</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">event_loop_overlap</span>(<span class="params">self</span>):        <span class="comment"># 重叠事件循环</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">event_loop_pp</span>(<span class="params">self</span>):             <span class="comment"># 流水线并行事件循环</span></span><br></pre></td></tr></table></figure>

<h3 id="关键组件实现-2"><a href="#关键组件实现-2" class="headerlink" title="关键组件实现"></a>关键组件实现</h3><h4 id="1-多模式事件循环"><a href="#1-多模式事件循环" class="headerlink" title="1. 多模式事件循环"></a>1. <strong>多模式事件循环</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@DynamicGradMode()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">event_loop_normal</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;标准调度循环&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        recv_reqs = <span class="variable language_">self</span>.recv_requests()</span><br><span class="line">        <span class="variable language_">self</span>.process_input_requests(recv_reqs)</span><br><span class="line">        </span><br><span class="line">        batch = <span class="variable language_">self</span>.get_next_batch_to_run()</span><br><span class="line">        <span class="variable language_">self</span>.cur_batch = batch</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> batch:</span><br><span class="line">            result = <span class="variable language_">self</span>.run_batch(batch)</span><br><span class="line">            <span class="variable language_">self</span>.process_batch_result(batch, result)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.check_memory()</span><br><span class="line">            <span class="variable language_">self</span>.new_token_ratio = <span class="variable language_">self</span>.init_new_token_ratio</span><br><span class="line"></span><br><span class="line"><span class="meta">@DynamicGradMode()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">event_loop_overlap</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;重叠调度循环 - CPU处理与GPU计算重叠&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 异步处理上次批次结果</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.last_batch:</span><br><span class="line">            tmp_batch, tmp_result = <span class="variable language_">self</span>.result_queue.popleft()</span><br><span class="line">            <span class="variable language_">self</span>.process_batch_result(tmp_batch, tmp_result)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 同时准备新批次</span></span><br><span class="line">        batch = <span class="variable language_">self</span>.get_next_batch_to_run()</span><br><span class="line">        <span class="keyword">if</span> batch:</span><br><span class="line">            result = <span class="variable language_">self</span>.run_batch(batch)</span><br><span class="line">            <span class="variable language_">self</span>.result_queue.append((batch.copy(), result))</span><br></pre></td></tr></table></figure>

<h4 id="2-智能预填充调度"><a href="#2-智能预填充调度" class="headerlink" title="2. 智能预填充调度"></a>2. <strong>智能预填充调度</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrefillAdder</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, page_size, tree_cache, token_to_kv_pool_allocator, </span></span><br><span class="line"><span class="params">                 running_batch, new_token_ratio, max_prefill_tokens,</span></span><br><span class="line"><span class="params">                 chunked_prefill_size, mixed_chunk_size</span>):</span><br><span class="line">        <span class="variable language_">self</span>.can_run_list = []</span><br><span class="line">        <span class="variable language_">self</span>.new_chunked_req = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_one_req</span>(<span class="params">self, req: Req, has_chunked_req: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; AddReqResult:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;添加单个请求到预填充批次&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 检查Token预算</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.total_token_num + req.extend_input_len &gt; <span class="variable language_">self</span>.max_prefill_tokens:</span><br><span class="line">            <span class="keyword">return</span> AddReqResult.NO_TOKEN</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 检查KV Cache资源</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.alloc_req(req):</span><br><span class="line">            <span class="keyword">return</span> AddReqResult.NO_MEM</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 成功添加请求</span></span><br><span class="line">        <span class="variable language_">self</span>.can_run_list.append(req)</span><br><span class="line">        <span class="keyword">return</span> AddReqResult.CONTINUE</span><br></pre></td></tr></table></figure>

<h4 id="3-分块预填充优化"><a href="#3-分块预填充优化" class="headerlink" title="3. 分块预填充优化"></a>3. <strong>分块预填充优化</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_new_batch_prefill</span>(<span class="params">self</span>) -&gt; <span class="type">Optional</span>[ScheduleBatch]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取新的预填充批次&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 处理分块请求</span></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.chunked_req <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>.chunked_req.init_next_round_input()</span><br><span class="line">        <span class="variable language_">self</span>.chunked_req = adder.add_chunked_req(<span class="variable language_">self</span>.chunked_req)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 处理等待队列中的请求</span></span><br><span class="line">    <span class="keyword">for</span> req <span class="keyword">in</span> <span class="variable language_">self</span>.waiting_queue:</span><br><span class="line">        req.init_next_round_input(<span class="variable language_">self</span>.tree_cache)</span><br><span class="line">        res = adder.add_one_req(req, has_chunked_req=(<span class="variable language_">self</span>.chunked_req <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> res != AddReqResult.CONTINUE:</span><br><span class="line">            <span class="keyword">if</span> res == AddReqResult.NO_TOKEN:</span><br><span class="line">                <span class="variable language_">self</span>.running_batch.batch_is_full = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<h3 id="高级优化策略"><a href="#高级优化策略" class="headerlink" title="高级优化策略"></a>高级优化策略</h3><h4 id="1-调度策略优化"><a href="#1-调度策略优化" class="headerlink" title="1. 调度策略优化"></a>1. <strong>调度策略优化</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SchedulePolicy</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, policy_name, tree_cache, enable_hierarchical_cache</span>):</span><br><span class="line">        <span class="variable language_">self</span>.policy_name = policy_name</span><br><span class="line">        <span class="variable language_">self</span>.tree_cache = tree_cache</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">calc_priority</span>(<span class="params">self, waiting_queue</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;计算请求优先级&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.policy_name == <span class="string">&quot;lpm&quot;</span>:  <span class="comment"># Longest Prefix Match</span></span><br><span class="line">            <span class="variable language_">self</span>._calc_lpm_priority(waiting_queue)</span><br><span class="line">        <span class="keyword">elif</span> <span class="variable language_">self</span>.policy_name == <span class="string">&quot;fcfs&quot;</span>:  <span class="comment"># First Come First Serve</span></span><br><span class="line">            <span class="variable language_">self</span>._calc_fcfs_priority(waiting_queue)</span><br><span class="line">        <span class="keyword">elif</span> <span class="variable language_">self</span>.policy_name == <span class="string">&quot;dfs-weight&quot;</span>:  <span class="comment"># DFS with Weight</span></span><br><span class="line">            <span class="variable language_">self</span>._calc_dfs_weight_priority(waiting_queue)</span><br></pre></td></tr></table></figure>

<h4 id="2-内存抢占与回收"><a href="#2-内存抢占与回收" class="headerlink" title="2. 内存抢占与回收"></a>2. <strong>内存抢占与回收</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">update_running_batch</span>(<span class="params">self, batch: ScheduleBatch</span>) -&gt; <span class="type">Optional</span>[ScheduleBatch]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;更新运行批次，处理内存不足情况&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 检查解码内存</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> batch.check_decode_mem(<span class="variable language_">self</span>.decode_mem_cache_buf_multiplier):</span><br><span class="line">        <span class="comment"># 内存不足，回收请求</span></span><br><span class="line">        retracted_reqs, new_token_ratio = batch.retract_decode(<span class="variable language_">self</span>.server_args)</span><br><span class="line">        <span class="variable language_">self</span>.new_token_ratio = new_token_ratio</span><br><span class="line">        </span><br><span class="line">        logger.info(<span class="string">f&quot;KV cache pool is full. Retract requests. &quot;</span></span><br><span class="line">                   <span class="string">f&quot;#retracted_reqs: <span class="subst">&#123;<span class="built_in">len</span>(retracted_reqs)&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将回收的请求重新加入等待队列</span></span><br><span class="line">        <span class="variable language_">self</span>._extend_requests_to_queue(retracted_reqs, is_retracted=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h4 id="3-批次合并优化"><a href="#3-批次合并优化" class="headerlink" title="3. 批次合并优化"></a>3. <strong>批次合并优化</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mix_with_running</span>(<span class="params">self, running_batch: <span class="string">&quot;ScheduleBatch&quot;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;混合批次调度 - 预填充与解码混合&quot;&quot;&quot;</span></span><br><span class="line">    <span class="variable language_">self</span>.forward_mode = ForwardMode.MIXED</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 合并输入张量</span></span><br><span class="line">    input_ids = torch.cat([<span class="variable language_">self</span>.input_ids, running_batch.input_ids])</span><br><span class="line">    out_cache_loc = torch.cat([<span class="variable language_">self</span>.out_cache_loc, running_batch.out_cache_loc])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 合并批次状态</span></span><br><span class="line">    <span class="variable language_">self</span>.merge_batch(running_batch)</span><br><span class="line">    <span class="variable language_">self</span>.input_ids = input_ids</span><br><span class="line">    <span class="variable language_">self</span>.out_cache_loc = out_cache_loc</span><br></pre></td></tr></table></figure>

<h2 id="调度开销优化对比"><a href="#调度开销优化对比" class="headerlink" title="调度开销优化对比"></a>调度开销优化对比</h2><h3 id="1-调度算法复杂度"><a href="#1-调度算法复杂度" class="headerlink" title="1. 调度算法复杂度"></a>1. <strong>调度算法复杂度</strong></h3><table>
<thead>
<tr>
<th>框架</th>
<th>调度复杂度</th>
<th>优化策略</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td><strong>TensorRT-LLM</strong></td>
<td>O(n log n)</td>
<td>分层调度 + 预排序</td>
<td>企业级稳定性</td>
</tr>
<tr>
<td><strong>vLLM</strong></td>
<td>O(n)</td>
<td>统一调度 + 预算管理</td>
<td>简洁高效</td>
</tr>
<tr>
<td><strong>SGLang</strong></td>
<td>O(n)</td>
<td>事件驱动 + 智能缓存</td>
<td>功能全面</td>
</tr>
</tbody></table>
<h3 id="2-内存分配开销"><a href="#2-内存分配开销" class="headerlink" title="2. 内存分配开销"></a>2. <strong>内存分配开销</strong></h3><table>
<thead>
<tr>
<th>操作</th>
<th>TensorRT-LLM</th>
<th>vLLM</th>
<th>SGLang</th>
</tr>
</thead>
<tbody><tr>
<td><strong>KV Cache分配</strong></td>
<td>预分配池 + 引用计数</td>
<td>Block分配器</td>
<td>三层内存池</td>
</tr>
<tr>
<td><strong>内存回收</strong></td>
<td>延迟回收 + LRU</td>
<td>即时回收</td>
<td>批量回收</td>
</tr>
<tr>
<td><strong>内存碎片</strong></td>
<td>低（固定块大小）</td>
<td>中（动态分配）</td>
<td>低（页对齐）</td>
</tr>
</tbody></table>
<h3 id="3-调度延迟优化"><a href="#3-调度延迟优化" class="headerlink" title="3. 调度延迟优化"></a>3. <strong>调度延迟优化</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TensorRT-LLM: 分层调度减少计算开销</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CapacityScheduler</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, activeRequests</span>):</span><br><span class="line">        <span class="comment"># 1. 快速过滤不可调度请求</span></span><br><span class="line">        <span class="comment"># 2. 分层资源检查</span></span><br><span class="line">        <span class="comment"># 3. 批量分配资源</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># vLLM: 预算管理避免重复计算</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SchedulingBudget</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">can_schedule</span>(<span class="params">self, num_new_tokens, num_new_seqs</span>):</span><br><span class="line">        <span class="comment"># O(1)复杂度的资源检查</span></span><br><span class="line">        <span class="keyword">return</span> (<span class="variable language_">self</span>.num_batched_tokens + num_new_tokens &lt;= <span class="variable language_">self</span>.token_budget</span><br><span class="line">                <span class="keyword">and</span> <span class="variable language_">self</span>.num_curr_seqs + num_new_seqs &lt;= <span class="variable language_">self</span>.max_num_seqs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SGLang: 事件驱动减少轮询开销</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">event_loop_overlap</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># CPU处理与GPU计算重叠</span></span><br><span class="line">    <span class="comment"># 异步结果处理</span></span><br><span class="line">    <span class="comment"># 批次重用优化</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h2 id="性能调优策略"><a href="#性能调优策略" class="headerlink" title="性能调优策略"></a>性能调优策略</h2><h3 id="1-TensorRT-LLM调优"><a href="#1-TensorRT-LLM调优" class="headerlink" title="1. TensorRT-LLM调优"></a>1. <strong>TensorRT-LLM调优</strong></h3><h4 id="关键参数"><a href="#关键参数" class="headerlink" title="关键参数"></a>关键参数</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调度策略选择</span></span><br><span class="line">--capacity-scheduler-policy=MAX_UTILIZATION  <span class="comment"># 最大利用率</span></span><br><span class="line">--capacity-scheduler-policy=GUARANTEED_NO_EVICT  <span class="comment"># 保证不驱逐</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 批次大小调优</span></span><br><span class="line">--max-batch-size=128</span><br><span class="line">--max-num-tokens=4096</span><br><span class="line"></span><br><span class="line"><span class="comment"># 内存管理</span></span><br><span class="line">--kv-cache-percent=0.9</span><br><span class="line">--enable-kv-cache-reuse=<span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h4 id="性能监控"><a href="#性能监控" class="headerlink" title="性能监控"></a>性能监控</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 监控调度开销</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SchedulingMetrics</span> &#123;</span><br><span class="line">    <span class="type">double</span> scheduling_time_ms;</span><br><span class="line">    <span class="type">size_t</span> scheduled_requests;</span><br><span class="line">    <span class="type">size_t</span> preempted_requests;</span><br><span class="line">    <span class="type">double</span> kv_cache_hit_rate;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="2-vLLM调优"><a href="#2-vLLM调优" class="headerlink" title="2. vLLM调优"></a>2. <strong>vLLM调优</strong></h3><h4 id="关键参数-1"><a href="#关键参数-1" class="headerlink" title="关键参数"></a>关键参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用分块预填充</span></span><br><span class="line">--enable-chunked-prefill</span><br><span class="line">--<span class="built_in">max</span>-num-batched-tokens=<span class="number">2048</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 内存配置</span></span><br><span class="line">--gpu-memory-utilization=<span class="number">0.9</span></span><br><span class="line">--swap-space=<span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调度策略</span></span><br><span class="line">--scheduler-policy=priority</span><br><span class="line">--preemption-mode=recompute</span><br></pre></td></tr></table></figure>

<h4 id="性能监控-1"><a href="#性能监控-1" class="headerlink" title="性能监控"></a>性能监控</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 监控调度性能</span></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SchedulingMetrics</span>:</span><br><span class="line">    scheduling_time: <span class="built_in">float</span></span><br><span class="line">    num_preempted: <span class="built_in">int</span></span><br><span class="line">    cache_hit_rate: <span class="built_in">float</span></span><br><span class="line">    memory_utilization: <span class="built_in">float</span></span><br></pre></td></tr></table></figure>

<h3 id="3-SGLang调优"><a href="#3-SGLang调优" class="headerlink" title="3. SGLang调优"></a>3. <strong>SGLang调优</strong></h3><h4 id="关键参数-2"><a href="#关键参数-2" class="headerlink" title="关键参数"></a>关键参数</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调度策略</span></span><br><span class="line">--schedule-policy=lpm  <span class="comment"># 最长前缀匹配</span></span><br><span class="line">--schedule-conservativeness=1.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分块预填充</span></span><br><span class="line">--chunked-prefill-size=4096</span><br><span class="line">--enable-mixed-chunk</span><br><span class="line"></span><br><span class="line"><span class="comment"># 内存配置</span></span><br><span class="line">--mem-fraction-static=0.9</span><br><span class="line">--max-prefill-tokens=16384</span><br></pre></td></tr></table></figure>

<h4 id="性能监控-2"><a href="#性能监控-2" class="headerlink" title="性能监控"></a>性能监控</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实时性能监控</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PerformanceMonitor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">log_prefill_stats</span>(<span class="params">self, adder, can_run_list, running_bs</span>):</span><br><span class="line">        logger.info(<span class="string">f&quot;Prefill batch. &quot;</span></span><br><span class="line">                   <span class="string">f&quot;#new-req: <span class="subst">&#123;<span class="built_in">len</span>(can_run_list)&#125;</span>, &quot;</span></span><br><span class="line">                   <span class="string">f&quot;#new-token: <span class="subst">&#123;adder.total_token_num&#125;</span>, &quot;</span></span><br><span class="line">                   <span class="string">f&quot;#running-req: <span class="subst">&#123;running_bs&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="实现建议"><a href="#实现建议" class="headerlink" title="实现建议"></a>实现建议</h2><h3 id="1-选择合适的调度策略"><a href="#1-选择合适的调度策略" class="headerlink" title="1. 选择合适的调度策略"></a>1. <strong>选择合适的调度策略</strong></h3><h4 id="简单场景（单一模型、稳定负载）"><a href="#简单场景（单一模型、稳定负载）" class="headerlink" title="简单场景（单一模型、稳定负载）"></a>简单场景（单一模型、稳定负载）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 推荐：vLLM的简洁设计</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleScheduler</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_batch_size, max_tokens</span>):</span><br><span class="line">        <span class="variable language_">self</span>.max_batch_size = max_batch_size</span><br><span class="line">        <span class="variable language_">self</span>.max_tokens = max_tokens</span><br><span class="line">        <span class="variable language_">self</span>.budget = SchedulingBudget(max_tokens, max_batch_size)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">schedule</span>(<span class="params">self, waiting_requests</span>):</span><br><span class="line">        scheduled = []</span><br><span class="line">        <span class="keyword">for</span> req <span class="keyword">in</span> waiting_requests:</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.budget.can_schedule(req.num_tokens, <span class="number">1</span>):</span><br><span class="line">                scheduled.append(req)</span><br><span class="line">                <span class="variable language_">self</span>.budget.add_request(req)</span><br><span class="line">        <span class="keyword">return</span> scheduled</span><br></pre></td></tr></table></figure>

<h4 id="复杂场景（多模型、动态负载）"><a href="#复杂场景（多模型、动态负载）" class="headerlink" title="复杂场景（多模型、动态负载）"></a>复杂场景（多模型、动态负载）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 推荐：SGLang的事件驱动设计</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EventDrivenScheduler</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.event_queue = queue.Queue()</span><br><span class="line">        <span class="variable language_">self</span>.policy = SchedulePolicy(<span class="string">&quot;dfs-weight&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">schedule_event_loop</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            event = <span class="variable language_">self</span>.event_queue.get()</span><br><span class="line">            <span class="keyword">if</span> event.<span class="built_in">type</span> == <span class="string">&quot;new_request&quot;</span>:</span><br><span class="line">                <span class="variable language_">self</span>.handle_new_request(event.request)</span><br><span class="line">            <span class="keyword">elif</span> event.<span class="built_in">type</span> == <span class="string">&quot;request_finished&quot;</span>:</span><br><span class="line">                <span class="variable language_">self</span>.handle_finished_request(event.request)</span><br></pre></td></tr></table></figure>

<h4 id="企业级场景（高可靠性、SLA要求）"><a href="#企业级场景（高可靠性、SLA要求）" class="headerlink" title="企业级场景（高可靠性、SLA要求）"></a>企业级场景（高可靠性、SLA要求）</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 推荐：TensorRT-LLM的分层设计</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EnterpriseScheduler</span> &#123;</span><br><span class="line">    std::unique_ptr&lt;CapacityScheduler&gt; capacity_scheduler;</span><br><span class="line">    std::unique_ptr&lt;MicroBatchScheduler&gt; micro_batch_scheduler;</span><br><span class="line">    std::unique_ptr&lt;ResourceManager&gt; resource_manager;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">SchedulingResult <span class="title">schedule</span><span class="params">(<span class="type">const</span> RequestList&amp; requests)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 1. 容量调度</span></span><br><span class="line">        <span class="keyword">auto</span> [fitting_requests, paused_requests] = </span><br><span class="line">            capacity_scheduler-&gt;<span class="built_in">schedule</span>(requests);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 2. 微批调度</span></span><br><span class="line">        <span class="keyword">auto</span> [context_requests, generation_requests] = </span><br><span class="line">            micro_batch_scheduler-&gt;<span class="built_in">schedule</span>(fitting_requests);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 3. 资源分配</span></span><br><span class="line">        resource_manager-&gt;<span class="built_in">allocate_resources</span>(context_requests, generation_requests);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> &#123;context_requests, generation_requests, paused_requests&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="2-关键优化技巧"><a href="#2-关键优化技巧" class="headerlink" title="2. 关键优化技巧"></a>2. <strong>关键优化技巧</strong></h3><h4 id="减少调度开销"><a href="#减少调度开销" class="headerlink" title="减少调度开销"></a>减少调度开销</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 批次重用</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BatchReuser</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.batch_pool = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_batch</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.batch_pool.pop() <span class="keyword">if</span> <span class="variable language_">self</span>.batch_pool <span class="keyword">else</span> Batch()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">return_batch</span>(<span class="params">self, batch</span>):</span><br><span class="line">        batch.clear()</span><br><span class="line">        <span class="variable language_">self</span>.batch_pool.append(batch)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 预计算优化</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RequestPreprocessor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.token_cache = &#123;&#125;</span><br><span class="line">        <span class="variable language_">self</span>.priority_cache = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">preprocess_request</span>(<span class="params">self, request</span>):</span><br><span class="line">        <span class="comment"># 缓存tokenization结果</span></span><br><span class="line">        <span class="keyword">if</span> request.text <span class="keyword">not</span> <span class="keyword">in</span> <span class="variable language_">self</span>.token_cache:</span><br><span class="line">            <span class="variable language_">self</span>.token_cache[request.text] = <span class="variable language_">self</span>.tokenize(request.text)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 缓存优先级计算</span></span><br><span class="line">        <span class="keyword">if</span> request.<span class="built_in">id</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="variable language_">self</span>.priority_cache:</span><br><span class="line">            <span class="variable language_">self</span>.priority_cache[request.<span class="built_in">id</span>] = <span class="variable language_">self</span>.calculate_priority(request)</span><br></pre></td></tr></table></figure>

<h4 id="内存优化"><a href="#内存优化" class="headerlink" title="内存优化"></a>内存优化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3. 分层内存管理</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HierarchicalMemoryManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.l1_cache = FastMemoryPool(size=<span class="number">1024</span>*<span class="number">1024</span>*<span class="number">1024</span>)  <span class="comment"># 1GB GPU</span></span><br><span class="line">        <span class="variable language_">self</span>.l2_cache = MediumMemoryPool(size=<span class="number">4</span>*<span class="number">1024</span>*<span class="number">1024</span>*<span class="number">1024</span>)  <span class="comment"># 4GB CPU</span></span><br><span class="line">        <span class="variable language_">self</span>.l3_cache = SlowMemoryPool(size=<span class="number">16</span>*<span class="number">1024</span>*<span class="number">1024</span>*<span class="number">1024</span>)  <span class="comment"># 16GB SSD</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">allocate</span>(<span class="params">self, size</span>):</span><br><span class="line">        <span class="keyword">if</span> block := <span class="variable language_">self</span>.l1_cache.allocate(size):</span><br><span class="line">            <span class="keyword">return</span> block</span><br><span class="line">        <span class="keyword">elif</span> block := <span class="variable language_">self</span>.l2_cache.allocate(size):</span><br><span class="line">            <span class="keyword">return</span> block</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.l3_cache.allocate(size)</span><br></pre></td></tr></table></figure>

<h3 id="3-性能监控与调优"><a href="#3-性能监控与调优" class="headerlink" title="3. 性能监控与调优"></a>3. <strong>性能监控与调优</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SchedulingProfiler</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.metrics = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">profile_scheduling</span>(<span class="params">self, scheduler</span>):</span><br><span class="line">        start_time = time.time()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 调度执行</span></span><br><span class="line">        result = scheduler.schedule()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 记录指标</span></span><br><span class="line">        <span class="variable language_">self</span>.metrics[<span class="string">&#x27;scheduling_time&#x27;</span>].append(time.time() - start_time)</span><br><span class="line">        <span class="variable language_">self</span>.metrics[<span class="string">&#x27;scheduled_requests&#x27;</span>].append(<span class="built_in">len</span>(result.scheduled))</span><br><span class="line">        <span class="variable language_">self</span>.metrics[<span class="string">&#x27;memory_utilization&#x27;</span>].append(scheduler.get_memory_utilization())</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_performance_report</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;avg_scheduling_time&#x27;</span>: np.mean(<span class="variable language_">self</span>.metrics[<span class="string">&#x27;scheduling_time&#x27;</span>]),</span><br><span class="line">            <span class="string">&#x27;avg_scheduled_requests&#x27;</span>: np.mean(<span class="variable language_">self</span>.metrics[<span class="string">&#x27;scheduled_requests&#x27;</span>]),</span><br><span class="line">            <span class="string">&#x27;avg_memory_utilization&#x27;</span>: np.mean(<span class="variable language_">self</span>.metrics[<span class="string">&#x27;memory_utilization&#x27;</span>]),</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>三个框架在Continuous Batching和请求调度方面各有特色：</p>
<h3 id="架构特点"><a href="#架构特点" class="headerlink" title="架构特点"></a><strong>架构特点</strong></h3><ul>
<li><strong>TensorRT-LLM</strong>: 分层调度架构，企业级稳定性</li>
<li><strong>vLLM</strong>: 统一调度器，简洁高效</li>
<li><strong>SGLang</strong>: 事件驱动架构，功能全面</li>
</ul>
<h3 id="性能特点"><a href="#性能特点" class="headerlink" title="性能特点"></a><strong>性能特点</strong></h3><ul>
<li><strong>调度延迟</strong>: SGLang &lt; vLLM &lt; TensorRT-LLM</li>
<li><strong>内存效率</strong>: TensorRT-LLM &gt; SGLang &gt; vLLM</li>
<li><strong>扩展性</strong>: SGLang &gt; TensorRT-LLM &gt; vLLM</li>
</ul>
<h3 id="选择建议"><a href="#选择建议" class="headerlink" title="选择建议"></a><strong>选择建议</strong></h3><ol>
<li><strong>快速原型</strong>: vLLM（简洁易用）</li>
<li><strong>生产环境</strong>: TensorRT-LLM（稳定可靠）</li>
<li><strong>研究平台</strong>: SGLang（功能丰富）</li>
<li><strong>定制需求</strong>: 结合三者优势设计</li>
</ol>
<p>关键是根据具体场景选择合适的调度策略，并持续监控和优化性能指标。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/16/System/Continuous_Batching%E4%B8%8E%E8%AF%B7%E6%B1%82%E8%B0%83%E5%BA%A6%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/" data-id="cmdpf31a70014q0onfxmz6o2b" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-System/LLM_Serving_Framework_Comparison" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/14/System/LLM_Serving_Framework_Comparison/" class="article-date">
  <time class="dt-published" datetime="2025-07-14T03:21:11.628Z" itemprop="datePublished">2025-07-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="LLM-Serving-Framework-Comparison-KVCache-PrefixCache-and-Prefill-Decode-Disaggregation"><a href="#LLM-Serving-Framework-Comparison-KVCache-PrefixCache-and-Prefill-Decode-Disaggregation" class="headerlink" title="LLM Serving Framework Comparison: KVCache, PrefixCache, and Prefill-Decode-Disaggregation"></a>LLM Serving Framework Comparison: KVCache, PrefixCache, and Prefill-Decode-Disaggregation</h1><h2 id="Executive-Summary"><a href="#Executive-Summary" class="headerlink" title="Executive Summary"></a>Executive Summary</h2><p>This document provides a comprehensive analysis of three major LLM serving frameworks: <strong>TensorRT-LLM</strong>, <strong>vLLM</strong>, and <strong>SGLang</strong>, focusing on their implementations of:</p>
<ol>
<li><strong>KV Cache Management</strong> - Memory optimization for attention mechanisms</li>
<li><strong>Prefix Caching</strong> - Reuse of computed attention states for shared prefixes</li>
<li><strong>Prefill-Decode Disaggregation</strong> - Separation of prefill and decode phases for better resource utilization</li>
</ol>
<h2 id="1-KV-Cache-Management"><a href="#1-KV-Cache-Management" class="headerlink" title="1. KV Cache Management"></a>1. KV Cache Management</h2><h3 id="TensorRT-LLM-Implementation"><a href="#TensorRT-LLM-Implementation" class="headerlink" title="TensorRT-LLM Implementation"></a>TensorRT-LLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>kvCacheManager.cpp</code>, <code>kvCacheEventManager.cpp</code>, <code>allocateKvCache.cpp</code></li>
<li><strong>Block-based memory management</strong> with configurable block sizes (16, 32, 64, 128 tokens)</li>
<li><strong>Multi-level cache system</strong> with primary GPU memory and secondary CPU memory for offloading</li>
<li><strong>Paged attention</strong> with TensorRT kernel optimizations</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Hash-based block identification for efficient lookups</li>
<li>Reference counting for memory safety</li>
<li>Priority-based LRU eviction with retention policies</li>
<li>Multi-pool architecture for different KV head configurations</li>
<li>Quantization support (FP8, INT4, AWQ, GPTQ) for memory efficiency</li>
<li>Thread-safe operations with mutex&#x2F;condition variable synchronization</li>
</ul>
<p><strong>Memory Management:</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Block management with priority-based eviction</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BlockManager</span> &#123;</span><br><span class="line">    std::unordered_map&lt;BlockHash, BlockId&gt; cached_blocks;</span><br><span class="line">    std::vector&lt;BlockPool&gt; pools_by_config;</span><br><span class="line">    LRUEvictionPolicy eviction_policy;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="vLLM-Implementation"><a href="#vLLM-Implementation" class="headerlink" title="vLLM Implementation"></a>vLLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>core/block_manager.py</code>, <code>core/block/prefix_caching_block.py</code>, <code>attention/layer.py</code></li>
<li><strong>BlockSpaceManager</strong> for centralized memory allocation</li>
<li><strong>Prefix-aware block allocation</strong> with copy-on-write semantics</li>
<li><strong>Lookahead slots</strong> for speculative decoding support</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Unified block management for both regular and prefix-cached blocks</li>
<li>Sliding window attention support</li>
<li>Advanced scheduling integration with memory-aware allocation</li>
<li>Support for both CPU and GPU memory pools</li>
<li>Seamless integration with attention backends (FlashAttention, etc.)</li>
</ul>
<p><strong>Memory Management:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SelfAttnBlockSpaceManager</span>(<span class="title class_ inherited__">BlockSpaceManager</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block_size: <span class="built_in">int</span>, num_gpu_blocks: <span class="built_in">int</span>, num_cpu_blocks: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.block_allocator = CpuGpuBlockAllocator(...)</span><br><span class="line">        <span class="variable language_">self</span>.block_tables = &#123;&#125;  <span class="comment"># seq_id -&gt; BlockTable</span></span><br></pre></td></tr></table></figure>

<h3 id="SGLang-Implementation"><a href="#SGLang-Implementation" class="headerlink" title="SGLang Implementation"></a>SGLang Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>mem_cache/memory_pool.py</code>, <code>mem_cache/radix_cache.py</code>, <code>mem_cache/swa_radix_cache.py</code></li>
<li><strong>Three-tier memory pool system</strong>: ReqToTokenPool → TokenToKVPoolAllocator → KVCache</li>
<li><strong>RadixAttention</strong> with tree-based prefix sharing</li>
<li><strong>Sliding Window Attention (SWA)</strong> with hybrid full&#x2F;SWA cache management</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Most sophisticated memory hierarchy with multiple abstraction levels</li>
<li>Native support for different attention mechanisms (MHA, MLA, SWA)</li>
<li>Advanced eviction policies with LRU lists and tombstone mechanisms</li>
<li>Host memory backup for cache persistence</li>
<li>Specialized kernels for different hardware (CUDA, Ascend NPU)</li>
</ul>
<p><strong>Memory Management:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReqToTokenPool</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Maps requests to token locations&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TokenToKVPoolAllocator</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Manages KV cache indices&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KVCache</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Physical KV cache storage&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="2-Prefix-Caching"><a href="#2-Prefix-Caching" class="headerlink" title="2. Prefix Caching"></a>2. Prefix Caching</h2><h3 id="TensorRT-LLM-Implementation-1"><a href="#TensorRT-LLM-Implementation-1" class="headerlink" title="TensorRT-LLM Implementation"></a>TensorRT-LLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Hash-based prefix identification</strong> using <code>BlockKeyHasher::hash()</code></li>
<li><strong>Radix tree structure</strong> for hierarchical prefix organization</li>
<li><strong>Partial block reuse</strong> with configurable granularity</li>
<li><strong>Cache hit rate tracking</strong> for performance monitoring</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Block-level prefix matching with configurable page sizes</li>
<li>Copy-on-write semantics for memory efficiency</li>
<li>Sophisticated cache replacement policies</li>
<li>Integration with dynamic profiling for optimization</li>
</ul>
<p><strong>Prefix Matching:</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BlockKeyHasher</span> &#123;</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">uint64_t</span> <span class="title">hash</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">int</span>&gt;&amp; tokens, <span class="type">int</span> extra_hash = <span class="number">0</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">bool</span> <span class="title">matches</span><span class="params">(<span class="type">const</span> BlockKey&amp; key1, <span class="type">const</span> BlockKey&amp; key2)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="vLLM-Implementation-1"><a href="#vLLM-Implementation-1" class="headerlink" title="vLLM Implementation"></a>vLLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>core/block/prefix_caching_block.py</code>, <code>core/block/cpu_gpu_block_allocator.py</code></li>
<li><strong>PrefixCachingBlockAllocator</strong> with content-hash based caching</li>
<li><strong>ComputedBlocksTracker</strong> for managing computed state</li>
<li><strong>Comprehensive prefix cache APIs</strong> across the engine</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Content-based hashing for reliable prefix identification</li>
<li>Immutable vs mutable block distinction</li>
<li>Extensive prefix cache hit rate monitoring</li>
<li>API endpoints for cache management (<code>/reset_prefix_cache</code>)</li>
<li>Integration with speculative decoding</li>
</ul>
<p><strong>Prefix Cache Management:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrefixCachingBlockAllocator</span>(<span class="title class_ inherited__">BlockAllocator</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_blocks: <span class="built_in">int</span>, block_size: <span class="built_in">int</span>, eviction_policy: EvictionPolicy</span>):</span><br><span class="line">        <span class="variable language_">self</span>._cached_blocks: <span class="type">Dict</span>[PrefixHash, BlockId] = &#123;&#125;</span><br><span class="line">        <span class="variable language_">self</span>._touched_blocks: <span class="type">Set</span>[BlockId] = <span class="built_in">set</span>()</span><br><span class="line">        <span class="variable language_">self</span>._block_tracker: <span class="type">Dict</span>[BlockId, BlockTracker] = &#123;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="SGLang-Implementation-1"><a href="#SGLang-Implementation-1" class="headerlink" title="SGLang Implementation"></a>SGLang Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>mem_cache/radix_cache.py</code>, <code>mem_cache/swa_radix_cache.py</code>, <code>mem_cache/hiradix_cache.py</code></li>
<li><strong>RadixCache</strong> with tree-based prefix sharing</li>
<li><strong>SWARadixCache</strong> for sliding window attention</li>
<li><strong>HiRadixCache</strong> for hierarchical caching</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Most advanced prefix caching with multiple cache types</li>
<li>Tree-based prefix sharing with automatic splitting&#x2F;merging</li>
<li>Support for different page sizes and sliding window configurations</li>
<li>Host memory backup for prefix persistence</li>
<li>Event-driven cache management for disaggregated scenarios</li>
</ul>
<p><strong>Radix Tree Implementation:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TreeNode</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.children = defaultdict(TreeNode)</span><br><span class="line">        <span class="variable language_">self</span>.parent: TreeNode = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.key: <span class="type">List</span>[<span class="built_in">int</span>] = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.value: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.lock_ref = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.last_access_time = time.monotonic()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RadixCache</span>(<span class="title class_ inherited__">BasePrefixCache</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">match_prefix</span>(<span class="params">self, key: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; MatchResult:</span><br><span class="line">        <span class="comment"># Tree traversal for prefix matching</span></span><br></pre></td></tr></table></figure>

<h2 id="3-Prefill-Decode-Disaggregation"><a href="#3-Prefill-Decode-Disaggregation" class="headerlink" title="3. Prefill-Decode Disaggregation"></a>3. Prefill-Decode Disaggregation</h2><h3 id="TensorRT-LLM-Implementation-2"><a href="#TensorRT-LLM-Implementation-2" class="headerlink" title="TensorRT-LLM Implementation"></a>TensorRT-LLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>trtGptModelInflightBatching.cpp</code>, <code>dataTransceiverImpl.cpp</code>, <code>cacheTransBuffer.cpp</code></li>
<li><strong>Separate context and generation phases</strong> in model execution</li>
<li><strong>KV cache transfer protocols</strong> for distributed serving</li>
<li><strong>Layer-wise disaggregation</strong> with selective transfer</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Production-ready disaggregation with robust error handling</li>
<li>Optimized cache transfer with bandwidth reduction</li>
<li>Async&#x2F;sync transfer modes with overlap capabilities</li>
<li>Comprehensive metrics and benchmarking support</li>
<li>Integration with TensorRT’s dynamic profiling</li>
</ul>
<p><strong>Cache Transfer:</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CacheTransBuffer</span> &#123;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">transferKVCache</span><span class="params">(LayerId layer, <span class="type">const</span> KVData&amp; data, TransferMode mode)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">waitForTransfer</span><span class="params">(LayerId layer)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">isTransferComplete</span><span class="params">(LayerId layer)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="vLLM-Implementation-2"><a href="#vLLM-Implementation-2" class="headerlink" title="vLLM Implementation"></a>vLLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>distributed/kv_transfer/</code>, <code>examples/online_serving/disaggregated_serving/</code></li>
<li><strong>Disaggregated serving examples</strong> with prefill&#x2F;decode separation</li>
<li><strong>KV transfer protocols</strong> for distributed deployment</li>
<li><strong>Proxy-based routing</strong> between prefill and decode instances</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Reference implementations and examples</li>
<li>Support for different transfer backends (NCCL, gRPC)</li>
<li>Integration with existing vLLM scheduling</li>
<li>Experimental disaggregation features</li>
<li>Focus on ease of deployment and configuration</li>
</ul>
<p><strong>Disaggregated Architecture:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Prefill instance handles context processing</span></span><br><span class="line">prefill_instance = vLLM(model_path, instance_type=<span class="string">&quot;prefill&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decode instance handles generation</span></span><br><span class="line">decode_instance = vLLM(model_path, instance_type=<span class="string">&quot;decode&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Proxy routes requests between instances</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DisaggregatedProxy</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">route_request</span>(<span class="params">self, request</span>):</span><br><span class="line">        <span class="comment"># Route to appropriate instance</span></span><br></pre></td></tr></table></figure>

<h3 id="SGLang-Implementation-2"><a href="#SGLang-Implementation-2" class="headerlink" title="SGLang Implementation"></a>SGLang Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>disaggregation/prefill.py</code>, <code>disaggregation/decode.py</code>, <code>disaggregation/utils.py</code></li>
<li><strong>Comprehensive disaggregation framework</strong> with multiple backends</li>
<li><strong>Advanced queue management</strong> for different phases</li>
<li><strong>Sophisticated KV transfer protocols</strong></li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Most comprehensive disaggregation implementation</li>
<li>Support for multiple transfer backends (NIXL, Mooncake, etc.)</li>
<li>Advanced queue management with bootstrap, transfer, and inflight phases</li>
<li>Extensive metadata management for distributed coordination</li>
<li>Integration with RadixAttention for efficient prefix sharing</li>
</ul>
<p><strong>Disaggregation Architecture:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrefillBootstrapQueue</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Bootstrap queue for prefill requests&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecodePreallocQueue</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Pre-allocation queue for decode requests&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecodeTransferQueue</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Transfer queue for KV data&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BaseKVManager</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Abstract base for KV transfer management&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="4-Technical-Comparison-Summary"><a href="#4-Technical-Comparison-Summary" class="headerlink" title="4. Technical Comparison Summary"></a>4. Technical Comparison Summary</h2><h3 id="Performance-Characteristics"><a href="#Performance-Characteristics" class="headerlink" title="Performance Characteristics"></a>Performance Characteristics</h3><table>
<thead>
<tr>
<th>Feature</th>
<th>TensorRT-LLM</th>
<th>vLLM</th>
<th>SGLang</th>
</tr>
</thead>
<tbody><tr>
<td><strong>KV Cache Efficiency</strong></td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
</tr>
<tr>
<td><strong>Prefix Cache Hit Rate</strong></td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
</tr>
<tr>
<td><strong>Disaggregation Maturity</strong></td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
</tr>
<tr>
<td><strong>Memory Efficiency</strong></td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
</tr>
<tr>
<td><strong>Scalability</strong></td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
</tr>
</tbody></table>
<h3 id="Implementation-Complexity"><a href="#Implementation-Complexity" class="headerlink" title="Implementation Complexity"></a>Implementation Complexity</h3><table>
<thead>
<tr>
<th>Aspect</th>
<th>TensorRT-LLM</th>
<th>vLLM</th>
<th>SGLang</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Codebase Size</strong></td>
<td>Large (C++)</td>
<td>Medium (Python)</td>
<td>Large (Python)</td>
</tr>
<tr>
<td><strong>Architecture</strong></td>
<td>Monolithic</td>
<td>Modular</td>
<td>Highly Modular</td>
</tr>
<tr>
<td><strong>Extensibility</strong></td>
<td>Medium</td>
<td>High</td>
<td>Very High</td>
</tr>
<tr>
<td><strong>Documentation</strong></td>
<td>Good</td>
<td>Excellent</td>
<td>Good</td>
</tr>
<tr>
<td><strong>Community</strong></td>
<td>NVIDIA</td>
<td>Very Active</td>
<td>Growing</td>
</tr>
</tbody></table>
<h3 id="Use-Case-Recommendations"><a href="#Use-Case-Recommendations" class="headerlink" title="Use Case Recommendations"></a>Use Case Recommendations</h3><p><strong>TensorRT-LLM:</strong></p>
<ul>
<li>✅ Production deployments requiring maximum performance</li>
<li>✅ NVIDIA GPU-centric environments</li>
<li>✅ Applications needing quantization support</li>
<li>✅ Enterprise deployments with dedicated DevOps teams</li>
</ul>
<p><strong>vLLM:</strong></p>
<ul>
<li>✅ Research and development environments</li>
<li>✅ Rapid prototyping and experimentation</li>
<li>✅ Multi-GPU deployments with good Python ecosystem integration</li>
<li>✅ Applications requiring extensive customization</li>
</ul>
<p><strong>SGLang:</strong></p>
<ul>
<li>✅ Advanced research requiring cutting-edge optimizations</li>
<li>✅ Applications with complex attention patterns (sliding window, etc.)</li>
<li>✅ Disaggregated deployments with sophisticated requirements</li>
<li>✅ Multi-modal and structured generation tasks</li>
</ul>
<h2 id="5-Key-Insights-and-Recommendations"><a href="#5-Key-Insights-and-Recommendations" class="headerlink" title="5. Key Insights and Recommendations"></a>5. Key Insights and Recommendations</h2><h3 id="Architecture-Insights"><a href="#Architecture-Insights" class="headerlink" title="Architecture Insights"></a>Architecture Insights</h3><ol>
<li><strong>SGLang</strong> shows the most sophisticated approach to memory management with its three-tier system and multiple cache types</li>
<li><strong>TensorRT-LLM</strong> provides the most production-ready disaggregation with robust error handling and performance optimization</li>
<li><strong>vLLM</strong> offers the best balance of features and usability for most deployment scenarios</li>
</ol>
<h3 id="Performance-Considerations"><a href="#Performance-Considerations" class="headerlink" title="Performance Considerations"></a>Performance Considerations</h3><ol>
<li><strong>Memory Efficiency</strong>: SGLang &gt; TensorRT-LLM &gt; vLLM</li>
<li><strong>Prefix Cache Effectiveness</strong>: SGLang ≈ TensorRT-LLM &gt; vLLM</li>
<li><strong>Disaggregation Maturity</strong>: TensorRT-LLM ≈ SGLang &gt; vLLM</li>
<li><strong>Deployment Simplicity</strong>: vLLM &gt; SGLang &gt; TensorRT-LLM</li>
</ol>
<h3 id="Future-Trends"><a href="#Future-Trends" class="headerlink" title="Future Trends"></a>Future Trends</h3><ol>
<li><strong>Convergence</strong>: All frameworks are evolving toward similar architectural patterns</li>
<li><strong>Specialization</strong>: Each framework is developing unique strengths for different use cases</li>
<li><strong>Integration</strong>: Increasing focus on multi-modal and structured generation capabilities</li>
<li><strong>Hardware Optimization</strong>: Growing emphasis on hardware-specific optimizations</li>
</ol>
<h2 id="6-Conclusion"><a href="#6-Conclusion" class="headerlink" title="6. Conclusion"></a>6. Conclusion</h2><p>All three frameworks represent significant advances in LLM serving technology, each with distinct strengths:</p>
<ul>
<li><strong>TensorRT-LLM</strong> excels in production-ready performance optimization and NVIDIA ecosystem integration</li>
<li><strong>vLLM</strong> provides the best developer experience and community support for most use cases</li>
<li><strong>SGLang</strong> pushes the boundaries of what’s possible with advanced memory management and disaggregation</li>
</ul>
<p>The choice between frameworks should be based on specific requirements: performance needs, deployment complexity, hardware constraints, and team expertise. For most applications, vLLM provides the best starting point, while TensorRT-LLM offers maximum performance for production deployments, and SGLang enables cutting-edge research and advanced optimizations. </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/14/System/LLM_Serving_Framework_Comparison/" data-id="cmdpf31ah001rq0oneg6j9as4" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-System/LLM_KVCache_详细分析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/14/System/LLM_KVCache_%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2025-07-14T03:21:11.624Z" itemprop="datePublished">2025-07-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="LLM-Serving-Framework-KV-Cache-管理机制详细分析"><a href="#LLM-Serving-Framework-KV-Cache-管理机制详细分析" class="headerlink" title="LLM Serving Framework KV Cache 管理机制详细分析"></a>LLM Serving Framework KV Cache 管理机制详细分析</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li><a href="#%E6%A6%82%E8%BF%B0">概述</a></li>
<li><a href="#tensorrt-llm-kv-cache-%E7%AE%A1%E7%90%86">TensorRT-LLM KV Cache 管理</a></li>
<li><a href="#vllm-kv-cache-%E7%AE%A1%E7%90%86">vLLM KV Cache 管理</a>  </li>
<li><a href="#sglang-kv-cache-%E7%AE%A1%E7%90%86">SGLang KV Cache 管理</a></li>
<li><a href="#%E6%8A%80%E6%9C%AF%E5%AF%B9%E6%AF%94%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90">技术对比与深度分析</a></li>
<li><a href="#%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5">性能优化策略</a></li>
<li><a href="#%E6%80%BB%E7%BB%93%E4%B8%8E%E5%BB%BA%E8%AE%AE">总结与建议</a></li>
</ol>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>KV Cache是大语言模型推理中最关键的优化技术之一，它通过缓存attention机制中的Key和Value张量来避免重复计算，显著提升推理性能。本文深入分析TensorRT-LLM、vLLM和SGLang三个主流LLM serving框架的KV Cache管理实现。</p>
<h3 id="KV-Cache基本原理"><a href="#KV-Cache基本原理" class="headerlink" title="KV Cache基本原理"></a>KV Cache基本原理</h3><p>在Transformer架构中，每个attention层都需要计算Q、K、V三个矩阵：</p>
<ul>
<li><strong>Query (Q)</strong>: 当前token的查询向量</li>
<li><strong>Key (K)</strong>: 所有token的键向量  </li>
<li><strong>Value (V)</strong>: 所有token的值向量</li>
</ul>
<p>KV Cache的核心思想是：</p>
<ol>
<li><strong>缓存已计算的K、V</strong>: 避免重复计算历史token的K、V</li>
<li><strong>增量更新</strong>: 只计算新token的K、V并追加到缓存</li>
<li><strong>内存复用</strong>: 通过block管理和prefix sharing减少内存占用</li>
</ol>
<h2 id="TensorRT-LLM-KV-Cache-管理"><a href="#TensorRT-LLM-KV-Cache-管理" class="headerlink" title="TensorRT-LLM KV Cache 管理"></a>TensorRT-LLM KV Cache 管理</h2><h3 id="整体架构设计"><a href="#整体架构设计" class="headerlink" title="整体架构设计"></a>整体架构设计</h3><p>TensorRT-LLM采用<strong>分层block管理架构</strong>，具有以下核心组件：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 核心类层次结构</span></span><br><span class="line">KVCacheManager</span><br><span class="line">├── BlockManager</span><br><span class="line">│   └── <span class="built_in">WindowBlockManager</span> (多个，按window size分组)</span><br><span class="line">│       ├── <span class="built_in">KVCacheBlockPool</span> (内存池)</span><br><span class="line">│       ├── <span class="built_in">LRUEvictionPolicy</span> (驱逐策略)</span><br><span class="line">│       └── <span class="built_in">KVCacheTransferManager</span> (传输管理)</span><br><span class="line">├── <span class="built_in">KVCacheEventManager</span> (事件管理)</span><br><span class="line">└── <span class="built_in">AllocateKvCache</span> (分配策略)</span><br></pre></td></tr></table></figure>

<h3 id="1-Block管理机制"><a href="#1-Block管理机制" class="headerlink" title="1. Block管理机制"></a>1. Block管理机制</h3><h4 id="Block数据结构"><a href="#Block数据结构" class="headerlink" title="Block数据结构"></a>Block数据结构</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KVCacheBlock</span> &#123;</span><br><span class="line">    IdType mBlockId;                    <span class="comment">// 块ID</span></span><br><span class="line">    tk::KVCacheIndex mMemoryPoolBlockIndex; <span class="comment">// 内存池索引</span></span><br><span class="line">    <span class="type">int32_t</span> mRefCount;                  <span class="comment">// 引用计数</span></span><br><span class="line">    <span class="type">int32_t</span> mSchedulingRefCount;        <span class="comment">// 调度引用计数</span></span><br><span class="line">    BlockPtr mPrevBlock;                <span class="comment">// 前驱块指针</span></span><br><span class="line">    NextBlockMap mNextBlocks;           <span class="comment">// 后继块映射</span></span><br><span class="line">    <span class="type">bool</span> mIsFull;                       <span class="comment">// 是否已满</span></span><br><span class="line">    executor::RetentionPriority mPriority; <span class="comment">// 优先级</span></span><br><span class="line">    std::optional&lt;std::chrono::milliseconds&gt; mDurationMs; <span class="comment">// 持续时间</span></span><br><span class="line">    <span class="type">size_t</span> mHash;                       <span class="comment">// 哈希值</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="Block分配策略"><a href="#Block分配策略" class="headerlink" title="Block分配策略"></a>Block分配策略</h4><ol>
<li><strong>分池管理</strong>: 根据KV head数量分组，相同配置的layer共享池</li>
<li><strong>优先级分配</strong>: 支持设置block优先级和过期时间</li>
<li><strong>引用计数</strong>: 精确跟踪block使用情况，支持共享和释放</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Block分配核心逻辑</span></span><br><span class="line"><span class="function">BlockPtr <span class="title">WindowBlockManager::getFreeBlock</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    executor::RetentionPriority priority, </span></span></span><br><span class="line"><span class="params"><span class="function">    std::optional&lt;std::chrono::milliseconds&gt; durationMs)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 1. 从驱逐策略获取空闲block</span></span><br><span class="line">    <span class="keyword">auto</span> [block, canOffload] = mEvictionPolicy-&gt;<span class="built_in">getFreeBlock</span>(kPrimaryLevel);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 2. 如果需要，执行offload到secondary memory</span></span><br><span class="line">    <span class="keyword">if</span> (!block-&gt;<span class="built_in">getUniqueTokens</span>().<span class="built_in">empty</span>() &amp;&amp; canOffload &amp;&amp; </span><br><span class="line">        mEvictionPolicy-&gt;<span class="built_in">getNumFreeBlocks</span>(kSecondaryLevel) &gt; <span class="number">0</span> &amp;&amp; mOnboardBlocks) &#123;</span><br><span class="line">        <span class="keyword">auto</span> offloadBlock = std::<span class="built_in">get</span>&lt;<span class="number">0</span>&gt;(mEvictionPolicy-&gt;<span class="built_in">getFreeBlock</span>(kSecondaryLevel));</span><br><span class="line">        mTransferManager-&gt;<span class="built_in">offload</span>(block, offloadBlock, mPools);</span><br><span class="line">        block-&gt;<span class="built_in">swapMemoryPoolBlockOffset</span>(offloadBlock);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> block;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-内存池管理"><a href="#2-内存池管理" class="headerlink" title="2. 内存池管理"></a>2. 内存池管理</h3><h4 id="分层内存设计"><a href="#分层内存设计" class="headerlink" title="分层内存设计"></a>分层内存设计</h4><ul>
<li><strong>Primary Pool</strong>: GPU快速内存，用于活跃block</li>
<li><strong>Secondary Pool</strong>: CPU较慢内存，用于offload</li>
<li><strong>Block Pool</strong>: 按layer配置分组的物理内存</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KVCacheBlockPool</span> &#123;</span><br><span class="line">    SizeType32 numLayers;           <span class="comment">// layer数量</span></span><br><span class="line">    SizeType32 kvFactor;            <span class="comment">// KV因子(通常为2，K和V)</span></span><br><span class="line">    SizeType32 numKvHeads;          <span class="comment">// KV head数量</span></span><br><span class="line">    SizeType32 tokensPerBlock;      <span class="comment">// 每个block的token数</span></span><br><span class="line">    runtime::ITensor::SharedPtr primaryPtr;   <span class="comment">// 主内存池</span></span><br><span class="line">    runtime::ITensor::SharedPtr secondaryPtr; <span class="comment">// 辅助内存池</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="内存分配流程"><a href="#内存分配流程" class="headerlink" title="内存分配流程"></a>内存分配流程</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">WindowBlockManager::allocatePools</span><span class="params">(<span class="type">bool</span> useUvm)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; pool : mPools) &#123;</span><br><span class="line">        <span class="comment">// 计算block大小</span></span><br><span class="line">        <span class="keyword">auto</span> blockSize = pool.blockSize;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 主内存池分配 - 形状: [num_blocks, num_layers, kv_factor, block_size]</span></span><br><span class="line">        nvinfer1::Dims cacheShape = ITensor::<span class="built_in">makeShape</span>(</span><br><span class="line">            &#123;mNumPrimaryBlocks, pool.numLayers, mKVFactor, blockSize&#125;);</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> (useUvm)</span><br><span class="line">            pool.primaryPtr = BufferManager::<span class="built_in">managed</span>(cacheShape, poolDtype);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            pool.primaryPtr = mBufferManager.<span class="built_in">gpuSync</span>(cacheShape, poolDtype);</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 辅助内存池分配</span></span><br><span class="line">        <span class="keyword">if</span> (mNumSecondaryBlocks &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            nvinfer1::Dims cacheShapeOffload = ITensor::<span class="built_in">makeShape</span>(</span><br><span class="line">                &#123;mNumSecondaryBlocks, pool.numLayers, mKVFactor, blockSize&#125;);</span><br><span class="line">            pool.secondaryPtr = BufferManager::<span class="built_in">pinned</span>(cacheShapeOffload, poolDtype);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-哈希与缓存复用"><a href="#3-哈希与缓存复用" class="headerlink" title="3. 哈希与缓存复用"></a>3. 哈希与缓存复用</h3><h4 id="高性能哈希算法"><a href="#高性能哈希算法" class="headerlink" title="高性能哈希算法"></a>高性能哈希算法</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">size_t</span> <span class="title">BlockKeyHasher::hash</span><span class="params">(BlockKey <span class="type">const</span>&amp; blockKey, std::<span class="type">size_t</span> parentHash)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="type">size_t</span> seed = blockKey.uniqueTokens.<span class="built_in">size</span>() ^ parentHash * <span class="built_in">UINT64_C</span>(<span class="number">0xbf58476d1ce4e5b9</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> <span class="type">const</span>&amp; uniqueToken : blockKey.uniqueTokens) &#123;</span><br><span class="line">        <span class="comment">// 使用Wang hash算法优化token ID哈希</span></span><br><span class="line">        <span class="type">uint32_t</span> a = <span class="built_in">static_cast</span>&lt;<span class="type">uint32_t</span>&gt;(uniqueToken.tokenId);</span><br><span class="line">        a = ((a &gt;&gt; <span class="number">16</span>) ^ a) * <span class="number">0x45d9f3b</span>;</span><br><span class="line">        a = ((a &gt;&gt; <span class="number">16</span>) ^ a) * <span class="number">0x45d9f3b</span>; </span><br><span class="line">        a = (a &gt;&gt; <span class="number">16</span>) ^ a;</span><br><span class="line">        seed ^= a + <span class="number">0x9e3779b9</span> + (seed &lt;&lt; <span class="number">6</span>) + (seed &gt;&gt; <span class="number">2</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 处理额外ID（如LoRA task ID）</span></span><br><span class="line">        <span class="keyword">if</span> (blockKey.usesExtraIds) &#123;</span><br><span class="line">            <span class="type">uint64_t</span> b = uniqueToken.tokenExtraId;</span><br><span class="line">            <span class="comment">// 64位哈希处理...</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> seed;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-驱逐策略"><a href="#4-驱逐策略" class="headerlink" title="4. 驱逐策略"></a>4. 驱逐策略</h3><h4 id="LRU驱逐算法"><a href="#LRU驱逐算法" class="headerlink" title="LRU驱逐算法"></a>LRU驱逐算法</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LRUEvictionPolicy</span> &#123;</span><br><span class="line">    <span class="comment">// 分优先级的队列结构</span></span><br><span class="line">    std::vector&lt;std::vector&lt;FreeBlocksQueue&gt;&gt; mFreeQueues; <span class="comment">// [cache_level][priority]</span></span><br><span class="line">    std::vector&lt;std::unordered_set&lt;SizeType32&gt;&gt; mReleasedBlocks;</span><br><span class="line">    std::vector&lt;SizeType32&gt; mNumFreeBlocksPerLevel;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取空闲block</span></span><br><span class="line">    <span class="function">std::tuple&lt;BlockPtr, <span class="type">bool</span>&gt; <span class="title">getFreeBlock</span><span class="params">(SizeType32 level)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 按优先级顺序查找空闲block</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> priority = kMinPriority; priority &lt;= kMaxPriority; ++priority) &#123;</span><br><span class="line">            <span class="keyword">auto</span>&amp; freeQueue = mFreeQueues[level][<span class="built_in">getPriorityIdx</span>(priority)];</span><br><span class="line">            <span class="keyword">if</span> (!freeQueue.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                <span class="keyword">auto</span> block = freeQueue.<span class="built_in">front</span>();</span><br><span class="line">                freeQueue.<span class="built_in">pop_front</span>();</span><br><span class="line">                <span class="keyword">return</span> &#123;block, <span class="literal">true</span>&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="literal">nullptr</span>, <span class="literal">false</span>&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="vLLM-KV-Cache-管理"><a href="#vLLM-KV-Cache-管理" class="headerlink" title="vLLM KV Cache 管理"></a>vLLM KV Cache 管理</h2><h3 id="整体架构设计-1"><a href="#整体架构设计-1" class="headerlink" title="整体架构设计"></a>整体架构设计</h3><p>vLLM采用<strong>模块化block分配架构</strong>，核心设计理念是简洁性和可扩展性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 核心类层次结构  </span></span><br><span class="line">SelfAttnBlockSpaceManager</span><br><span class="line">├── CpuGpuBlockAllocator</span><br><span class="line">│   ├── PrefixCachingBlockAllocator (GPU)</span><br><span class="line">│   └── PrefixCachingBlockAllocator (CPU)</span><br><span class="line">├── ComputedBlocksTracker (prefix缓存跟踪)</span><br><span class="line">└── LastAccessBlocksTracker (访问时间跟踪)</span><br></pre></td></tr></table></figure>

<h3 id="1-Block分配器设计"><a href="#1-Block分配器设计" class="headerlink" title="1. Block分配器设计"></a>1. Block分配器设计</h3><h4 id="设备感知分配器"><a href="#设备感知分配器" class="headerlink" title="设备感知分配器"></a>设备感知分配器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CpuGpuBlockAllocator</span>(<span class="title class_ inherited__">DeviceAwareBlockAllocator</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cpu_block_allocator: BlockAllocator, </span></span><br><span class="line"><span class="params">                 gpu_block_allocator: BlockAllocator</span>):</span><br><span class="line">        <span class="variable language_">self</span>._allocators = &#123;</span><br><span class="line">            Device.CPU: cpu_block_allocator,</span><br><span class="line">            Device.GPU: gpu_block_allocator,</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="variable language_">self</span>._swap_mapping: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">int</span>] = &#123;&#125;  <span class="comment"># CPU-GPU交换映射</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">allocate_mutable_block</span>(<span class="params">self, prev_block: <span class="type">Optional</span>[Block], </span></span><br><span class="line"><span class="params">                              device: Device, extra_hash: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span></span>) -&gt; Block:</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._allocators[device].allocate_mutable_block(prev_block, extra_hash=extra_hash)</span><br></pre></td></tr></table></figure>

<h4 id="PrefixCaching分配器"><a href="#PrefixCaching分配器" class="headerlink" title="PrefixCaching分配器"></a>PrefixCaching分配器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrefixCachingBlockAllocator</span>(<span class="title class_ inherited__">BlockAllocator</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_blocks: <span class="built_in">int</span>, block_size: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 eviction_policy: EvictionPolicy = EvictionPolicy.LRU</span>):</span><br><span class="line">        <span class="comment"># prefix hash到block ID的映射</span></span><br><span class="line">        <span class="variable language_">self</span>._cached_blocks: <span class="type">Dict</span>[PrefixHash, BlockId] = &#123;&#125;</span><br><span class="line">        <span class="comment"># 被调度器触及的不可变block ID集合</span></span><br><span class="line">        <span class="variable language_">self</span>._touched_blocks: <span class="type">Set</span>[BlockId] = <span class="built_in">set</span>()</span><br><span class="line">        <span class="comment"># 每个物理block ID的状态跟踪</span></span><br><span class="line">        <span class="variable language_">self</span>._block_tracker: <span class="type">Dict</span>[BlockId, BlockTracker] = &#123;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-Block生命周期管理"><a href="#2-Block生命周期管理" class="headerlink" title="2. Block生命周期管理"></a>2. Block生命周期管理</h3><h4 id="Block状态跟踪"><a href="#Block状态跟踪" class="headerlink" title="Block状态跟踪"></a>Block状态跟踪</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BlockTracker</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.active: <span class="built_in">bool</span> = <span class="literal">False</span>           <span class="comment"># 是否活跃</span></span><br><span class="line">        <span class="variable language_">self</span>.last_accessed: <span class="built_in">float</span> = -<span class="number">1</span>      <span class="comment"># 最后访问时间</span></span><br><span class="line">        <span class="variable language_">self</span>.computed: <span class="built_in">bool</span> = <span class="literal">False</span>         <span class="comment"># 是否已计算</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">enable</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.active = <span class="literal">True</span></span><br><span class="line">        <span class="variable language_">self</span>.reset()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.last_accessed = _DEFAULT_LAST_ACCESSED_TIME</span><br><span class="line">        <span class="variable language_">self</span>.computed = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h4 id="Immutable-vs-Mutable-Block"><a href="#Immutable-vs-Mutable-Block" class="headerlink" title="Immutable vs Mutable Block"></a>Immutable vs Mutable Block</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">allocate_immutable_block</span>(<span class="params">self, prev_block: <span class="type">Optional</span>[Block], </span></span><br><span class="line"><span class="params">                           token_ids: <span class="type">List</span>[<span class="built_in">int</span>], extra_hash: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span></span>) -&gt; Block:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;分配不可变block用于prefix caching&quot;&quot;&quot;</span></span><br><span class="line">    block = <span class="variable language_">self</span>._create_block(prev_block, token_ids, <span class="variable language_">self</span>._block_size, </span><br><span class="line">                              <span class="variable language_">self</span>, computed=<span class="literal">True</span>, extra_hash=extra_hash)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 检查是否已缓存</span></span><br><span class="line">    <span class="keyword">if</span> block.content_hash <span class="keyword">in</span> <span class="variable language_">self</span>._cached_blocks:</span><br><span class="line">        cached_block_id = <span class="variable language_">self</span>._cached_blocks[block.content_hash]</span><br><span class="line">        <span class="variable language_">self</span>._incr_refcount_cached_block(<span class="variable language_">self</span>._blocks[cached_block_id])</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._blocks[cached_block_id]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分配新block</span></span><br><span class="line">    <span class="variable language_">self</span>._cached_blocks[block.content_hash] = block.block_id</span><br><span class="line">    <span class="keyword">return</span> block</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">allocate_mutable_block</span>(<span class="params">self, prev_block: <span class="type">Optional</span>[Block], </span></span><br><span class="line"><span class="params">                          extra_hash: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span></span>) -&gt; Block:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;分配可变block用于新生成的token&quot;&quot;&quot;</span></span><br><span class="line">    block_id = <span class="variable language_">self</span>._allocate_block_id()</span><br><span class="line">    block = <span class="variable language_">self</span>._create_block(prev_block, [], <span class="variable language_">self</span>._block_size, </span><br><span class="line">                              <span class="variable language_">self</span>, block_id, extra_hash=extra_hash)</span><br><span class="line">    <span class="keyword">return</span> block</span><br></pre></td></tr></table></figure>

<h3 id="3-内容哈希机制"><a href="#3-内容哈希机制" class="headerlink" title="3. 内容哈希机制"></a>3. 内容哈希机制</h3><h4 id="层次化哈希计算"><a href="#层次化哈希计算" class="headerlink" title="层次化哈希计算"></a>层次化哈希计算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrefixCachingBlock</span>(<span class="title class_ inherited__">Block</span>):</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hash_block_tokens</span>(<span class="params">cls, is_first_block: <span class="built_in">bool</span>, prev_block_hash: <span class="type">Optional</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">                         cur_block_token_ids: <span class="type">List</span>[<span class="built_in">int</span>], extra_hash: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;计算block的内容哈希&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> is_first_block:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">hash</span>((<span class="built_in">tuple</span>(cur_block_token_ids), extra_hash))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">hash</span>((prev_block_hash, <span class="built_in">tuple</span>(cur_block_token_ids), extra_hash))</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @property </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">content_hash</span>(<span class="params">self</span>) -&gt; <span class="type">Optional</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>._content_hash <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="variable language_">self</span>.token_ids:</span><br><span class="line">            <span class="variable language_">self</span>._content_hash = <span class="variable language_">self</span>.hash_block_tokens(</span><br><span class="line">                <span class="variable language_">self</span>._prev_block <span class="keyword">is</span> <span class="literal">None</span>,</span><br><span class="line">                <span class="variable language_">self</span>._prev_block.content_hash <span class="keyword">if</span> <span class="variable language_">self</span>._prev_block <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                <span class="variable language_">self</span>.token_ids,</span><br><span class="line">                <span class="variable language_">self</span>.extra_hash</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._content_hash</span><br></pre></td></tr></table></figure>

<h3 id="4-调度集成"><a href="#4-调度集成" class="headerlink" title="4. 调度集成"></a>4. 调度集成</h3><h4 id="Memory-aware调度"><a href="#Memory-aware调度" class="headerlink" title="Memory-aware调度"></a>Memory-aware调度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SelfAttnBlockSpaceManager</span>(<span class="title class_ inherited__">BlockSpaceManager</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">can_allocate</span>(<span class="params">self, seq_group: SequenceGroup, num_lookahead_slots: <span class="built_in">int</span> = <span class="number">0</span></span>) -&gt; AllocStatus:</span><br><span class="line">        <span class="comment"># 检查是否有足够的GPU blocks</span></span><br><span class="line">        num_required_blocks = <span class="variable language_">self</span>._get_seq_num_required_blocks(seq_group.get_seqs()[<span class="number">0</span>])</span><br><span class="line">        num_required_blocks += num_lookahead_slots</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.block_allocator.get_num_free_blocks(Device.GPU) &lt; num_required_blocks:</span><br><span class="line">            <span class="keyword">return</span> AllocStatus.NEVER</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> AllocStatus.OK</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">allocate</span>(<span class="params">self, seq_group: SequenceGroup</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;为sequence group分配blocks&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> seq <span class="keyword">in</span> seq_group.get_seqs():</span><br><span class="line">            block_table = <span class="variable language_">self</span>._allocate_sequence(seq)</span><br><span class="line">            seq.block_table = block_table</span><br></pre></td></tr></table></figure>

<h2 id="SGLang-KV-Cache-管理"><a href="#SGLang-KV-Cache-管理" class="headerlink" title="SGLang KV Cache 管理"></a>SGLang KV Cache 管理</h2><h3 id="整体架构设计-2"><a href="#整体架构设计-2" class="headerlink" title="整体架构设计"></a>整体架构设计</h3><p>SGLang采用<strong>三层内存池架构</strong>，这是三个框架中最复杂和最灵活的设计：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 三层架构设计</span></span><br><span class="line">ReqToTokenPool          <span class="comment"># 第一层：请求到token位置映射</span></span><br><span class="line">├── TokenToKVPoolAllocator    <span class="comment"># 第二层：token到KV pool分配</span></span><br><span class="line">│   ├── PagedTokenToKVPoolAllocator (分页版本)</span><br><span class="line">│   └── SWATokenToKVPoolAllocator (滑动窗口版本)  </span><br><span class="line">└── KVCache                   <span class="comment"># 第三层：物理KV cache存储</span></span><br><span class="line">    ├── MHATokenToKVPool     <span class="comment"># 多头注意力</span></span><br><span class="line">    ├── MLATokenToKVPool     <span class="comment"># MLA注意力  </span></span><br><span class="line">    └── SWAKVPool            <span class="comment"># 滑动窗口注意力</span></span><br></pre></td></tr></table></figure>

<h3 id="1-请求级内存管理"><a href="#1-请求级内存管理" class="headerlink" title="1. 请求级内存管理"></a>1. 请求级内存管理</h3><h4 id="ReqToTokenPool"><a href="#ReqToTokenPool" class="headerlink" title="ReqToTokenPool"></a>ReqToTokenPool</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReqToTokenPool</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, max_context_len: <span class="built_in">int</span>, device: <span class="built_in">str</span>, enable_memory_saver: <span class="built_in">bool</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.size = size</span><br><span class="line">        <span class="variable language_">self</span>.max_context_len = max_context_len</span><br><span class="line">        <span class="comment"># 核心张量：[size, max_context_len]，存储token位置</span></span><br><span class="line">        <span class="variable language_">self</span>.req_to_token = torch.zeros((size, max_context_len), </span><br><span class="line">                                       dtype=torch.int32, device=device)</span><br><span class="line">        <span class="variable language_">self</span>.free_slots = <span class="built_in">list</span>(<span class="built_in">range</span>(size))  <span class="comment"># 空闲slot列表</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">alloc</span>(<span class="params">self, need_size: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;分配指定数量的slots&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> need_size &gt; <span class="built_in">len</span>(<span class="variable language_">self</span>.free_slots):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        select_index = <span class="variable language_">self</span>.free_slots[:need_size]</span><br><span class="line">        <span class="variable language_">self</span>.free_slots = <span class="variable language_">self</span>.free_slots[need_size:]</span><br><span class="line">        <span class="keyword">return</span> select_index</span><br></pre></td></tr></table></figure>

<h3 id="2-分页Token分配器"><a href="#2-分页Token分配器" class="headerlink" title="2. 分页Token分配器"></a>2. 分页Token分配器</h3><h4 id="PagedTokenToKVPoolAllocator"><a href="#PagedTokenToKVPoolAllocator" class="headerlink" title="PagedTokenToKVPoolAllocator"></a>PagedTokenToKVPoolAllocator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PagedTokenToKVPoolAllocator</span>(<span class="title class_ inherited__">BaseTokenToKVPoolAllocator</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, page_size: <span class="built_in">int</span>, dtype: torch.dtype, device: <span class="built_in">str</span>, kvcache: KVCache</span>):</span><br><span class="line">        <span class="variable language_">self</span>.size = size</span><br><span class="line">        <span class="variable language_">self</span>.page_size = page_size</span><br><span class="line">        <span class="comment"># 空闲页面列表：每个页面包含page_size个tokens</span></span><br><span class="line">        <span class="variable language_">self</span>.free_pages = torch.arange(<span class="number">1</span>, (size // page_size) + <span class="number">1</span>, device=device)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">alloc_extend</span>(<span class="params">self, prefix_lens: torch.Tensor, seq_lens: torch.Tensor, </span></span><br><span class="line"><span class="params">                    last_loc: torch.Tensor, extend_num_tokens: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;为extend阶段分配内存（使用Triton kernel优化）&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> alloc_extend_kernel(prefix_lens, seq_lens, last_loc, </span><br><span class="line">                                 <span class="variable language_">self</span>.free_pages, extend_num_tokens, <span class="variable language_">self</span>.page_size)</span><br></pre></td></tr></table></figure>

<h4 id="高性能Triton-Kernel"><a href="#高性能Triton-Kernel" class="headerlink" title="高性能Triton Kernel"></a>高性能Triton Kernel</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">alloc_extend_kernel</span>(<span class="params">pre_lens_ptr, seq_lens_ptr, last_loc_ptr, free_page_ptr,</span></span><br><span class="line"><span class="params">                       out_indices, ret_values, bs_upper: tl.constexpr, </span></span><br><span class="line"><span class="params">                       page_size: tl.constexpr, max_num_extend_tokens: tl.constexpr</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;使用Triton实现的高性能内存分配kernel&quot;&quot;&quot;</span></span><br><span class="line">    bid = tl.program_id(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> bid &gt;= bs_upper:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 加载序列信息</span></span><br><span class="line">    pre_len = tl.load(pre_lens_ptr + bid)</span><br><span class="line">    seq_len = tl.load(seq_lens_ptr + bid)</span><br><span class="line">    last_loc = tl.load(last_loc_ptr + bid)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算需要的token数和页数</span></span><br><span class="line">    num_new_tokens = seq_len - pre_len</span><br><span class="line">    num_new_pages = (num_new_tokens + page_size - <span class="number">1</span>) // page_size</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 原子操作分配页面</span></span><br><span class="line">    global_start_page = tl.atomic_add(free_page_ptr, num_new_pages)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成连续的token indices</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_new_tokens):</span><br><span class="line">        page_idx = i // page_size</span><br><span class="line">        page_offset = i % page_size</span><br><span class="line">        token_idx = (global_start_page + page_idx) * page_size + page_offset</span><br><span class="line">        tl.store(out_indices + bid * max_num_extend_tokens + i, token_idx)</span><br></pre></td></tr></table></figure>

<h3 id="3-SWA-Sliding-Window-Attention-支持"><a href="#3-SWA-Sliding-Window-Attention-支持" class="headerlink" title="3. SWA (Sliding Window Attention) 支持"></a>3. SWA (Sliding Window Attention) 支持</h3><h4 id="SWATokenToKVPoolAllocator"><a href="#SWATokenToKVPoolAllocator" class="headerlink" title="SWATokenToKVPoolAllocator"></a>SWATokenToKVPoolAllocator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SWATokenToKVPoolAllocator</span>(<span class="title class_ inherited__">BaseTokenToKVPoolAllocator</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, size_swa: <span class="built_in">int</span>, dtype: torch.dtype, device: <span class="built_in">str</span>, kvcache: SWAKVPool</span>):</span><br><span class="line">        <span class="comment"># 全注意力内存池</span></span><br><span class="line">        <span class="variable language_">self</span>.size_full = size</span><br><span class="line">        <span class="variable language_">self</span>.free_pages_full = torch.arange(<span class="number">1</span>, size + <span class="number">1</span>, device=device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 滑动窗口注意力内存池  </span></span><br><span class="line">        <span class="variable language_">self</span>.size_swa = size_swa</span><br><span class="line">        <span class="variable language_">self</span>.free_pages_swa = torch.arange(<span class="number">1</span>, size_swa + <span class="number">1</span>, device=device)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">alloc</span>(<span class="params">self, need_size: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;优先从full pool分配，不足时使用swa pool&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> need_size &lt;= <span class="built_in">len</span>(<span class="variable language_">self</span>.free_pages_full):</span><br><span class="line">            <span class="comment"># 从full pool分配</span></span><br><span class="line">            select_index = <span class="variable language_">self</span>.free_pages_full[:need_size]</span><br><span class="line">            <span class="variable language_">self</span>.free_pages_full = <span class="variable language_">self</span>.free_pages_full[need_size:]</span><br><span class="line">            <span class="keyword">return</span> select_index, <span class="string">&quot;full&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> need_size &lt;= <span class="built_in">len</span>(<span class="variable language_">self</span>.free_pages_swa):</span><br><span class="line">            <span class="comment"># 从swa pool分配</span></span><br><span class="line">            select_index = <span class="variable language_">self</span>.free_pages_swa[:need_size]</span><br><span class="line">            <span class="variable language_">self</span>.free_pages_swa = <span class="variable language_">self</span>.free_pages_swa[need_size:]</span><br><span class="line">            <span class="comment"># 转换索引以区分不同池</span></span><br><span class="line">            select_index = <span class="variable language_">self</span>.translate_loc_from_full_to_swa(select_index)</span><br><span class="line">            <span class="keyword">return</span> select_index, <span class="string">&quot;swa&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span>, <span class="string">&quot;none&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="4-物理KV-Cache层"><a href="#4-物理KV-Cache层" class="headerlink" title="4. 物理KV Cache层"></a>4. 物理KV Cache层</h3><h4 id="MLA-Multi-Latent-Attention-支持"><a href="#MLA-Multi-Latent-Attention-支持" class="headerlink" title="MLA (Multi-Latent Attention) 支持"></a>MLA (Multi-Latent Attention) 支持</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLATokenToKVPool</span>(<span class="title class_ inherited__">KVCache</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, page_size: <span class="built_in">int</span>, dtype: torch.dtype, </span></span><br><span class="line"><span class="params">                 kv_lora_rank: <span class="built_in">int</span>, qk_rope_head_dim: <span class="built_in">int</span>, layer_num: <span class="built_in">int</span>, device: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="comment"># MLA特殊的KV cache形状：[size, layer_num, kv_lora_rank + qk_rope_head_dim]</span></span><br><span class="line">        <span class="variable language_">self</span>.kv_buffer = torch.empty((size, layer_num, kv_lora_rank + qk_rope_head_dim), </span><br><span class="line">                                    dtype=dtype, device=device)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_mla_kv_buffer</span>(<span class="params">self, layer: RadixAttention, loc: torch.Tensor,</span></span><br><span class="line"><span class="params">                         cache_k_nope: torch.Tensor, cache_k_rope: torch.Tensor</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;使用Triton kernel高效设置MLA KV buffer&quot;&quot;&quot;</span></span><br><span class="line">        set_mla_kv_buffer_triton(<span class="variable language_">self</span>.kv_buffer, loc, cache_k_nope, cache_k_rope)</span><br></pre></td></tr></table></figure>

<h4 id="高性能MLA-Kernel"><a href="#高性能MLA-Kernel" class="headerlink" title="高性能MLA Kernel"></a>高性能MLA Kernel</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_mla_kv_buffer_kernel</span>(<span class="params">kv_buffer_ptr, cache_k_nope_ptr, cache_k_rope_ptr, loc_ptr,</span></span><br><span class="line"><span class="params">                            buffer_stride: tl.constexpr, nope_stride: tl.constexpr, </span></span><br><span class="line"><span class="params">                            rope_stride: tl.constexpr, nope_dim: tl.constexpr, </span></span><br><span class="line"><span class="params">                            rope_dim: tl.constexpr, BLOCK: tl.constexpr</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;MLA KV buffer设置的优化kernel&quot;&quot;&quot;</span></span><br><span class="line">    bid = tl.program_id(<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 加载位置信息</span></span><br><span class="line">    loc = tl.load(loc_ptr + bid)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 加载nope部分</span></span><br><span class="line">    nope_offset = bid * nope_stride + tl.arange(<span class="number">0</span>, nope_dim)</span><br><span class="line">    cache_k_nope = tl.load(cache_k_nope_ptr + nope_offset)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 加载rope部分</span></span><br><span class="line">    rope_offset = bid * rope_stride + tl.arange(<span class="number">0</span>, rope_dim)  </span><br><span class="line">    cache_k_rope = tl.load(cache_k_rope_ptr + rope_offset)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 写入KV buffer</span></span><br><span class="line">    buffer_offset = loc * buffer_stride + tl.arange(<span class="number">0</span>, nope_dim + rope_dim)</span><br><span class="line">    combined_kv = tl.join(cache_k_nope, cache_k_rope)</span><br><span class="line">    tl.store(kv_buffer_ptr + buffer_offset, combined_kv)</span><br></pre></td></tr></table></figure>

<h3 id="5-RadixAttention集成"><a href="#5-RadixAttention集成" class="headerlink" title="5. RadixAttention集成"></a>5. RadixAttention集成</h3><h4 id="RadixCache树形结构"><a href="#RadixCache树形结构" class="headerlink" title="RadixCache树形结构"></a>RadixCache树形结构</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RadixCache</span>(<span class="title class_ inherited__">BasePrefixCache</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, req_to_token_pool: ReqToTokenPool, </span></span><br><span class="line"><span class="params">                 token_to_kv_pool: BaseTokenToKVPoolAllocator, page_size: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.req_to_token_pool = req_to_token_pool</span><br><span class="line">        <span class="variable language_">self</span>.token_to_kv_pool = token_to_kv_pool  </span><br><span class="line">        <span class="variable language_">self</span>.page_size = page_size</span><br><span class="line">        <span class="variable language_">self</span>.root = TreeNode()  <span class="comment"># 根节点</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">match_prefix</span>(<span class="params">self, key: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; MatchResult:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;匹配最长公共前缀&quot;&quot;&quot;</span></span><br><span class="line">        node = <span class="variable language_">self</span>.root</span><br><span class="line">        matched_len = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分页匹配，提高效率</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(key), <span class="variable language_">self</span>.page_size):</span><br><span class="line">            page_key = key[i:i+<span class="variable language_">self</span>.page_size]</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">tuple</span>(page_key) <span class="keyword">in</span> node.children:</span><br><span class="line">                node = node.children[<span class="built_in">tuple</span>(page_key)]</span><br><span class="line">                matched_len += <span class="built_in">len</span>(page_key)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> MatchResult(matched_len, node)</span><br></pre></td></tr></table></figure>

<h2 id="技术对比与深度分析"><a href="#技术对比与深度分析" class="headerlink" title="技术对比与深度分析"></a>技术对比与深度分析</h2><h3 id="1-内存管理策略对比"><a href="#1-内存管理策略对比" class="headerlink" title="1. 内存管理策略对比"></a>1. 内存管理策略对比</h3><table>
<thead>
<tr>
<th>特性</th>
<th>TensorRT-LLM</th>
<th>vLLM</th>
<th>SGLang</th>
</tr>
</thead>
<tbody><tr>
<td><strong>架构复杂度</strong></td>
<td>中等 (分层block)</td>
<td>简单 (模块化)</td>
<td>高 (三层架构)</td>
</tr>
<tr>
<td><strong>内存池设计</strong></td>
<td>按配置分池</td>
<td>CPU&#x2F;GPU分离</td>
<td>多类型Pool</td>
</tr>
<tr>
<td><strong>分页支持</strong></td>
<td>支持 (16,32,64,128)</td>
<td>支持 (可配置)</td>
<td>支持 (可配置)</td>
</tr>
<tr>
<td><strong>SWA支持</strong></td>
<td>支持</td>
<td>部分支持</td>
<td>原生支持</td>
</tr>
<tr>
<td><strong>量化支持</strong></td>
<td>FP8&#x2F;INT4&#x2F;AWQ&#x2F;GPTQ</td>
<td>FP8</td>
<td>基础支持</td>
</tr>
</tbody></table>
<h3 id="2-前缀缓存机制对比"><a href="#2-前缀缓存机制对比" class="headerlink" title="2. 前缀缓存机制对比"></a>2. 前缀缓存机制对比</h3><h4 id="哈希算法性能"><a href="#哈希算法性能" class="headerlink" title="哈希算法性能"></a>哈希算法性能</h4><ul>
<li><strong>TensorRT-LLM</strong>: Wang hash + 64位优化，支持层次化哈希</li>
<li><strong>vLLM</strong>: Python标准hash，简单高效</li>
<li><strong>SGLang</strong>: 分页哈希，树形前缀匹配</li>
</ul>
<h4 id="缓存共享策略"><a href="#缓存共享策略" class="headerlink" title="缓存共享策略"></a>缓存共享策略</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TensorRT-LLM: 引用计数 + 优先级管理</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KVCacheBlock</span> &#123;</span><br><span class="line">    <span class="type">int32_t</span> mRefCount;                  <span class="comment">// 引用计数</span></span><br><span class="line">    executor::RetentionPriority mPriority; <span class="comment">// 优先级</span></span><br><span class="line">    std::chrono::milliseconds mDurationMs; <span class="comment">// 生存时间</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vLLM: 内容哈希 + LRU</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PrefixCachingBlockAllocator</span> &#123;</span><br><span class="line">    _cached_blocks: <span class="type">Dict</span>[PrefixHash, BlockId]  <span class="comment"># 哈希到块ID映射</span></span><br><span class="line">    _touched_blocks: <span class="type">Set</span>[BlockId]              <span class="comment"># 调度器触及的块</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SGLang: 树形结构 + 分页匹配</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TreeNode</span> &#123;</span><br><span class="line">    children: defaultdict(TreeNode)     <span class="comment"># 子节点映射</span></span><br><span class="line">    value: <span class="type">Optional</span>[torch.Tensor]       <span class="comment"># 缓存值</span></span><br><span class="line">    last_access_time: <span class="built_in">float</span>            <span class="comment"># 最后访问时间</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-性能优化技术"><a href="#3-性能优化技术" class="headerlink" title="3. 性能优化技术"></a>3. 性能优化技术</h3><h4 id="内存访问优化"><a href="#内存访问优化" class="headerlink" title="内存访问优化"></a>内存访问优化</h4><ol>
<li><p><strong>TensorRT-LLM</strong>:</p>
<ul>
<li>CUDA kernel优化的paged attention</li>
<li>多级缓存 (primary&#x2F;secondary)</li>
<li>Fabric memory支持高速传输</li>
</ul>
</li>
<li><p><strong>vLLM</strong>: </p>
<ul>
<li>Triton kernel实现</li>
<li>FlashAttention集成</li>
<li>多后端支持 (CUDA&#x2F;ROCm&#x2F;CPU)</li>
</ul>
</li>
<li><p><strong>SGLang</strong>:</p>
<ul>
<li>最多Triton kernel优化</li>
<li>专门的MLA&#x2F;SWA支持  </li>
<li>硬件特定优化 (Ascend NPU)</li>
</ul>
</li>
</ol>
<h4 id="并发和同步"><a href="#并发和同步" class="headerlink" title="并发和同步"></a>并发和同步</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TensorRT-LLM: 细粒度锁</span></span><br><span class="line">std::mutex mAllocatedBlocksPerSeqMutex;</span><br><span class="line">std::condition_variable mCondVar;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调度期间的引用计数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">KVCacheBlock::startScheduling</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    mSchedulingRefCount = mRefCount;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vLLM: 简化的状态管理</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BlockTracker</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">enable</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">assert</span> <span class="keyword">not</span> <span class="variable language_">self</span>.active</span><br><span class="line">        <span class="variable language_">self</span>.active = <span class="literal">True</span></span><br><span class="line">        <span class="variable language_">self</span>.reset()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SGLang: 分组释放优化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">free_group_begin</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="variable language_">self</span>.is_not_in_free_group = <span class="literal">False</span></span><br><span class="line">    <span class="variable language_">self</span>.free_group = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">free_group_end</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.free_group:</span><br><span class="line">        <span class="variable language_">self</span>.free(torch.cat(<span class="variable language_">self</span>.free_group))  <span class="comment"># 批量释放</span></span><br></pre></td></tr></table></figure>

<h2 id="性能优化策略"><a href="#性能优化策略" class="headerlink" title="性能优化策略"></a>性能优化策略</h2><h3 id="1-内存分配优化"><a href="#1-内存分配优化" class="headerlink" title="1. 内存分配优化"></a>1. 内存分配优化</h3><h4 id="TensorRT-LLM优化要点"><a href="#TensorRT-LLM优化要点" class="headerlink" title="TensorRT-LLM优化要点"></a>TensorRT-LLM优化要点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 预分配策略 - 避免运行时分配</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">WindowBlockManager::allocatePools</span><span class="params">(<span class="type">bool</span> useUvm)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 预分配所有内存池</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; pool : mPools) &#123;</span><br><span class="line">        pool.primaryPtr = mBufferManager.<span class="built_in">gpuSync</span>(cacheShape, poolDtype);</span><br><span class="line">        <span class="keyword">if</span> (mNumSecondaryBlocks &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            pool.secondaryPtr = BufferManager::<span class="built_in">pinned</span>(cacheShapeOffload, poolDtype);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 智能驱逐策略</span></span><br><span class="line"><span class="function">BlockPtr <span class="title">getFreeBlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 优先级队列 + LRU</span></span><br><span class="line">    <span class="keyword">auto</span> [block, canOffload] = mEvictionPolicy-&gt;<span class="built_in">getFreeBlock</span>(kPrimaryLevel);</span><br><span class="line">    <span class="keyword">if</span> (canOffload &amp;&amp; needOffload) &#123;</span><br><span class="line">        <span class="comment">// 异步offload到secondary memory</span></span><br><span class="line">        mTransferManager-&gt;<span class="built_in">offload</span>(block, offloadBlock, mPools);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> block;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="vLLM优化要点"><a href="#vLLM优化要点" class="headerlink" title="vLLM优化要点"></a>vLLM优化要点</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 延迟计算 - 仅在需要时计算哈希</span></span><br><span class="line"><span class="meta">@property</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">content_hash</span>(<span class="params">self</span>) -&gt; <span class="type">Optional</span>[<span class="built_in">int</span>]:</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>._content_hash <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="variable language_">self</span>.token_ids:</span><br><span class="line">        <span class="variable language_">self</span>._content_hash = <span class="variable language_">self</span>.hash_block_tokens(...)</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>._content_hash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 设备感知分配</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">allocate_mutable_block</span>(<span class="params">self, device: Device</span>) -&gt; Block:</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>._allocators[device].allocate_mutable_block(...)</span><br></pre></td></tr></table></figure>

<h4 id="SGLang优化要点"><a href="#SGLang优化要点" class="headerlink" title="SGLang优化要点"></a>SGLang优化要点</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Triton kernel加速</span></span><br><span class="line"><span class="meta">@triton.jit  </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">alloc_extend_kernel</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="comment"># GPU并行分配，避免CPU-GPU同步</span></span><br><span class="line">    global_start_page = tl.atomic_add(free_page_ptr, num_new_pages)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 分组操作减少开销</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">free_group_end</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.free_group:</span><br><span class="line">        <span class="variable language_">self</span>.free(torch.cat(<span class="variable language_">self</span>.free_group))  <span class="comment"># 批量释放</span></span><br></pre></td></tr></table></figure>

<h3 id="2-缓存命中率优化"><a href="#2-缓存命中率优化" class="headerlink" title="2. 缓存命中率优化"></a>2. 缓存命中率优化</h3><h4 id="前缀匹配算法"><a href="#前缀匹配算法" class="headerlink" title="前缀匹配算法"></a>前缀匹配算法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SGLang: 分页前缀匹配</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_key_match_paged</span>(<span class="params">key0: <span class="type">List</span>, key1: <span class="type">List</span>, page_size: <span class="built_in">int</span></span>):</span><br><span class="line">    min_len = <span class="built_in">min</span>(<span class="built_in">len</span>(key0), <span class="built_in">len</span>(key1))</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; min_len:</span><br><span class="line">        <span class="keyword">if</span> key0[i : i + page_size] != key1[i : i + page_size]:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        i += page_size</span><br><span class="line">    <span class="keyword">return</span> i</span><br><span class="line"></span><br><span class="line"><span class="comment"># TensorRT-LLM: 部分块复用</span></span><br><span class="line">std::<span class="built_in">tuple</span>&lt;<span class="built_in">bool</span>, SizeType32, BlockPtr&gt; findMatchingBlock(</span><br><span class="line">    BlockKey const&amp; blockKey, <span class="built_in">bool</span> enablePartialReuse) &#123;</span><br><span class="line">    <span class="keyword">if</span> (enablePartialReuse) &#123;</span><br><span class="line">        // 查找最佳部分匹配</span><br><span class="line">        <span class="keyword">for</span> (auto const&amp; [key, block] : mNextBlocks) &#123;</span><br><span class="line">            SizeType32 numMatched = key.partialMatch(blockKey);</span><br><span class="line">            <span class="keyword">if</span> (numMatched &gt; bestNumMatched) &#123;</span><br><span class="line">                bestNumMatched = numMatched;</span><br><span class="line">                bestBlock = block;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="缓存替换策略"><a href="#缓存替换策略" class="headerlink" title="缓存替换策略"></a>缓存替换策略</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TensorRT-LLM: 多因素LRU</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LRUEvictionPolicy</span> &#123;</span><br><span class="line">    <span class="comment">// 考虑优先级、访问时间、引用计数</span></span><br><span class="line">    std::vector&lt;std::vector&lt;FreeBlocksQueue&gt;&gt; mFreeQueues; <span class="comment">// [level][priority]</span></span><br><span class="line">    </span><br><span class="line">    <span class="function">BlockPtr <span class="title">getLRUBlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 优先级 &gt; 最后访问时间 &gt; 引用计数</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> priority = kMinPriority; priority &lt;= kMaxPriority; ++priority) &#123;</span><br><span class="line">            <span class="keyword">auto</span>&amp; queue = mFreeQueues[level][priority];</span><br><span class="line">            <span class="keyword">if</span> (!queue.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                <span class="keyword">return</span> queue.<span class="built_in">front</span>(); <span class="comment">// LRU order</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="3-内存使用优化"><a href="#3-内存使用优化" class="headerlink" title="3. 内存使用优化"></a>3. 内存使用优化</h3><h4 id="动态内存管理"><a href="#动态内存管理" class="headerlink" title="动态内存管理"></a>动态内存管理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SGLang: 动态SWA池切换</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SWATokenToKVPoolAllocator</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">alloc</span>(<span class="params">self, need_size: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="keyword">if</span> need_size &lt;= <span class="built_in">len</span>(<span class="variable language_">self</span>.free_pages_full):</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.free_pages_full[:need_size], <span class="string">&quot;full&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> need_size &lt;= <span class="built_in">len</span>(<span class="variable language_">self</span>.free_pages_swa):</span><br><span class="line">            <span class="comment"># 动态切换到SWA池</span></span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.translate_loc_from_full_to_swa(</span><br><span class="line">                <span class="variable language_">self</span>.free_pages_swa[:need_size]), <span class="string">&quot;swa&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="内存碎片减少"><a href="#内存碎片减少" class="headerlink" title="内存碎片减少"></a>内存碎片减少</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TensorRT-LLM: 连续块分配</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">addSequence</span><span class="params">(GenerationRequest&amp; sequence, SizeType32 inputLength)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 尽量分配连续的blocks以减少碎片</span></span><br><span class="line">    <span class="keyword">auto</span> blockedUniqueTokens = <span class="built_in">chopVectorIntoBlocks</span>(uniqueTokens, inputLength<span class="number">-1</span>, mTokensPerBlock);</span><br><span class="line">    <span class="keyword">auto</span> prepopulatedPromptLen = <span class="built_in">loadOrAllocateBlocks</span>(blockKeys, numContextBlocks, sequence);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="总结与建议"><a href="#总结与建议" class="headerlink" title="总结与建议"></a>总结与建议</h2><h3 id="各框架优势总结"><a href="#各框架优势总结" class="headerlink" title="各框架优势总结"></a>各框架优势总结</h3><h4 id="TensorRT-LLM"><a href="#TensorRT-LLM" class="headerlink" title="TensorRT-LLM"></a>TensorRT-LLM</h4><p><strong>优势</strong>:</p>
<ul>
<li>生产级稳定性和性能</li>
<li>完善的量化支持</li>
<li>优秀的CUDA kernel优化</li>
<li>企业级特性 (优先级、过期时间等)</li>
</ul>
<p><strong>适用场景</strong>:</p>
<ul>
<li>大规模生产部署</li>
<li>高性能要求的应用</li>
<li>NVIDIA GPU集群环境</li>
</ul>
<h4 id="vLLM"><a href="#vLLM" class="headerlink" title="vLLM"></a>vLLM</h4><p><strong>优势</strong>:</p>
<ul>
<li>代码简洁，易于理解和扩展</li>
<li>良好的社区支持</li>
<li>灵活的后端支持</li>
<li>快速迭代和新特性集成</li>
</ul>
<p><strong>适用场景</strong>:</p>
<ul>
<li>研究和原型开发</li>
<li>多样化硬件环境</li>
<li>需要快速集成新特性</li>
</ul>
<h4 id="SGLang"><a href="#SGLang" class="headerlink" title="SGLang"></a>SGLang</h4><p><strong>优势</strong>:</p>
<ul>
<li>最先进的内存管理架构</li>
<li>原生多模态支持</li>
<li>尖端优化技术 (MLA, SWA等)</li>
<li>硬件异构支持</li>
</ul>
<p><strong>适用场景</strong>:</p>
<ul>
<li>前沿研究项目  </li>
<li>复杂attention模式需求</li>
<li>异构硬件环境</li>
</ul>
<h3 id="技术发展趋势"><a href="#技术发展趋势" class="headerlink" title="技术发展趋势"></a>技术发展趋势</h3><ol>
<li><strong>架构融合</strong>: 各框架正在互相借鉴优势特性</li>
<li><strong>硬件特化</strong>: 针对不同硬件的专门优化</li>
<li><strong>智能调度</strong>: AI驱动的内存管理和调度策略</li>
<li><strong>异构计算</strong>: CPU&#x2F;GPU&#x2F;NPU协同的KV cache管理</li>
</ol>
<h3 id="选择建议"><a href="#选择建议" class="headerlink" title="选择建议"></a>选择建议</h3><table>
<thead>
<tr>
<th>需求</th>
<th>推荐框架</th>
<th>理由</th>
</tr>
</thead>
<tbody><tr>
<td>生产部署</td>
<td>TensorRT-LLM</td>
<td>稳定性和性能最佳</td>
</tr>
<tr>
<td>研究开发</td>
<td>vLLM</td>
<td>开发效率和扩展性好</td>
</tr>
<tr>
<td>前沿探索</td>
<td>SGLang</td>
<td>最新技术和架构创新</td>
</tr>
<tr>
<td>多模态应用</td>
<td>SGLang</td>
<td>原生多模态支持</td>
</tr>
<tr>
<td>异构硬件</td>
<td>SGLang &gt; vLLM &gt; TensorRT-LLM</td>
<td>硬件支持广度</td>
</tr>
</tbody></table>
<p>选择框架时应综合考虑性能需求、开发资源、部署环境和长期维护等因素。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/14/System/LLM_KVCache_%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/" data-id="cmdpf31ag001pq0onhmttcccs" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Programming/CPP/modern cpu" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/10/Programming/CPP/modern%20cpu/" class="article-date">
  <time class="dt-published" datetime="2025-07-10T01:35:38.184Z" itemprop="datePublished">2025-07-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="现代CPU架构与性能优化详解"><a href="#现代CPU架构与性能优化详解" class="headerlink" title="现代CPU架构与性能优化详解"></a>现代CPU架构与性能优化详解</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>在现代高性能计算中，CPU绑定和NUMA感知编程是重要的优化技术。理解这些技术的底层原理对于开发高性能应用至关重要。</p>
<h2 id="1-CPU绑定-CPU-Affinity"><a href="#1-CPU绑定-CPU-Affinity" class="headerlink" title="1. CPU绑定 (CPU Affinity)"></a>1. CPU绑定 (CPU Affinity)</h2><h3 id="1-1-什么是CPU绑定"><a href="#1-1-什么是CPU绑定" class="headerlink" title="1.1 什么是CPU绑定"></a>1.1 什么是CPU绑定</h3><p>CPU绑定是指将进程或线程固定到特定的CPU核心上运行，避免操作系统调度器将其迁移到其他核心。</p>
<h3 id="1-2-为什么需要CPU绑定"><a href="#1-2-为什么需要CPU绑定" class="headerlink" title="1.2 为什么需要CPU绑定"></a>1.2 为什么需要CPU绑定</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 没有CPU绑定的问题</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">without_affinity</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 线程可能在不同核心间迁移，导致：</span></span><br><span class="line">    <span class="comment">// 1. 缓存失效 (Cache Miss)</span></span><br><span class="line">    <span class="comment">// 2. TLB失效 (Translation Lookaside Buffer)</span></span><br><span class="line">    <span class="comment">// 3. 上下文切换开销</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">        <span class="built_in">heavy_computation</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用CPU绑定</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">with_affinity</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">cpu_set_t</span> cpuset;</span><br><span class="line">    <span class="built_in">CPU_ZERO</span>(&amp;cpuset);</span><br><span class="line">    <span class="built_in">CPU_SET</span>(<span class="number">0</span>, &amp;cpuset);  <span class="comment">// 绑定到核心0</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">pthread_setaffinity_np</span>(<span class="built_in">pthread_self</span>(), <span class="built_in">sizeof</span>(<span class="type">cpu_set_t</span>), &amp;cpuset);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 现在线程固定在核心0上运行，避免迁移开销</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">        <span class="built_in">heavy_computation</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="1-3-性能影响分析"><a href="#1-3-性能影响分析" class="headerlink" title="1.3 性能影响分析"></a>1.3 性能影响分析</h3><h4 id="缓存局部性"><a href="#缓存局部性" class="headerlink" title="缓存局部性"></a>缓存局部性</h4><ul>
<li><strong>L1缓存</strong>：32KB，1个周期延迟</li>
<li><strong>L2缓存</strong>：256KB，10个周期延迟  </li>
<li><strong>L3缓存</strong>：8MB，40个周期延迟</li>
<li><strong>主内存</strong>：100-300个周期延迟</li>
</ul>
<p>线程迁移会导致缓存失效，大幅增加内存访问延迟。</p>
<h4 id="TLB-Translation-Lookaside-Buffer-优化"><a href="#TLB-Translation-Lookaside-Buffer-优化" class="headerlink" title="TLB (Translation Lookaside Buffer) 优化"></a>TLB (Translation Lookaside Buffer) 优化</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TLB友好的内存分配</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TLBOptimizedAllocator</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">size_t</span> PAGE_SIZE = <span class="number">4096</span>;</span><br><span class="line">    <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">size_t</span> TLB_ENTRIES = <span class="number">64</span>;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span>* <span class="title">allocate_aligned</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 按页对齐分配，减少TLB缺失</span></span><br><span class="line">        <span class="type">size_t</span> aligned_size = (size + PAGE_SIZE - <span class="number">1</span>) &amp; ~(PAGE_SIZE - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">aligned_alloc</span>(PAGE_SIZE, aligned_size);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="2-NUMA架构详解"><a href="#2-NUMA架构详解" class="headerlink" title="2. NUMA架构详解"></a>2. NUMA架构详解</h2><h3 id="2-1-什么是NUMA"><a href="#2-1-什么是NUMA" class="headerlink" title="2.1 什么是NUMA"></a>2.1 什么是NUMA</h3><p>NUMA (Non-Uniform Memory Access) 是一种内存架构，其中内存访问时间取决于内存相对于处理器的位置。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">NUMA架构示意图：</span><br><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│                        NUMA Node 0                          │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  CPU 0  │  CPU 1  │  CPU 2  │  CPU 3  │  Memory Controller  │</span><br><span class="line">│         │         │         │         │                     │</span><br><span class="line">│  L1/L2  │  L1/L2  │  L1/L2  │  L1/L2  │  Local Memory      │</span><br><span class="line">│  Cache  │  Cache  │  Cache  │  Cache  │  (Fast Access)     │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br><span class="line">         │                    │</span><br><span class="line">         │   Interconnect     │</span><br><span class="line">         │   (Slower)         │</span><br><span class="line">         │                    │</span><br><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│                        NUMA Node 1                          │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  CPU 4  │  CPU 5  │  CPU 6  │  CPU 7  │  Memory Controller  │</span><br><span class="line">│         │         │         │         │                     │</span><br><span class="line">│  L1/L2  │  L1/L2  │  L1/L2  │  L1/L2  │  Remote Memory     │</span><br><span class="line">│  Cache  │  Cache  │  Cache  │  Cache  │  (Slow Access)     │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="2-2-NUMA访问延迟"><a href="#2-2-NUMA访问延迟" class="headerlink" title="2.2 NUMA访问延迟"></a>2.2 NUMA访问延迟</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NUMA感知的内存访问</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NUMAOptimized</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span>* local_data_;</span><br><span class="line">    <span class="type">int</span>* remote_data_;</span><br><span class="line">    <span class="type">int</span> numa_node_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">NUMAOptimized</span>(<span class="type">int</span> numa_node) : <span class="built_in">numa_node_</span>(numa_node) &#123;</span><br><span class="line">        <span class="comment">// 在本地NUMA节点分配内存</span></span><br><span class="line">        local_data_ = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>*&gt;(</span><br><span class="line">            <span class="built_in">numa_alloc_onnode</span>(<span class="number">1024</span> * <span class="built_in">sizeof</span>(<span class="type">int</span>), numa_node_));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 在远程NUMA节点分配内存</span></span><br><span class="line">        remote_data_ = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>*&gt;(</span><br><span class="line">            <span class="built_in">numa_alloc_onnode</span>(<span class="number">1024</span> * <span class="built_in">sizeof</span>(<span class="type">int</span>), (numa_node_ + <span class="number">1</span>) % <span class="number">2</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">benchmark_access</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> start = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 访问本地内存</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1024</span>; ++i) &#123;</span><br><span class="line">            local_data_[i] = i;  <span class="comment">// 快速访问</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">auto</span> local_end = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 访问远程内存</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1024</span>; ++i) &#123;</span><br><span class="line">            remote_data_[i] = i;  <span class="comment">// 慢速访问</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">auto</span> remote_end = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">auto</span> local_time = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::nanoseconds&gt;(</span><br><span class="line">            local_end - start).<span class="built_in">count</span>();</span><br><span class="line">        <span class="keyword">auto</span> remote_time = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::nanoseconds&gt;(</span><br><span class="line">            remote_end - local_end).<span class="built_in">count</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Local access: %ld ns, Remote access: %ld ns\n&quot;</span>, </span><br><span class="line">               local_time, remote_time);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-NUMA感知编程"><a href="#2-3-NUMA感知编程" class="headerlink" title="2.3 NUMA感知编程"></a>2.3 NUMA感知编程</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NUMA感知的线程池</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NUMAThreadPool</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">NUMAWorker</span> &#123;</span><br><span class="line">        std::thread thread;</span><br><span class="line">        <span class="type">int</span> numa_node;</span><br><span class="line">        std::queue&lt;std::function&lt;<span class="type">void</span>()&gt;&gt; tasks;</span><br><span class="line">        std::mutex mutex;</span><br><span class="line">        std::condition_variable cv;</span><br><span class="line">        <span class="type">bool</span> stop;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    std::vector&lt;NUMAWorker&gt; workers_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">NUMAThreadPool</span>() &#123;</span><br><span class="line">        <span class="type">int</span> num_numa_nodes = <span class="built_in">numa_num_configured_nodes</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> node = <span class="number">0</span>; node &lt; num_numa_nodes; ++node) &#123;</span><br><span class="line">            <span class="type">int</span> num_cpus = <span class="built_in">numa_num_configured_cpus</span>();</span><br><span class="line">            <span class="type">int</span> cpus_per_node = num_cpus / num_numa_nodes;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; cpus_per_node; ++i) &#123;</span><br><span class="line">                NUMAWorker worker;</span><br><span class="line">                worker.numa_node = node;</span><br><span class="line">                worker.stop = <span class="literal">false</span>;</span><br><span class="line">                </span><br><span class="line">                worker.thread = std::<span class="built_in">thread</span>([<span class="keyword">this</span>, &amp;worker]() &#123;</span><br><span class="line">                    <span class="comment">// 绑定到特定NUMA节点的CPU</span></span><br><span class="line">                    <span class="type">cpu_set_t</span> cpuset;</span><br><span class="line">                    <span class="built_in">CPU_ZERO</span>(&amp;cpuset);</span><br><span class="line">                    </span><br><span class="line">                    <span class="type">int</span> cpu_id = worker.numa_node * (<span class="built_in">numa_num_configured_cpus</span>() / </span><br><span class="line">                                                   <span class="built_in">numa_num_configured_nodes</span>()) + </span><br><span class="line">                               worker.thread.<span class="built_in">get_id</span>() % (<span class="built_in">numa_num_configured_cpus</span>() / </span><br><span class="line">                                                       <span class="built_in">numa_num_configured_nodes</span>());</span><br><span class="line">                    <span class="built_in">CPU_SET</span>(cpu_id, &amp;cpuset);</span><br><span class="line">                    </span><br><span class="line">                    <span class="built_in">pthread_setaffinity_np</span>(worker.thread.<span class="built_in">native_handle</span>(), </span><br><span class="line">                                          <span class="built_in">sizeof</span>(<span class="type">cpu_set_t</span>), &amp;cpuset);</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">// 在本地NUMA节点分配内存</span></span><br><span class="line">                    <span class="built_in">numa_set_preferred</span>(node);</span><br><span class="line">                    </span><br><span class="line">                    <span class="keyword">while</span> (!worker.stop) &#123;</span><br><span class="line">                        std::function&lt;<span class="built_in">void</span>()&gt; task;</span><br><span class="line">                        &#123;</span><br><span class="line">                            std::unique_lock&lt;std::mutex&gt; <span class="built_in">lock</span>(worker.mutex);</span><br><span class="line">                            worker.cv.<span class="built_in">wait</span>(lock, [&amp;worker]() &#123;</span><br><span class="line">                                <span class="keyword">return</span> !worker.tasks.<span class="built_in">empty</span>() || worker.stop;</span><br><span class="line">                            &#125;);</span><br><span class="line">                            </span><br><span class="line">                            <span class="keyword">if</span> (worker.stop) <span class="keyword">break</span>;</span><br><span class="line">                            </span><br><span class="line">                            task = std::<span class="built_in">move</span>(worker.tasks.<span class="built_in">front</span>());</span><br><span class="line">                            worker.tasks.<span class="built_in">pop</span>();</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="built_in">task</span>();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">                </span><br><span class="line">                workers_.<span class="built_in">push_back</span>(std::<span class="built_in">move</span>(worker));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> F&gt;</span></span><br><span class="line"><span class="function">    <span class="type">void</span> <span class="title">enqueue</span><span class="params">(F&amp;&amp; task, <span class="type">int</span> preferred_numa_node = <span class="number">-1</span>)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (preferred_numa_node &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// 将任务分配给指定NUMA节点的worker</span></span><br><span class="line">            <span class="type">int</span> worker_index = preferred_numa_node * </span><br><span class="line">                              (<span class="built_in">numa_num_configured_cpus</span>() / <span class="built_in">numa_num_configured_nodes</span>());</span><br><span class="line">            </span><br><span class="line">            <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(workers_[worker_index].mutex)</span></span>;</span><br><span class="line">            workers_[worker_index].tasks.<span class="built_in">emplace</span>(std::forward&lt;F&gt;(task));</span><br><span class="line">            workers_[worker_index].cv.<span class="built_in">notify_one</span>();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 轮询分配</span></span><br><span class="line">            <span class="type">static</span> <span class="type">int</span> current_worker = <span class="number">0</span>;</span><br><span class="line">            <span class="type">int</span> worker_index = current_worker++ % workers_.<span class="built_in">size</span>();</span><br><span class="line">            </span><br><span class="line">            <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(workers_[worker_index].mutex)</span></span>;</span><br><span class="line">            workers_[worker_index].tasks.<span class="built_in">emplace</span>(std::forward&lt;F&gt;(task));</span><br><span class="line">            workers_[worker_index].cv.<span class="built_in">notify_one</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="3-缓存层次结构"><a href="#3-缓存层次结构" class="headerlink" title="3. 缓存层次结构"></a>3. 缓存层次结构</h2><h3 id="3-1-现代CPU缓存架构"><a href="#3-1-现代CPU缓存架构" class="headerlink" title="3.1 现代CPU缓存架构"></a>3.1 现代CPU缓存架构</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 缓存层次结构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CacheHierarchy</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">CacheInfo</span> &#123;</span><br><span class="line">        <span class="type">size_t</span> size;      <span class="comment">// 缓存大小</span></span><br><span class="line">        <span class="type">size_t</span> line_size; <span class="comment">// 缓存行大小</span></span><br><span class="line">        <span class="type">int</span> associativity; <span class="comment">// 关联度</span></span><br><span class="line">        <span class="type">int</span> latency;      <span class="comment">// 访问延迟</span></span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> CacheInfo <span class="title">get_cache_info</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        CacheInfo info;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// L1数据缓存</span></span><br><span class="line">        info.size = <span class="number">32</span> * <span class="number">1024</span>;        <span class="comment">// 32KB</span></span><br><span class="line">        info.line_size = <span class="number">64</span>;          <span class="comment">// 64字节</span></span><br><span class="line">        info.associativity = <span class="number">8</span>;       <span class="comment">// 8路组关联</span></span><br><span class="line">        info.latency = <span class="number">1</span>;             <span class="comment">// 1个周期</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> info;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 缓存友好的数据结构</span></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">CacheFriendlyArray</span> &#123;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        std::vector&lt;T&gt; data_;</span><br><span class="line">        <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">size_t</span> CACHE_LINE_SIZE = <span class="number">64</span>;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">CacheFriendlyArray</span>(<span class="type">size_t</span> size) : <span class="built_in">data_</span>(size) &#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 确保数据按缓存行对齐</span></span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">align_to_cache_line</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="type">size_t</span> alignment = CACHE_LINE_SIZE / <span class="built_in">sizeof</span>(T);</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; data_.<span class="built_in">size</span>(); i += alignment) &#123;</span><br><span class="line">                <span class="comment">// 预取下一个缓存行</span></span><br><span class="line">                __builtin_prefetch(&amp;data_[i + alignment], <span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 缓存友好的访问模式</span></span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">cache_friendly_access</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; data_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">                <span class="comment">// 顺序访问，最大化缓存利用率</span></span><br><span class="line">                data_[i] = <span class="built_in">process</span>(data_[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-预取优化"><a href="#3-2-预取优化" class="headerlink" title="3.2 预取优化"></a>3.2 预取优化</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 硬件预取优化</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PrefetchOptimization</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; data_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">PrefetchOptimization</span>(<span class="type">size_t</span> size) : <span class="built_in">data_</span>(size) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">            data_[i] = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 使用软件预取</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">software_prefetch</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">size_t</span> prefetch_distance = <span class="number">16</span>;  <span class="comment">// 预取距离</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; data_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            <span class="comment">// 预取未来要访问的数据</span></span><br><span class="line">            <span class="keyword">if</span> (i + prefetch_distance &lt; data_.<span class="built_in">size</span>()) &#123;</span><br><span class="line">                __builtin_prefetch(&amp;data_[i + prefetch_distance], <span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 处理当前数据</span></span><br><span class="line">            data_[i] = <span class="built_in">heavy_computation</span>(data_[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 使用硬件预取友好的访问模式</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">hardware_prefetch_friendly</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 大步长访问，触发硬件预取</span></span><br><span class="line">        <span class="type">const</span> <span class="type">size_t</span> stride = <span class="number">64</span> / <span class="built_in">sizeof</span>(<span class="type">int</span>);  <span class="comment">// 一个缓存行的大小</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; data_.<span class="built_in">size</span>(); i += stride) &#123;</span><br><span class="line">            data_[i] = <span class="built_in">heavy_computation</span>(data_[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">heavy_computation</span><span class="params">(<span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> value * value + value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="4-实际应用示例"><a href="#4-实际应用示例" class="headerlink" title="4. 实际应用示例"></a>4. 实际应用示例</h2><h3 id="4-1-高性能矩阵乘法"><a href="#4-1-高性能矩阵乘法" class="headerlink" title="4.1 高性能矩阵乘法"></a>4.1 高性能矩阵乘法</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NUMA感知的矩阵乘法</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NUMAOptimizedMatrix</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">double</span>* matrix_a_;</span><br><span class="line">    <span class="type">double</span>* matrix_b_;</span><br><span class="line">    <span class="type">double</span>* matrix_c_;</span><br><span class="line">    <span class="type">int</span> size_;</span><br><span class="line">    <span class="type">int</span> numa_node_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">NUMAOptimizedMatrix</span>(<span class="type">int</span> size, <span class="type">int</span> numa_node) </span><br><span class="line">        : <span class="built_in">size_</span>(size), <span class="built_in">numa_node_</span>(numa_node) &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 在本地NUMA节点分配内存</span></span><br><span class="line">        matrix_a_ = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>*&gt;(</span><br><span class="line">            <span class="built_in">numa_alloc_onnode</span>(size * size * <span class="built_in">sizeof</span>(<span class="type">double</span>), numa_node_));</span><br><span class="line">        matrix_b_ = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>*&gt;(</span><br><span class="line">            <span class="built_in">numa_alloc_onnode</span>(size * size * <span class="built_in">sizeof</span>(<span class="type">double</span>), numa_node_));</span><br><span class="line">        matrix_c_ = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>*&gt;(</span><br><span class="line">            <span class="built_in">numa_alloc_onnode</span>(size * size * <span class="built_in">sizeof</span>(<span class="type">double</span>), numa_node_));</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">initialize_matrices</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">multiply_optimized</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> block_size = <span class="number">64</span>;  <span class="comment">// 缓存友好的块大小</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 分块矩阵乘法</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size_; i += block_size) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; size_; j += block_size) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; size_; k += block_size) &#123;</span><br><span class="line">                    <span class="built_in">multiply_block</span>(i, j, k, block_size);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">multiply_block</span><span class="params">(<span class="type">int</span> i_start, <span class="type">int</span> j_start, <span class="type">int</span> k_start, <span class="type">int</span> block_size)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> i_end = std::<span class="built_in">min</span>(i_start + block_size, size_);</span><br><span class="line">        <span class="type">int</span> j_end = std::<span class="built_in">min</span>(j_start + block_size, size_);</span><br><span class="line">        <span class="type">int</span> k_end = std::<span class="built_in">min</span>(k_start + block_size, size_);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = i_start; i &lt; i_end; ++i) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = j_start; j &lt; j_end; ++j) &#123;</span><br><span class="line">                <span class="type">double</span> sum = <span class="number">0.0</span>;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> k = k_start; k &lt; k_end; ++k) &#123;</span><br><span class="line">                    sum += matrix_a_[i * size_ + k] * matrix_b_[k * size_ + j];</span><br><span class="line">                &#125;</span><br><span class="line">                matrix_c_[i * size_ + j] += sum;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">initialize_matrices</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size_ * size_; ++i) &#123;</span><br><span class="line">            matrix_a_[i] = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(<span class="built_in">rand</span>()) / RAND_MAX;</span><br><span class="line">            matrix_b_[i] = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(<span class="built_in">rand</span>()) / RAND_MAX;</span><br><span class="line">            matrix_c_[i] = <span class="number">0.0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="5-性能监控和调优"><a href="#5-性能监控和调优" class="headerlink" title="5. 性能监控和调优"></a>5. 性能监控和调优</h2><h3 id="5-1-性能计数器"><a href="#5-1-性能计数器" class="headerlink" title="5.1 性能计数器"></a>5.1 性能计数器</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用性能计数器监控缓存性能</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CachePerformanceMonitor</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">CacheStats</span> &#123;</span><br><span class="line">        <span class="type">uint64_t</span> l1_misses;</span><br><span class="line">        <span class="type">uint64_t</span> l2_misses;</span><br><span class="line">        <span class="type">uint64_t</span> l3_misses;</span><br><span class="line">        <span class="type">uint64_t</span> tlb_misses;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> CacheStats <span class="title">get_cache_stats</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        CacheStats stats = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">        </span><br><span class="line">        <span class="meta">#<span class="keyword">ifdef</span> __linux__</span></span><br><span class="line">        <span class="comment">// 使用perf_event_open读取硬件计数器</span></span><br><span class="line">        <span class="type">int</span> fd = <span class="built_in">perf_event_open</span>(&amp;pe, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (fd != <span class="number">-1</span>) &#123;</span><br><span class="line">            <span class="built_in">read</span>(fd, &amp;stats, <span class="built_in">sizeof</span>(stats));</span><br><span class="line">            <span class="built_in">close</span>(fd);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> stats;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">print_cache_stats</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        CacheStats stats = <span class="built_in">get_cache_stats</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Cache Performance:\n&quot;</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  L1 Misses: %lu\n&quot;</span>, stats.l1_misses);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  L2 Misses: %lu\n&quot;</span>, stats.l2_misses);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  L3 Misses: %lu\n&quot;</span>, stats.l3_misses);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  TLB Misses: %lu\n&quot;</span>, stats.tlb_misses);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="5-2-NUMA统计信息"><a href="#5-2-NUMA统计信息" class="headerlink" title="5.2 NUMA统计信息"></a>5.2 NUMA统计信息</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NUMA性能监控</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NUMAPerformanceMonitor</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">print_numa_stats</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> num_nodes = <span class="built_in">numa_num_configured_nodes</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;NUMA Statistics:\n&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> node = <span class="number">0</span>; node &lt; num_nodes; ++node) &#123;</span><br><span class="line">            <span class="keyword">struct</span> <span class="title class_">bitmask</span>* cpus = <span class="built_in">numa_allocate_cpumask</span>();</span><br><span class="line">            <span class="built_in">numa_node_to_cpus</span>(node, cpus);</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;  Node %d:\n&quot;</span>, node);</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;    CPUs: &quot;</span>);</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> cpu = <span class="number">0</span>; cpu &lt; <span class="built_in">numa_num_configured_cpus</span>(); ++cpu) &#123;</span><br><span class="line">                <span class="keyword">if</span> (<span class="built_in">numa_bitmask_isbitset</span>(cpus, cpu)) &#123;</span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, cpu);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">numa_free_cpumask</span>(cpus);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">benchmark_numa_access</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> num_nodes = <span class="built_in">numa_num_configured_nodes</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> node = <span class="number">0</span>; node &lt; num_nodes; ++node) &#123;</span><br><span class="line">            <span class="comment">// 分配本地内存</span></span><br><span class="line">            <span class="type">void</span>* local_mem = <span class="built_in">numa_alloc_onnode</span>(<span class="number">1024</span> * <span class="number">1024</span>, node);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 分配远程内存</span></span><br><span class="line">            <span class="type">void</span>* remote_mem = <span class="built_in">numa_alloc_onnode</span>(<span class="number">1024</span> * <span class="number">1024</span>, (node + <span class="number">1</span>) % num_nodes);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 测试访问延迟</span></span><br><span class="line">            <span class="keyword">auto</span> start = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">                <span class="built_in">static_cast</span>&lt;<span class="type">char</span>*&gt;(local_mem)[i % <span class="number">1024</span>] = i;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">auto</span> local_end = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">                <span class="built_in">static_cast</span>&lt;<span class="type">char</span>*&gt;(remote_mem)[i % <span class="number">1024</span>] = i;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">auto</span> remote_end = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">auto</span> local_time = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::microseconds&gt;(</span><br><span class="line">                local_end - start).<span class="built_in">count</span>();</span><br><span class="line">            <span class="keyword">auto</span> remote_time = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::microseconds&gt;(</span><br><span class="line">                remote_end - local_end).<span class="built_in">count</span>();</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Node %d: Local=%ldμs, Remote=%ldμs, Ratio=%.2f\n&quot;</span>, </span><br><span class="line">                   node, local_time, remote_time, </span><br><span class="line">                   <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(remote_time) / local_time);</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">numa_free</span>(local_mem, <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">            <span class="built_in">numa_free</span>(remote_mem, <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="6-最佳实践总结"><a href="#6-最佳实践总结" class="headerlink" title="6. 最佳实践总结"></a>6. 最佳实践总结</h2><h3 id="6-1-CPU绑定最佳实践"><a href="#6-1-CPU绑定最佳实践" class="headerlink" title="6.1 CPU绑定最佳实践"></a>6.1 CPU绑定最佳实践</h3><ol>
<li><strong>选择合适的核心</strong>：避免绑定到同一个物理核心的超线程</li>
<li><strong>考虑NUMA节点</strong>：将线程绑定到同一NUMA节点的核心上</li>
<li><strong>监控性能</strong>：使用性能计数器验证绑定效果</li>
<li><strong>动态调整</strong>：根据负载情况动态调整绑定策略</li>
</ol>
<h3 id="6-2-NUMA优化最佳实践"><a href="#6-2-NUMA优化最佳实践" class="headerlink" title="6.2 NUMA优化最佳实践"></a>6.2 NUMA优化最佳实践</h3><ol>
<li><strong>本地内存分配</strong>：优先在本地NUMA节点分配内存</li>
<li><strong>数据局部性</strong>：将相关数据放在同一NUMA节点</li>
<li><strong>线程亲和性</strong>：将线程绑定到数据所在的NUMA节点</li>
<li><strong>负载均衡</strong>：避免单个NUMA节点过载</li>
</ol>
<h3 id="6-3-缓存优化最佳实践"><a href="#6-3-缓存优化最佳实践" class="headerlink" title="6.3 缓存优化最佳实践"></a>6.3 缓存优化最佳实践</h3><ol>
<li><strong>缓存行对齐</strong>：确保数据结构按缓存行对齐</li>
<li><strong>顺序访问</strong>：尽量使用顺序访问模式</li>
<li><strong>预取优化</strong>：合理使用软件和硬件预取</li>
<li><strong>减少伪共享</strong>：避免不同线程访问同一缓存行的不同部分</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>CPU绑定和NUMA感知编程是现代高性能计算的重要技术。通过理解底层原理并正确应用这些技术，可以显著提升应用程序的性能。关键是要根据具体的应用场景和硬件特性，选择合适的优化策略。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.intel.com/content/dam/doc/manual/64-ia-32-architectures-optimization-manual.pdf">Intel 64 and IA-32 Architectures Optimization Reference Manual</a></li>
<li><a target="_blank" rel="noopener" href="https://www.amd.com/system/files/TechDocs/24594.pdf">AMD64 Architecture Programmer’s Manual</a></li>
<li><a target="_blank" rel="noopener" href="https://lwn.net/Articles/254445/">NUMA-aware Programming</a></li>
<li><a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin-guide/cpu-affinity.html">CPU Affinity and Performance</a></li>
<li><a target="_blank" rel="noopener" href="https://www.intel.com/content/www/us/en/developer/articles/technical/cache-performance-and-optimization.html">Cache Performance and Optimization</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/10/Programming/CPP/modern%20cpu/" data-id="cmdpf31az0037q0onegs01dvh" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Programming/CPP/jemalloc" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/10/Programming/CPP/jemalloc/" class="article-date">
  <time class="dt-published" datetime="2025-07-10T01:24:11.149Z" itemprop="datePublished">2025-07-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="jemalloc-内存分配器详解"><a href="#jemalloc-内存分配器详解" class="headerlink" title="jemalloc 内存分配器详解"></a>jemalloc 内存分配器详解</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>jemalloc 是一个通用的内存分配器，由 Jason Evans 开发，最初为 FreeBSD 系统设计，现在被广泛应用于各种高性能系统中。它以其出色的内存碎片控制、多线程性能和可扩展性而闻名。</p>
<h2 id="1-jemalloc-核心原理"><a href="#1-jemalloc-核心原理" class="headerlink" title="1. jemalloc 核心原理"></a>1. jemalloc 核心原理</h2><h3 id="1-1-设计目标"><a href="#1-1-设计目标" class="headerlink" title="1.1 设计目标"></a>1.1 设计目标</h3><p>jemalloc 的设计目标包括：</p>
<ul>
<li><strong>减少内存碎片</strong>：通过精心设计的内存布局和分配策略</li>
<li><strong>提高多线程性能</strong>：减少线程间的锁竞争</li>
<li><strong>可扩展性</strong>：支持大内存分配和多种分配模式</li>
<li><strong>可观测性</strong>：提供详细的内存使用统计信息</li>
</ul>
<h3 id="1-2-内存布局架构"><a href="#1-2-内存布局架构" class="headerlink" title="1.2 内存布局架构"></a>1.2 内存布局架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">jemalloc 内存布局：</span><br><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│                    Arena (竞技场)                            │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  Chunk (2MB)  │  Chunk (2MB)  │  Chunk (2MB)  │  ...        │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  Run (页组)   │  Run (页组)   │  Run (页组)   │  ...        │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  Bin (大小类) │  Bin (大小类) │  Bin (大小类) │  ...        │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="1-3-核心组件"><a href="#1-3-核心组件" class="headerlink" title="1.3 核心组件"></a>1.3 核心组件</h3><h4 id="Arena-竞技场"><a href="#Arena-竞技场" class="headerlink" title="Arena (竞技场)"></a>Arena (竞技场)</h4><ul>
<li>每个 Arena 管理独立的内存池</li>
<li>默认情况下，每个 CPU 核心对应一个 Arena</li>
<li>减少线程间的锁竞争</li>
</ul>
<h4 id="Chunk-大块"><a href="#Chunk-大块" class="headerlink" title="Chunk (大块)"></a>Chunk (大块)</h4><ul>
<li>大小为 2MB 的内存块</li>
<li>是 Arena 分配的基本单位</li>
<li>支持不同的内存对齐要求</li>
</ul>
<h4 id="Run-页组"><a href="#Run-页组" class="headerlink" title="Run (页组)"></a>Run (页组)</h4><ul>
<li>由连续的页面组成</li>
<li>每个 Run 专门用于特定大小的分配</li>
<li>减少内存碎片</li>
</ul>
<h4 id="Bin-大小类"><a href="#Bin-大小类" class="headerlink" title="Bin (大小类)"></a>Bin (大小类)</h4><ul>
<li>将相似大小的分配请求归类</li>
<li>减少内存浪费</li>
<li>提高分配效率</li>
</ul>
<h2 id="2-分配策略"><a href="#2-分配策略" class="headerlink" title="2. 分配策略"></a>2. 分配策略</h2><h3 id="2-1-大小分类"><a href="#2-1-大小分类" class="headerlink" title="2.1 大小分类"></a>2.1 大小分类</h3><p>jemalloc 将分配请求按大小分为几类：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 小对象分配 (≤ 8KB)</span></span><br><span class="line"><span class="keyword">if</span> (size &lt;= <span class="number">8</span> * <span class="number">1024</span>) &#123;</span><br><span class="line">    <span class="comment">// 使用 Bin 分配</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">bin_alloc</span>(size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 大对象分配 (8KB - 2MB)</span></span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (size &lt;= <span class="number">2</span> * <span class="number">1024</span> * <span class="number">1024</span>) &#123;</span><br><span class="line">    <span class="comment">// 使用 Run 分配</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">run_alloc</span>(size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 超大对象分配 (&gt; 2MB)</span></span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 直接使用 mmap</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">huge_alloc</span>(size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-2-线程本地缓存-TLS"><a href="#2-2-线程本地缓存-TLS" class="headerlink" title="2.2 线程本地缓存 (TLS)"></a>2.2 线程本地缓存 (TLS)</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 线程本地缓存结构</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">tcache_s</span> &#123;</span><br><span class="line">    <span class="type">tcache_bin_t</span> bins[TCACHE_NBINS];  <span class="comment">// 每个大小类的缓存</span></span><br><span class="line">    <span class="type">uint32_t</span> gc_incr;                 <span class="comment">// 垃圾回收增量</span></span><br><span class="line">    <span class="type">uint32_t</span> counts[TCACHE_NBINS];    <span class="comment">// 每个bin的计数</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 快速分配路径</span></span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="title">fast_alloc</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="type">tcache_bin_t</span>* bin = &amp;tcache-&gt;bins[<span class="built_in">size_to_bin</span>(size)];</span><br><span class="line">    <span class="keyword">if</span> (bin-&gt;ncached &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 从线程本地缓存分配</span></span><br><span class="line">        <span class="keyword">return</span> bin-&gt;avail[--bin-&gt;ncached];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 回退到 Arena 分配</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">arena_alloc</span>(size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-内存回收策略"><a href="#2-3-内存回收策略" class="headerlink" title="2.3 内存回收策略"></a>2.3 内存回收策略</h3><h4 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h4><ul>
<li>定期触发垃圾回收</li>
<li>将线程本地缓存的对象归还给 Arena</li>
<li>减少内存占用</li>
</ul>
<h4 id="内存合并"><a href="#内存合并" class="headerlink" title="内存合并"></a>内存合并</h4><ul>
<li>合并相邻的空闲块</li>
<li>减少内存碎片</li>
<li>提高内存利用率</li>
</ul>
<h2 id="3-多线程优化"><a href="#3-多线程优化" class="headerlink" title="3. 多线程优化"></a>3. 多线程优化</h2><h3 id="3-1-Arena-分配"><a href="#3-1-Arena-分配" class="headerlink" title="3.1 Arena 分配"></a>3.1 Arena 分配</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Arena 分配策略</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">arena_s</span> &#123;</span><br><span class="line">    <span class="type">malloc_mutex_t</span> lock;           <span class="comment">// Arena 锁</span></span><br><span class="line">    <span class="type">chunk_alloc_t</span>* chunk_alloc;    <span class="comment">// Chunk 分配器</span></span><br><span class="line">    <span class="type">chunk_dalloc_t</span>* chunk_dalloc;  <span class="comment">// Chunk 释放器</span></span><br><span class="line">    <span class="type">arena_bin_t</span> bins[NBINS];       <span class="comment">// 大小类数组</span></span><br><span class="line">    <span class="type">arena_runs_dirty_t</span> runs_dirty; <span class="comment">// 脏页管理</span></span><br><span class="line">    <span class="type">arena_large_t</span>* large;          <span class="comment">// 大对象管理</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 线程到 Arena 的映射</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">arena_t</span>* <span class="title">arena_choose</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> arena_ind = <span class="built_in">atomic_fetch_add_u</span>(&amp;arenas_next_ind, <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> arenas[arena_ind % narenas_auto];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-锁优化"><a href="#3-2-锁优化" class="headerlink" title="3.2 锁优化"></a>3.2 锁优化</h3><ul>
<li><strong>细粒度锁</strong>：每个 Arena 有独立的锁</li>
<li><strong>无锁分配</strong>：线程本地缓存无需加锁</li>
<li><strong>锁分片</strong>：减少锁竞争</li>
</ul>
<h2 id="4-使用场景"><a href="#4-使用场景" class="headerlink" title="4. 使用场景"></a>4. 使用场景</h2><h3 id="4-1-高性能服务器"><a href="#4-1-高性能服务器" class="headerlink" title="4.1 高性能服务器"></a>4.1 高性能服务器</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在 C++ 项目中使用 jemalloc</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;jemalloc/jemalloc.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HighPerformanceServer</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 自定义内存分配器</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">JemallocAllocator</span> &#123;</span><br><span class="line">        <span class="function"><span class="type">void</span>* <span class="title">allocate</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">je_malloc</span>(size);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">            <span class="built_in">je_free</span>(ptr);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    std::vector&lt;<span class="type">int</span>, JemallocAllocator&gt; data_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">process_request</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 使用 jemalloc 进行内存分配</span></span><br><span class="line">        <span class="keyword">auto</span> buffer = std::<span class="built_in">make_unique</span>&lt;<span class="type">char</span>[]&gt;(<span class="number">1024</span>);</span><br><span class="line">        <span class="comment">// 处理请求...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="4-2-数据库系统"><a href="#4-2-数据库系统" class="headerlink" title="4.2 数据库系统"></a>4.2 数据库系统</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Redis 使用 jemalloc 的示例</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_JEMALLOC</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;jemalloc/jemalloc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> malloc je_malloc</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> free je_free</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> realloc je_realloc</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> calloc je_calloc</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 内存统计</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">print_memory_stats</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">size_t</span> allocated, active, metadata;</span><br><span class="line">    <span class="type">size_t</span> len = <span class="built_in">sizeof</span>(<span class="type">size_t</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">mallctl</span>(<span class="string">&quot;stats.allocated&quot;</span>, &amp;allocated, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">mallctl</span>(<span class="string">&quot;stats.active&quot;</span>, &amp;active, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">mallctl</span>(<span class="string">&quot;stats.metadata&quot;</span>, &amp;metadata, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Allocated: %zu, Active: %zu, Metadata: %zu\n&quot;</span>, </span><br><span class="line">           allocated, active, metadata);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-3-游戏引擎"><a href="#4-3-游戏引擎" class="headerlink" title="4.3 游戏引擎"></a>4.3 游戏引擎</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 游戏引擎中的内存管理</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GameEngine</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 对象池使用 jemalloc</span></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">ObjectPool</span> &#123;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        std::vector&lt;T*, JemallocAllocator&gt; pool_;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function">T* <span class="title">acquire</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (pool_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">je_malloc</span>(<span class="built_in">sizeof</span>(T));</span><br><span class="line">            &#125;</span><br><span class="line">            T* obj = pool_.<span class="built_in">back</span>();</span><br><span class="line">            pool_.<span class="built_in">pop_back</span>();</span><br><span class="line">            <span class="keyword">return</span> obj;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">release</span><span class="params">(T* obj)</span> </span>&#123;</span><br><span class="line">            pool_.<span class="built_in">push_back</span>(obj);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="5-配置和调优"><a href="#5-配置和调优" class="headerlink" title="5. 配置和调优"></a>5. 配置和调优</h2><h3 id="5-1-编译时配置"><a href="#5-1-编译时配置" class="headerlink" title="5.1 编译时配置"></a>5.1 编译时配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译 jemalloc</span></span><br><span class="line">./configure --prefix=/usr/local/jemalloc \</span><br><span class="line">           --enable-prof \</span><br><span class="line">           --enable-stats \</span><br><span class="line">           --enable-debug</span><br><span class="line"></span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"></span><br><span class="line"><span class="comment"># 链接 jemalloc</span></span><br><span class="line">g++ -o myapp myapp.cpp -ljemalloc</span><br></pre></td></tr></table></figure>

<h3 id="5-2-运行时配置"><a href="#5-2-运行时配置" class="headerlink" title="5.2 运行时配置"></a>5.2 运行时配置</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置 Arena 数量</span></span><br><span class="line"><span class="built_in">mallctl</span>(<span class="string">&quot;arenas.narenas&quot;</span>, &amp;narenas, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置线程本地缓存大小</span></span><br><span class="line"><span class="type">size_t</span> tcache_max = <span class="number">1024</span>;</span><br><span class="line"><span class="built_in">mallctl</span>(<span class="string">&quot;tcache.max&quot;</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>, &amp;tcache_max, <span class="built_in">sizeof</span>(tcache_max));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 启用内存统计</span></span><br><span class="line"><span class="type">bool</span> stats_active = <span class="literal">true</span>;</span><br><span class="line"><span class="built_in">mallctl</span>(<span class="string">&quot;stats.active&quot;</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>, &amp;stats_active, <span class="built_in">sizeof</span>(stats_active));</span><br></pre></td></tr></table></figure>

<h3 id="5-3-环境变量"><a href="#5-3-环境变量" class="headerlink" title="5.3 环境变量"></a>5.3 环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置 Arena 数量</span></span><br><span class="line"><span class="built_in">export</span> MALLOC_CONF=<span class="string">&quot;narenas:8&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用内存统计</span></span><br><span class="line"><span class="built_in">export</span> MALLOC_CONF=<span class="string">&quot;stats:true&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置线程本地缓存</span></span><br><span class="line"><span class="built_in">export</span> MALLOC_CONF=<span class="string">&quot;tcache_max:1024&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用内存分析</span></span><br><span class="line"><span class="built_in">export</span> MALLOC_CONF=<span class="string">&quot;prof:true,prof_prefix:/tmp/jeprof&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="6-常见问题和解决方案"><a href="#6-常见问题和解决方案" class="headerlink" title="6. 常见问题和解决方案"></a>6. 常见问题和解决方案</h2><h3 id="6-1-内存泄漏检测"><a href="#6-1-内存泄漏检测" class="headerlink" title="6.1 内存泄漏检测"></a>6.1 内存泄漏检测</h3><p>jemalloc 可能会暴露原本存在的内存问题：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 问题代码：内存泄漏</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemoryLeakExample</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span>* data_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MemoryLeakExample</span>() &#123;</span><br><span class="line">        data_ = <span class="keyword">new</span> <span class="type">int</span>[<span class="number">1000</span>];  <span class="comment">// 分配内存</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ~<span class="built_in">MemoryLeakExample</span>() &#123;</span><br><span class="line">        <span class="comment">// 忘记释放内存！</span></span><br><span class="line">        <span class="comment">// delete[] data_;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 解决方案：使用智能指针</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SafeExample</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::unique_ptr&lt;<span class="type">int</span>[]&gt; data_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">SafeExample</span>() : <span class="built_in">data_</span>(std::<span class="built_in">make_unique</span>&lt;<span class="type">int</span>[]&gt;(<span class="number">1000</span>)) &#123;&#125;</span><br><span class="line">    <span class="comment">// 析构函数自动释放内存</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="6-2-内存碎片问题"><a href="#6-2-内存碎片问题" class="headerlink" title="6.2 内存碎片问题"></a>6.2 内存碎片问题</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 问题：频繁分配释放不同大小的内存</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">fragment_memory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;<span class="type">void</span>*&gt; ptrs;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; ++i) &#123;</span><br><span class="line">        <span class="comment">// 分配不同大小的内存</span></span><br><span class="line">        <span class="type">size_t</span> size = <span class="number">16</span> + (i % <span class="number">100</span>) * <span class="number">8</span>;</span><br><span class="line">        ptrs.<span class="built_in">push_back</span>(<span class="built_in">malloc</span>(size));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 随机释放一些内存</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">500</span>; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> idx = <span class="built_in">rand</span>() % ptrs.<span class="built_in">size</span>();</span><br><span class="line">        <span class="built_in">free</span>(ptrs[idx]);</span><br><span class="line">        ptrs.<span class="built_in">erase</span>(ptrs.<span class="built_in">begin</span>() + idx);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 释放剩余内存</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">void</span>* ptr : ptrs) &#123;</span><br><span class="line">        <span class="built_in">free</span>(ptr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 解决方案：使用对象池</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ObjectPool</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::stack&lt;T*&gt; pool_;</span><br><span class="line">    std::mutex mutex_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">T* <span class="title">acquire</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        <span class="keyword">if</span> (pool_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">T</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        T* obj = pool_.<span class="built_in">top</span>();</span><br><span class="line">        pool_.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">release</span><span class="params">(T* obj)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        pool_.<span class="built_in">push</span>(obj);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="6-3-性能调优"><a href="#6-3-性能调优" class="headerlink" title="6.3 性能调优"></a>6.3 性能调优</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 监控内存使用</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemoryMonitor</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">print_stats</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">size_t</span> allocated, active, metadata;</span><br><span class="line">        <span class="type">size_t</span> len = <span class="built_in">sizeof</span>(<span class="type">size_t</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.allocated&quot;</span>, &amp;allocated, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.active&quot;</span>, &amp;active, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.metadata&quot;</span>, &amp;metadata, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Memory Stats:\n&quot;</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  Allocated: %zu bytes\n&quot;</span>, allocated);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  Active: %zu bytes\n&quot;</span>, active);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  Metadata: %zu bytes\n&quot;</span>, metadata);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  Fragmentation: %.2f%%\n&quot;</span>, </span><br><span class="line">               (<span class="type">double</span>)(active - allocated) / active * <span class="number">100</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">enable_profiling</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">bool</span> prof_active = <span class="literal">true</span>;</span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;prof.active&quot;</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>, &amp;prof_active, <span class="built_in">sizeof</span>(prof_active));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="7-性能对比"><a href="#7-性能对比" class="headerlink" title="7. 性能对比"></a>7. 性能对比</h2><h3 id="7-1-与系统-malloc-对比"><a href="#7-1-与系统-malloc-对比" class="headerlink" title="7.1 与系统 malloc 对比"></a>7.1 与系统 malloc 对比</h3><table>
<thead>
<tr>
<th>指标</th>
<th>系统 malloc</th>
<th>jemalloc</th>
<th>改进</th>
</tr>
</thead>
<tbody><tr>
<td>分配速度</td>
<td>基准</td>
<td>+15-25%</td>
<td>显著提升</td>
</tr>
<tr>
<td>内存碎片</td>
<td>基准</td>
<td>-50-70%</td>
<td>大幅减少</td>
</tr>
<tr>
<td>多线程性能</td>
<td>基准</td>
<td>+100-200%</td>
<td>显著提升</td>
</tr>
<tr>
<td>内存占用</td>
<td>基准</td>
<td>-10-20%</td>
<td>适度减少</td>
</tr>
</tbody></table>
<h3 id="7-2-实际测试数据"><a href="#7-2-实际测试数据" class="headerlink" title="7.2 实际测试数据"></a>7.2 实际测试数据</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 性能测试代码</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;chrono&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">benchmark_allocator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> num_allocations = <span class="number">1000000</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> num_threads = <span class="number">8</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">auto</span> start = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    </span><br><span class="line">    std::vector&lt;std::thread&gt; threads;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> t = <span class="number">0</span>; t &lt; num_threads; ++t) &#123;</span><br><span class="line">        threads.<span class="built_in">emplace_back</span>([num_allocations]() &#123;</span><br><span class="line">            std::vector&lt;<span class="type">void</span>*&gt; ptrs;</span><br><span class="line">            ptrs.<span class="built_in">reserve</span>(num_allocations);</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; num_allocations; ++i) &#123;</span><br><span class="line">                <span class="type">size_t</span> size = <span class="number">16</span> + (i % <span class="number">1000</span>) * <span class="number">8</span>;</span><br><span class="line">                ptrs.<span class="built_in">push_back</span>(<span class="built_in">malloc</span>(size));</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">void</span>* ptr : ptrs) &#123;</span><br><span class="line">                <span class="built_in">free</span>(ptr);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; thread : threads) &#123;</span><br><span class="line">        thread.<span class="built_in">join</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">auto</span> end = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    <span class="keyword">auto</span> duration = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::milliseconds&gt;(end - start);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Allocation benchmark completed in %lld ms\n&quot;</span>, duration.<span class="built_in">count</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="8-最佳实践"><a href="#8-最佳实践" class="headerlink" title="8. 最佳实践"></a>8. 最佳实践</h2><h3 id="8-1-内存分配模式"><a href="#8-1-内存分配模式" class="headerlink" title="8.1 内存分配模式"></a>8.1 内存分配模式</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 好的实践：批量分配</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BatchAllocator</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::vector&lt;<span class="type">void</span>*&gt; batch_;</span><br><span class="line">    <span class="type">size_t</span> batch_size_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">BatchAllocator</span>(<span class="type">size_t</span> batch_size = <span class="number">1000</span>) : <span class="built_in">batch_size_</span>(batch_size) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span>* <span class="title">allocate</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (batch_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="comment">// 批量预分配</span></span><br><span class="line">            batch_.<span class="built_in">reserve</span>(batch_size_);</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; batch_size_; ++i) &#123;</span><br><span class="line">                batch_.<span class="built_in">push_back</span>(<span class="built_in">malloc</span>(size));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="type">void</span>* ptr = batch_.<span class="built_in">back</span>();</span><br><span class="line">        batch_.<span class="built_in">pop_back</span>();</span><br><span class="line">        <span class="keyword">return</span> ptr;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">        batch_.<span class="built_in">push_back</span>(ptr);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (batch_.<span class="built_in">size</span>() &gt; batch_size_ * <span class="number">2</span>) &#123;</span><br><span class="line">            <span class="comment">// 清理多余的缓存</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">size_t</span> i = batch_size_; i &lt; batch_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">                <span class="built_in">free</span>(batch_[i]);</span><br><span class="line">            &#125;</span><br><span class="line">            batch_.<span class="built_in">resize</span>(batch_size_);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="8-2-内存对齐"><a href="#8-2-内存对齐" class="headerlink" title="8.2 内存对齐"></a>8.2 内存对齐</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 内存对齐分配</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlignedAllocator</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span>* <span class="title">allocate_aligned</span><span class="params">(<span class="type">size_t</span> size, <span class="type">size_t</span> alignment)</span> </span>&#123;</span><br><span class="line">        <span class="type">void</span>* ptr = <span class="literal">nullptr</span>;</span><br><span class="line">        <span class="type">int</span> result = <span class="built_in">posix_memalign</span>(&amp;ptr, alignment, size);</span><br><span class="line">        <span class="keyword">if</span> (result != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> std::<span class="built_in">bad_alloc</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ptr;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">deallocate_aligned</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">free</span>(ptr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用示例</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlignedBuffer</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">void</span>* data_;</span><br><span class="line">    <span class="type">size_t</span> size_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">AlignedBuffer</span>(<span class="type">size_t</span> size, <span class="type">size_t</span> alignment = <span class="number">64</span>) </span><br><span class="line">        : <span class="built_in">size_</span>(size) &#123;</span><br><span class="line">        data_ = AlignedAllocator::<span class="built_in">allocate_aligned</span>(size, alignment);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ~<span class="built_in">AlignedBuffer</span>() &#123;</span><br><span class="line">        AlignedAllocator::<span class="built_in">deallocate_aligned</span>(data_);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span>* <span class="title">data</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> data_; &#125;</span><br><span class="line">    <span class="function"><span class="type">size_t</span> <span class="title">size</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> size_; &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="8-3-内存池设计"><a href="#8-3-内存池设计" class="headerlink" title="8.3 内存池设计"></a>8.3 内存池设计</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 固定大小内存池</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="type">size_t</span> BlockSize&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FixedSizePool</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">Block</span> &#123;</span><br><span class="line">        Block* next;</span><br><span class="line">        <span class="type">char</span> data[BlockSize];</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    Block* free_list_;</span><br><span class="line">    std::vector&lt;Block*&gt; allocated_blocks_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">FixedSizePool</span>() : <span class="built_in">free_list_</span>(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span>* <span class="title">allocate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!free_list_) &#123;</span><br><span class="line">            <span class="built_in">allocate_new_block</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        Block* block = free_list_;</span><br><span class="line">        free_list_ = block-&gt;next;</span><br><span class="line">        allocated_blocks_.<span class="built_in">push_back</span>(block);</span><br><span class="line">        <span class="keyword">return</span> block-&gt;data;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">        Block* block = <span class="built_in">reinterpret_cast</span>&lt;Block*&gt;(</span><br><span class="line">            <span class="built_in">reinterpret_cast</span>&lt;<span class="type">char</span>*&gt;(ptr) - <span class="built_in">offsetof</span>(Block, data));</span><br><span class="line">        </span><br><span class="line">        block-&gt;next = free_list_;</span><br><span class="line">        free_list_ = block;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 从已分配列表中移除</span></span><br><span class="line">        <span class="keyword">auto</span> it = std::<span class="built_in">find</span>(allocated_blocks_.<span class="built_in">begin</span>(), </span><br><span class="line">                           allocated_blocks_.<span class="built_in">end</span>(), block);</span><br><span class="line">        <span class="keyword">if</span> (it != allocated_blocks_.<span class="built_in">end</span>()) &#123;</span><br><span class="line">            allocated_blocks_.<span class="built_in">erase</span>(it);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">allocate_new_block</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">size_t</span> blocks_per_chunk = <span class="number">1024</span>;</span><br><span class="line">        Block* chunk = <span class="built_in">reinterpret_cast</span>&lt;Block*&gt;(</span><br><span class="line">            <span class="built_in">malloc</span>(blocks_per_chunk * <span class="built_in">sizeof</span>(Block)));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 构建空闲链表</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; blocks_per_chunk - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">            chunk[i].next = &amp;chunk[i + <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        chunk[blocks_per_chunk - <span class="number">1</span>].next = <span class="literal">nullptr</span>;</span><br><span class="line">        </span><br><span class="line">        free_list_ = &amp;chunk[<span class="number">1</span>];</span><br><span class="line">        allocated_blocks_.<span class="built_in">push_back</span>(&amp;chunk[<span class="number">0</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="9-监控和调试"><a href="#9-监控和调试" class="headerlink" title="9. 监控和调试"></a>9. 监控和调试</h2><h3 id="9-1-内存使用监控"><a href="#9-1-内存使用监控" class="headerlink" title="9.1 内存使用监控"></a>9.1 内存使用监控</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 内存使用监控器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemoryMonitor</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::chrono::steady_clock::time_point last_check_;</span><br><span class="line">    <span class="type">size_t</span> last_allocated_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MemoryMonitor</span>() : <span class="built_in">last_allocated_</span>(<span class="number">0</span>) &#123;</span><br><span class="line">        last_check_ = std::chrono::steady_clock::<span class="built_in">now</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">check_memory_usage</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">size_t</span> allocated, active, metadata;</span><br><span class="line">        <span class="type">size_t</span> len = <span class="built_in">sizeof</span>(<span class="type">size_t</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.allocated&quot;</span>, &amp;allocated, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.active&quot;</span>, &amp;active, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.metadata&quot;</span>, &amp;metadata, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">auto</span> now = std::chrono::steady_clock::<span class="built_in">now</span>();</span><br><span class="line">        <span class="keyword">auto</span> duration = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::seconds&gt;(</span><br><span class="line">            now - last_check_).<span class="built_in">count</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (duration &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="type">size_t</span> diff = allocated - last_allocated_;</span><br><span class="line">            <span class="type">double</span> rate = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(diff) / duration;</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Memory usage: %zu bytes (%.2f bytes/sec)\n&quot;</span>, </span><br><span class="line">                   allocated, rate);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        last_allocated_ = allocated;</span><br><span class="line">        last_check_ = now;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="9-2-内存泄漏检测"><a href="#9-2-内存泄漏检测" class="headerlink" title="9.2 内存泄漏检测"></a>9.2 内存泄漏检测</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 内存泄漏检测器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeakDetector</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::unordered_set&lt;<span class="type">void</span>*&gt; allocated_ptrs_;</span><br><span class="line">    std::mutex mutex_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span>* <span class="title">track_allocation</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        allocated_ptrs_.<span class="built_in">insert</span>(ptr);</span><br><span class="line">        <span class="keyword">return</span> ptr;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">track_deallocation</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        allocated_ptrs_.<span class="built_in">erase</span>(ptr);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">report_leaks</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        <span class="keyword">if</span> (!allocated_ptrs_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Memory leak detected: %zu objects not freed\n&quot;</span>, </span><br><span class="line">                   allocated_ptrs_.<span class="built_in">size</span>());</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">void</span>* ptr : allocated_ptrs_) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;  Leaked pointer: %p\n&quot;</span>, ptr);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局泄漏检测器</span></span><br><span class="line"><span class="type">static</span> LeakDetector g_leak_detector;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 重载 new/delete 进行跟踪</span></span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="type">void</span>* ptr = <span class="built_in">malloc</span>(size);</span><br><span class="line">    g_leak_detector.<span class="built_in">track_allocation</span>(ptr);</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="type">void</span>* ptr)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    g_leak_detector.<span class="built_in">track_deallocation</span>(ptr);</span><br><span class="line">    <span class="built_in">free</span>(ptr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="10-总结"><a href="#10-总结" class="headerlink" title="10. 总结"></a>10. 总结</h2><p>jemalloc 是一个高性能的内存分配器，特别适合多线程环境和高性能应用。它的主要优势包括：</p>
<ol>
<li><strong>减少内存碎片</strong>：通过精心设计的内存布局和分配策略</li>
<li><strong>提高多线程性能</strong>：减少线程间的锁竞争</li>
<li><strong>可扩展性</strong>：支持大内存分配和多种分配模式</li>
<li><strong>可观测性</strong>：提供详细的内存使用统计信息</li>
</ol>
<h3 id="使用建议"><a href="#使用建议" class="headerlink" title="使用建议"></a>使用建议</h3><ol>
<li><strong>选择合适的场景</strong>：多线程、高并发应用</li>
<li><strong>正确配置</strong>：根据应用特点调整参数</li>
<li><strong>监控内存使用</strong>：及时发现和解决问题</li>
<li><strong>遵循最佳实践</strong>：避免常见的内存管理错误</li>
</ol>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ol>
<li><strong>可能暴露内存问题</strong>：jemalloc 的严格内存管理可能暴露原本存在的内存泄漏或越界访问</li>
<li><strong>学习成本</strong>：需要了解其工作原理和配置选项</li>
<li><strong>调试复杂性</strong>：内存问题的调试可能更加复杂</li>
</ol>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/jemalloc/jemalloc">jemalloc 官方文档</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bsdcan.org/2006/papers/jemalloc.pdf">jemalloc 论文：A Scalable Concurrent malloc(3) Implementation for FreeBSD</a></li>
<li><a target="_blank" rel="noopener" href="https://redis.io/topics/memory-optimization">Redis 内存优化实践</a></li>
<li><a target="_blank" rel="noopener" href="https://engineering.fb.com/2011/01/03/core-data/scalable-memory-allocation-using-jemalloc/">Facebook 内存分配器对比</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29216091">知乎：jemalloc 内存分配器详解</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhangyifei216/article/details/52247365">CSDN：jemalloc 源码分析</a></li>
<li><a target="_blank" rel="noopener" href="https://tech.meituan.com/2019/03/07/jemalloc-in-meituan.html">美团技术团队：jemalloc 在美团的实践</a></li>
<li><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1004367">腾讯技术工程：内存分配器对比分析</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/10/Programming/CPP/jemalloc/" data-id="cmdpf31ay0034q0on0c9v4304" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/2/">&laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/4/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/System/">System</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Test/">Test</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AI/" rel="tag">AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Attention/" rel="tag">Attention</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Communication/" rel="tag">Communication</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Compiler/" rel="tag">Compiler</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Computational-Graph/" rel="tag">Computational Graph</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DeepSeek/" rel="tag">DeepSeek</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Distributed/" rel="tag">Distributed</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MoE/" rel="tag">MoE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Optimization/" rel="tag">Optimization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Performance/" rel="tag">Performance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SGLang/" rel="tag">SGLang</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/System/" rel="tag">System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blog/" rel="tag">blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blues/" rel="tag">blues</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/career/" rel="tag">career</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/charts/" rel="tag">charts</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/consensus/" rel="tag">consensus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-parallelism/" rel="tag">data-parallelism</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/distributed-systems/" rel="tag">distributed-systems</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/experience/" rel="tag">experience</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/expert-parallelism/" rel="tag">expert-parallelism</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/guitar/" rel="tag">guitar</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/harmony/" rel="tag">harmony</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/licks/" rel="tag">licks</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/life/" rel="tag">life</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/llm/" rel="tag">llm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mermaid/" rel="tag">mermaid</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/raft/" rel="tag">raft</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rhythm/" rel="tag">rhythm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/test/" rel="tag">test</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/AI/" style="font-size: 10px;">AI</a> <a href="/tags/Attention/" style="font-size: 10px;">Attention</a> <a href="/tags/Communication/" style="font-size: 10px;">Communication</a> <a href="/tags/Compiler/" style="font-size: 10px;">Compiler</a> <a href="/tags/Computational-Graph/" style="font-size: 10px;">Computational Graph</a> <a href="/tags/DeepSeek/" style="font-size: 10px;">DeepSeek</a> <a href="/tags/Distributed/" style="font-size: 10px;">Distributed</a> <a href="/tags/LLM/" style="font-size: 10px;">LLM</a> <a href="/tags/MoE/" style="font-size: 10px;">MoE</a> <a href="/tags/Optimization/" style="font-size: 10px;">Optimization</a> <a href="/tags/Performance/" style="font-size: 10px;">Performance</a> <a href="/tags/SGLang/" style="font-size: 10px;">SGLang</a> <a href="/tags/System/" style="font-size: 15px;">System</a> <a href="/tags/blog/" style="font-size: 10px;">blog</a> <a href="/tags/blues/" style="font-size: 20px;">blues</a> <a href="/tags/career/" style="font-size: 10px;">career</a> <a href="/tags/charts/" style="font-size: 10px;">charts</a> <a href="/tags/consensus/" style="font-size: 10px;">consensus</a> <a href="/tags/data-parallelism/" style="font-size: 10px;">data-parallelism</a> <a href="/tags/distributed-systems/" style="font-size: 20px;">distributed-systems</a> <a href="/tags/experience/" style="font-size: 10px;">experience</a> <a href="/tags/expert-parallelism/" style="font-size: 10px;">expert-parallelism</a> <a href="/tags/guitar/" style="font-size: 20px;">guitar</a> <a href="/tags/harmony/" style="font-size: 10px;">harmony</a> <a href="/tags/licks/" style="font-size: 10px;">licks</a> <a href="/tags/life/" style="font-size: 10px;">life</a> <a href="/tags/llm/" style="font-size: 15px;">llm</a> <a href="/tags/mermaid/" style="font-size: 10px;">mermaid</a> <a href="/tags/raft/" style="font-size: 10px;">raft</a> <a href="/tags/rhythm/" style="font-size: 10px;">rhythm</a> <a href="/tags/test/" style="font-size: 10px;">test</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/07/">July 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/05/">May 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/04/">April 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">March 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/01/">January 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/07/30/System/%E5%B9%B6%E8%A1%8C%E7%AD%96%E7%95%A5/%E5%BA%8F%E5%88%97%E5%B9%B6%E8%A1%8C/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/07/28/PD%E5%88%86%E7%A6%BB%E6%9E%B6%E6%9E%84KVCache%E8%B7%A8%E8%8A%82%E7%82%B9%E4%BC%A0%E8%BE%93%E5%8A%9F%E8%83%BD%E5%BC%80%E5%8F%91%EF%BC%8C%E4%BC%98%E5%8C%96KVCache%E4%BC%A0%E8%BE%93%E6%95%88%E7%8E%87/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/07/28/System/%E5%B9%B6%E8%A1%8C%E7%AD%96%E7%95%A5/EP/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/07/28/System/%E5%B9%B6%E8%A1%8C%E7%AD%96%E7%95%A5/%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E5%9F%BA%E7%A1%80/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/07/28/System/DeepSeek/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>






<!-- Mermaid Support -->
<script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
<script>
  mermaid.initialize({
    startOnLoad: true,
    theme: 'default',
    securityLevel: 'loose',
    themeVariables: {
      primaryColor: '#0f4c75',
      primaryTextColor: '#fff',
      primaryBorderColor: '#0f4c75',
      lineColor: '#0f4c75',
      secondaryColor: '#006ba6',
      tertiaryColor: '#fff'
    }
  });
</script>
  </div>
</body>
</html>