<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/4/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

  
  <!-- Mermaid -->
  <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: 'default',
      securityLevel: 'loose',
      themeVariables: {
        primaryColor: '#0f4c75',
        primaryTextColor: '#fff',
        primaryBorderColor: '#0f4c75',
        lineColor: '#0f4c75',
        secondaryColor: '#006ba6',
        tertiaryColor: '#fff'
      }
    });
  </script>
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-System/LLM_Serving_Framework_Comparison" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/14/System/LLM_Serving_Framework_Comparison/" class="article-date">
  <time class="dt-published" datetime="2025-07-14T03:21:11.628Z" itemprop="datePublished">2025-07-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="LLM-Serving-Framework-Comparison-KVCache-PrefixCache-and-Prefill-Decode-Disaggregation"><a href="#LLM-Serving-Framework-Comparison-KVCache-PrefixCache-and-Prefill-Decode-Disaggregation" class="headerlink" title="LLM Serving Framework Comparison: KVCache, PrefixCache, and Prefill-Decode-Disaggregation"></a>LLM Serving Framework Comparison: KVCache, PrefixCache, and Prefill-Decode-Disaggregation</h1><h2 id="Executive-Summary"><a href="#Executive-Summary" class="headerlink" title="Executive Summary"></a>Executive Summary</h2><p>This document provides a comprehensive analysis of three major LLM serving frameworks: <strong>TensorRT-LLM</strong>, <strong>vLLM</strong>, and <strong>SGLang</strong>, focusing on their implementations of:</p>
<ol>
<li><strong>KV Cache Management</strong> - Memory optimization for attention mechanisms</li>
<li><strong>Prefix Caching</strong> - Reuse of computed attention states for shared prefixes</li>
<li><strong>Prefill-Decode Disaggregation</strong> - Separation of prefill and decode phases for better resource utilization</li>
</ol>
<h2 id="1-KV-Cache-Management"><a href="#1-KV-Cache-Management" class="headerlink" title="1. KV Cache Management"></a>1. KV Cache Management</h2><h3 id="TensorRT-LLM-Implementation"><a href="#TensorRT-LLM-Implementation" class="headerlink" title="TensorRT-LLM Implementation"></a>TensorRT-LLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>kvCacheManager.cpp</code>, <code>kvCacheEventManager.cpp</code>, <code>allocateKvCache.cpp</code></li>
<li><strong>Block-based memory management</strong> with configurable block sizes (16, 32, 64, 128 tokens)</li>
<li><strong>Multi-level cache system</strong> with primary GPU memory and secondary CPU memory for offloading</li>
<li><strong>Paged attention</strong> with TensorRT kernel optimizations</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Hash-based block identification for efficient lookups</li>
<li>Reference counting for memory safety</li>
<li>Priority-based LRU eviction with retention policies</li>
<li>Multi-pool architecture for different KV head configurations</li>
<li>Quantization support (FP8, INT4, AWQ, GPTQ) for memory efficiency</li>
<li>Thread-safe operations with mutex&#x2F;condition variable synchronization</li>
</ul>
<p><strong>Memory Management:</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Block management with priority-based eviction</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BlockManager</span> &#123;</span><br><span class="line">    std::unordered_map&lt;BlockHash, BlockId&gt; cached_blocks;</span><br><span class="line">    std::vector&lt;BlockPool&gt; pools_by_config;</span><br><span class="line">    LRUEvictionPolicy eviction_policy;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="vLLM-Implementation"><a href="#vLLM-Implementation" class="headerlink" title="vLLM Implementation"></a>vLLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>core/block_manager.py</code>, <code>core/block/prefix_caching_block.py</code>, <code>attention/layer.py</code></li>
<li><strong>BlockSpaceManager</strong> for centralized memory allocation</li>
<li><strong>Prefix-aware block allocation</strong> with copy-on-write semantics</li>
<li><strong>Lookahead slots</strong> for speculative decoding support</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Unified block management for both regular and prefix-cached blocks</li>
<li>Sliding window attention support</li>
<li>Advanced scheduling integration with memory-aware allocation</li>
<li>Support for both CPU and GPU memory pools</li>
<li>Seamless integration with attention backends (FlashAttention, etc.)</li>
</ul>
<p><strong>Memory Management:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SelfAttnBlockSpaceManager</span>(<span class="title class_ inherited__">BlockSpaceManager</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block_size: <span class="built_in">int</span>, num_gpu_blocks: <span class="built_in">int</span>, num_cpu_blocks: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.block_allocator = CpuGpuBlockAllocator(...)</span><br><span class="line">        <span class="variable language_">self</span>.block_tables = &#123;&#125;  <span class="comment"># seq_id -&gt; BlockTable</span></span><br></pre></td></tr></table></figure>

<h3 id="SGLang-Implementation"><a href="#SGLang-Implementation" class="headerlink" title="SGLang Implementation"></a>SGLang Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>mem_cache/memory_pool.py</code>, <code>mem_cache/radix_cache.py</code>, <code>mem_cache/swa_radix_cache.py</code></li>
<li><strong>Three-tier memory pool system</strong>: ReqToTokenPool → TokenToKVPoolAllocator → KVCache</li>
<li><strong>RadixAttention</strong> with tree-based prefix sharing</li>
<li><strong>Sliding Window Attention (SWA)</strong> with hybrid full&#x2F;SWA cache management</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Most sophisticated memory hierarchy with multiple abstraction levels</li>
<li>Native support for different attention mechanisms (MHA, MLA, SWA)</li>
<li>Advanced eviction policies with LRU lists and tombstone mechanisms</li>
<li>Host memory backup for cache persistence</li>
<li>Specialized kernels for different hardware (CUDA, Ascend NPU)</li>
</ul>
<p><strong>Memory Management:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReqToTokenPool</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Maps requests to token locations&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TokenToKVPoolAllocator</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Manages KV cache indices&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KVCache</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Physical KV cache storage&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="2-Prefix-Caching"><a href="#2-Prefix-Caching" class="headerlink" title="2. Prefix Caching"></a>2. Prefix Caching</h2><h3 id="TensorRT-LLM-Implementation-1"><a href="#TensorRT-LLM-Implementation-1" class="headerlink" title="TensorRT-LLM Implementation"></a>TensorRT-LLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Hash-based prefix identification</strong> using <code>BlockKeyHasher::hash()</code></li>
<li><strong>Radix tree structure</strong> for hierarchical prefix organization</li>
<li><strong>Partial block reuse</strong> with configurable granularity</li>
<li><strong>Cache hit rate tracking</strong> for performance monitoring</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Block-level prefix matching with configurable page sizes</li>
<li>Copy-on-write semantics for memory efficiency</li>
<li>Sophisticated cache replacement policies</li>
<li>Integration with dynamic profiling for optimization</li>
</ul>
<p><strong>Prefix Matching:</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BlockKeyHasher</span> &#123;</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">uint64_t</span> <span class="title">hash</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">int</span>&gt;&amp; tokens, <span class="type">int</span> extra_hash = <span class="number">0</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">bool</span> <span class="title">matches</span><span class="params">(<span class="type">const</span> BlockKey&amp; key1, <span class="type">const</span> BlockKey&amp; key2)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="vLLM-Implementation-1"><a href="#vLLM-Implementation-1" class="headerlink" title="vLLM Implementation"></a>vLLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>core/block/prefix_caching_block.py</code>, <code>core/block/cpu_gpu_block_allocator.py</code></li>
<li><strong>PrefixCachingBlockAllocator</strong> with content-hash based caching</li>
<li><strong>ComputedBlocksTracker</strong> for managing computed state</li>
<li><strong>Comprehensive prefix cache APIs</strong> across the engine</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Content-based hashing for reliable prefix identification</li>
<li>Immutable vs mutable block distinction</li>
<li>Extensive prefix cache hit rate monitoring</li>
<li>API endpoints for cache management (<code>/reset_prefix_cache</code>)</li>
<li>Integration with speculative decoding</li>
</ul>
<p><strong>Prefix Cache Management:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrefixCachingBlockAllocator</span>(<span class="title class_ inherited__">BlockAllocator</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_blocks: <span class="built_in">int</span>, block_size: <span class="built_in">int</span>, eviction_policy: EvictionPolicy</span>):</span><br><span class="line">        <span class="variable language_">self</span>._cached_blocks: <span class="type">Dict</span>[PrefixHash, BlockId] = &#123;&#125;</span><br><span class="line">        <span class="variable language_">self</span>._touched_blocks: <span class="type">Set</span>[BlockId] = <span class="built_in">set</span>()</span><br><span class="line">        <span class="variable language_">self</span>._block_tracker: <span class="type">Dict</span>[BlockId, BlockTracker] = &#123;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="SGLang-Implementation-1"><a href="#SGLang-Implementation-1" class="headerlink" title="SGLang Implementation"></a>SGLang Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>mem_cache/radix_cache.py</code>, <code>mem_cache/swa_radix_cache.py</code>, <code>mem_cache/hiradix_cache.py</code></li>
<li><strong>RadixCache</strong> with tree-based prefix sharing</li>
<li><strong>SWARadixCache</strong> for sliding window attention</li>
<li><strong>HiRadixCache</strong> for hierarchical caching</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Most advanced prefix caching with multiple cache types</li>
<li>Tree-based prefix sharing with automatic splitting&#x2F;merging</li>
<li>Support for different page sizes and sliding window configurations</li>
<li>Host memory backup for prefix persistence</li>
<li>Event-driven cache management for disaggregated scenarios</li>
</ul>
<p><strong>Radix Tree Implementation:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TreeNode</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.children = defaultdict(TreeNode)</span><br><span class="line">        <span class="variable language_">self</span>.parent: TreeNode = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.key: <span class="type">List</span>[<span class="built_in">int</span>] = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.value: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.lock_ref = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.last_access_time = time.monotonic()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RadixCache</span>(<span class="title class_ inherited__">BasePrefixCache</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">match_prefix</span>(<span class="params">self, key: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; MatchResult:</span><br><span class="line">        <span class="comment"># Tree traversal for prefix matching</span></span><br></pre></td></tr></table></figure>

<h2 id="3-Prefill-Decode-Disaggregation"><a href="#3-Prefill-Decode-Disaggregation" class="headerlink" title="3. Prefill-Decode Disaggregation"></a>3. Prefill-Decode Disaggregation</h2><h3 id="TensorRT-LLM-Implementation-2"><a href="#TensorRT-LLM-Implementation-2" class="headerlink" title="TensorRT-LLM Implementation"></a>TensorRT-LLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>trtGptModelInflightBatching.cpp</code>, <code>dataTransceiverImpl.cpp</code>, <code>cacheTransBuffer.cpp</code></li>
<li><strong>Separate context and generation phases</strong> in model execution</li>
<li><strong>KV cache transfer protocols</strong> for distributed serving</li>
<li><strong>Layer-wise disaggregation</strong> with selective transfer</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Production-ready disaggregation with robust error handling</li>
<li>Optimized cache transfer with bandwidth reduction</li>
<li>Async&#x2F;sync transfer modes with overlap capabilities</li>
<li>Comprehensive metrics and benchmarking support</li>
<li>Integration with TensorRT’s dynamic profiling</li>
</ul>
<p><strong>Cache Transfer:</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CacheTransBuffer</span> &#123;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">transferKVCache</span><span class="params">(LayerId layer, <span class="type">const</span> KVData&amp; data, TransferMode mode)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">waitForTransfer</span><span class="params">(LayerId layer)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">isTransferComplete</span><span class="params">(LayerId layer)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="vLLM-Implementation-2"><a href="#vLLM-Implementation-2" class="headerlink" title="vLLM Implementation"></a>vLLM Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>distributed/kv_transfer/</code>, <code>examples/online_serving/disaggregated_serving/</code></li>
<li><strong>Disaggregated serving examples</strong> with prefill&#x2F;decode separation</li>
<li><strong>KV transfer protocols</strong> for distributed deployment</li>
<li><strong>Proxy-based routing</strong> between prefill and decode instances</li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Reference implementations and examples</li>
<li>Support for different transfer backends (NCCL, gRPC)</li>
<li>Integration with existing vLLM scheduling</li>
<li>Experimental disaggregation features</li>
<li>Focus on ease of deployment and configuration</li>
</ul>
<p><strong>Disaggregated Architecture:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Prefill instance handles context processing</span></span><br><span class="line">prefill_instance = vLLM(model_path, instance_type=<span class="string">&quot;prefill&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decode instance handles generation</span></span><br><span class="line">decode_instance = vLLM(model_path, instance_type=<span class="string">&quot;decode&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Proxy routes requests between instances</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DisaggregatedProxy</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">route_request</span>(<span class="params">self, request</span>):</span><br><span class="line">        <span class="comment"># Route to appropriate instance</span></span><br></pre></td></tr></table></figure>

<h3 id="SGLang-Implementation-2"><a href="#SGLang-Implementation-2" class="headerlink" title="SGLang Implementation"></a>SGLang Implementation</h3><p><strong>Core Architecture:</strong></p>
<ul>
<li><strong>Files</strong>: <code>disaggregation/prefill.py</code>, <code>disaggregation/decode.py</code>, <code>disaggregation/utils.py</code></li>
<li><strong>Comprehensive disaggregation framework</strong> with multiple backends</li>
<li><strong>Advanced queue management</strong> for different phases</li>
<li><strong>Sophisticated KV transfer protocols</strong></li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li>Most comprehensive disaggregation implementation</li>
<li>Support for multiple transfer backends (NIXL, Mooncake, etc.)</li>
<li>Advanced queue management with bootstrap, transfer, and inflight phases</li>
<li>Extensive metadata management for distributed coordination</li>
<li>Integration with RadixAttention for efficient prefix sharing</li>
</ul>
<p><strong>Disaggregation Architecture:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrefillBootstrapQueue</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Bootstrap queue for prefill requests&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecodePreallocQueue</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Pre-allocation queue for decode requests&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecodeTransferQueue</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Transfer queue for KV data&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BaseKVManager</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Abstract base for KV transfer management&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="4-Technical-Comparison-Summary"><a href="#4-Technical-Comparison-Summary" class="headerlink" title="4. Technical Comparison Summary"></a>4. Technical Comparison Summary</h2><h3 id="Performance-Characteristics"><a href="#Performance-Characteristics" class="headerlink" title="Performance Characteristics"></a>Performance Characteristics</h3><table>
<thead>
<tr>
<th>Feature</th>
<th>TensorRT-LLM</th>
<th>vLLM</th>
<th>SGLang</th>
</tr>
</thead>
<tbody><tr>
<td><strong>KV Cache Efficiency</strong></td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
</tr>
<tr>
<td><strong>Prefix Cache Hit Rate</strong></td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
</tr>
<tr>
<td><strong>Disaggregation Maturity</strong></td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
</tr>
<tr>
<td><strong>Memory Efficiency</strong></td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
</tr>
<tr>
<td><strong>Scalability</strong></td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
</tr>
</tbody></table>
<h3 id="Implementation-Complexity"><a href="#Implementation-Complexity" class="headerlink" title="Implementation Complexity"></a>Implementation Complexity</h3><table>
<thead>
<tr>
<th>Aspect</th>
<th>TensorRT-LLM</th>
<th>vLLM</th>
<th>SGLang</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Codebase Size</strong></td>
<td>Large (C++)</td>
<td>Medium (Python)</td>
<td>Large (Python)</td>
</tr>
<tr>
<td><strong>Architecture</strong></td>
<td>Monolithic</td>
<td>Modular</td>
<td>Highly Modular</td>
</tr>
<tr>
<td><strong>Extensibility</strong></td>
<td>Medium</td>
<td>High</td>
<td>Very High</td>
</tr>
<tr>
<td><strong>Documentation</strong></td>
<td>Good</td>
<td>Excellent</td>
<td>Good</td>
</tr>
<tr>
<td><strong>Community</strong></td>
<td>NVIDIA</td>
<td>Very Active</td>
<td>Growing</td>
</tr>
</tbody></table>
<h3 id="Use-Case-Recommendations"><a href="#Use-Case-Recommendations" class="headerlink" title="Use Case Recommendations"></a>Use Case Recommendations</h3><p><strong>TensorRT-LLM:</strong></p>
<ul>
<li>✅ Production deployments requiring maximum performance</li>
<li>✅ NVIDIA GPU-centric environments</li>
<li>✅ Applications needing quantization support</li>
<li>✅ Enterprise deployments with dedicated DevOps teams</li>
</ul>
<p><strong>vLLM:</strong></p>
<ul>
<li>✅ Research and development environments</li>
<li>✅ Rapid prototyping and experimentation</li>
<li>✅ Multi-GPU deployments with good Python ecosystem integration</li>
<li>✅ Applications requiring extensive customization</li>
</ul>
<p><strong>SGLang:</strong></p>
<ul>
<li>✅ Advanced research requiring cutting-edge optimizations</li>
<li>✅ Applications with complex attention patterns (sliding window, etc.)</li>
<li>✅ Disaggregated deployments with sophisticated requirements</li>
<li>✅ Multi-modal and structured generation tasks</li>
</ul>
<h2 id="5-Key-Insights-and-Recommendations"><a href="#5-Key-Insights-and-Recommendations" class="headerlink" title="5. Key Insights and Recommendations"></a>5. Key Insights and Recommendations</h2><h3 id="Architecture-Insights"><a href="#Architecture-Insights" class="headerlink" title="Architecture Insights"></a>Architecture Insights</h3><ol>
<li><strong>SGLang</strong> shows the most sophisticated approach to memory management with its three-tier system and multiple cache types</li>
<li><strong>TensorRT-LLM</strong> provides the most production-ready disaggregation with robust error handling and performance optimization</li>
<li><strong>vLLM</strong> offers the best balance of features and usability for most deployment scenarios</li>
</ol>
<h3 id="Performance-Considerations"><a href="#Performance-Considerations" class="headerlink" title="Performance Considerations"></a>Performance Considerations</h3><ol>
<li><strong>Memory Efficiency</strong>: SGLang &gt; TensorRT-LLM &gt; vLLM</li>
<li><strong>Prefix Cache Effectiveness</strong>: SGLang ≈ TensorRT-LLM &gt; vLLM</li>
<li><strong>Disaggregation Maturity</strong>: TensorRT-LLM ≈ SGLang &gt; vLLM</li>
<li><strong>Deployment Simplicity</strong>: vLLM &gt; SGLang &gt; TensorRT-LLM</li>
</ol>
<h3 id="Future-Trends"><a href="#Future-Trends" class="headerlink" title="Future Trends"></a>Future Trends</h3><ol>
<li><strong>Convergence</strong>: All frameworks are evolving toward similar architectural patterns</li>
<li><strong>Specialization</strong>: Each framework is developing unique strengths for different use cases</li>
<li><strong>Integration</strong>: Increasing focus on multi-modal and structured generation capabilities</li>
<li><strong>Hardware Optimization</strong>: Growing emphasis on hardware-specific optimizations</li>
</ol>
<h2 id="6-Conclusion"><a href="#6-Conclusion" class="headerlink" title="6. Conclusion"></a>6. Conclusion</h2><p>All three frameworks represent significant advances in LLM serving technology, each with distinct strengths:</p>
<ul>
<li><strong>TensorRT-LLM</strong> excels in production-ready performance optimization and NVIDIA ecosystem integration</li>
<li><strong>vLLM</strong> provides the best developer experience and community support for most use cases</li>
<li><strong>SGLang</strong> pushes the boundaries of what’s possible with advanced memory management and disaggregation</li>
</ul>
<p>The choice between frameworks should be based on specific requirements: performance needs, deployment complexity, hardware constraints, and team expertise. For most applications, vLLM provides the best starting point, while TensorRT-LLM offers maximum performance for production deployments, and SGLang enables cutting-edge research and advanced optimizations. </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/14/System/LLM_Serving_Framework_Comparison/" data-id="cme17ov000018wnon7e7ygs7l" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-System/LLM_KVCache_详细分析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/14/System/LLM_KVCache_%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2025-07-14T03:21:11.624Z" itemprop="datePublished">2025-07-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="LLM-Serving-Framework-KV-Cache-管理机制详细分析"><a href="#LLM-Serving-Framework-KV-Cache-管理机制详细分析" class="headerlink" title="LLM Serving Framework KV Cache 管理机制详细分析"></a>LLM Serving Framework KV Cache 管理机制详细分析</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li><a href="#%E6%A6%82%E8%BF%B0">概述</a></li>
<li><a href="#tensorrt-llm-kv-cache-%E7%AE%A1%E7%90%86">TensorRT-LLM KV Cache 管理</a></li>
<li><a href="#vllm-kv-cache-%E7%AE%A1%E7%90%86">vLLM KV Cache 管理</a>  </li>
<li><a href="#sglang-kv-cache-%E7%AE%A1%E7%90%86">SGLang KV Cache 管理</a></li>
<li><a href="#%E6%8A%80%E6%9C%AF%E5%AF%B9%E6%AF%94%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90">技术对比与深度分析</a></li>
<li><a href="#%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5">性能优化策略</a></li>
<li><a href="#%E6%80%BB%E7%BB%93%E4%B8%8E%E5%BB%BA%E8%AE%AE">总结与建议</a></li>
</ol>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>KV Cache是大语言模型推理中最关键的优化技术之一，它通过缓存attention机制中的Key和Value张量来避免重复计算，显著提升推理性能。本文深入分析TensorRT-LLM、vLLM和SGLang三个主流LLM serving框架的KV Cache管理实现。</p>
<h3 id="KV-Cache基本原理"><a href="#KV-Cache基本原理" class="headerlink" title="KV Cache基本原理"></a>KV Cache基本原理</h3><p>在Transformer架构中，每个attention层都需要计算Q、K、V三个矩阵：</p>
<ul>
<li><strong>Query (Q)</strong>: 当前token的查询向量</li>
<li><strong>Key (K)</strong>: 所有token的键向量  </li>
<li><strong>Value (V)</strong>: 所有token的值向量</li>
</ul>
<p>KV Cache的核心思想是：</p>
<ol>
<li><strong>缓存已计算的K、V</strong>: 避免重复计算历史token的K、V</li>
<li><strong>增量更新</strong>: 只计算新token的K、V并追加到缓存</li>
<li><strong>内存复用</strong>: 通过block管理和prefix sharing减少内存占用</li>
</ol>
<h2 id="TensorRT-LLM-KV-Cache-管理"><a href="#TensorRT-LLM-KV-Cache-管理" class="headerlink" title="TensorRT-LLM KV Cache 管理"></a>TensorRT-LLM KV Cache 管理</h2><h3 id="整体架构设计"><a href="#整体架构设计" class="headerlink" title="整体架构设计"></a>整体架构设计</h3><p>TensorRT-LLM采用<strong>分层block管理架构</strong>，具有以下核心组件：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 核心类层次结构</span></span><br><span class="line">KVCacheManager</span><br><span class="line">├── BlockManager</span><br><span class="line">│   └── <span class="built_in">WindowBlockManager</span> (多个，按window size分组)</span><br><span class="line">│       ├── <span class="built_in">KVCacheBlockPool</span> (内存池)</span><br><span class="line">│       ├── <span class="built_in">LRUEvictionPolicy</span> (驱逐策略)</span><br><span class="line">│       └── <span class="built_in">KVCacheTransferManager</span> (传输管理)</span><br><span class="line">├── <span class="built_in">KVCacheEventManager</span> (事件管理)</span><br><span class="line">└── <span class="built_in">AllocateKvCache</span> (分配策略)</span><br></pre></td></tr></table></figure>

<h3 id="1-Block管理机制"><a href="#1-Block管理机制" class="headerlink" title="1. Block管理机制"></a>1. Block管理机制</h3><h4 id="Block数据结构"><a href="#Block数据结构" class="headerlink" title="Block数据结构"></a>Block数据结构</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KVCacheBlock</span> &#123;</span><br><span class="line">    IdType mBlockId;                    <span class="comment">// 块ID</span></span><br><span class="line">    tk::KVCacheIndex mMemoryPoolBlockIndex; <span class="comment">// 内存池索引</span></span><br><span class="line">    <span class="type">int32_t</span> mRefCount;                  <span class="comment">// 引用计数</span></span><br><span class="line">    <span class="type">int32_t</span> mSchedulingRefCount;        <span class="comment">// 调度引用计数</span></span><br><span class="line">    BlockPtr mPrevBlock;                <span class="comment">// 前驱块指针</span></span><br><span class="line">    NextBlockMap mNextBlocks;           <span class="comment">// 后继块映射</span></span><br><span class="line">    <span class="type">bool</span> mIsFull;                       <span class="comment">// 是否已满</span></span><br><span class="line">    executor::RetentionPriority mPriority; <span class="comment">// 优先级</span></span><br><span class="line">    std::optional&lt;std::chrono::milliseconds&gt; mDurationMs; <span class="comment">// 持续时间</span></span><br><span class="line">    <span class="type">size_t</span> mHash;                       <span class="comment">// 哈希值</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="Block分配策略"><a href="#Block分配策略" class="headerlink" title="Block分配策略"></a>Block分配策略</h4><ol>
<li><strong>分池管理</strong>: 根据KV head数量分组，相同配置的layer共享池</li>
<li><strong>优先级分配</strong>: 支持设置block优先级和过期时间</li>
<li><strong>引用计数</strong>: 精确跟踪block使用情况，支持共享和释放</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Block分配核心逻辑</span></span><br><span class="line"><span class="function">BlockPtr <span class="title">WindowBlockManager::getFreeBlock</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    executor::RetentionPriority priority, </span></span></span><br><span class="line"><span class="params"><span class="function">    std::optional&lt;std::chrono::milliseconds&gt; durationMs)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 1. 从驱逐策略获取空闲block</span></span><br><span class="line">    <span class="keyword">auto</span> [block, canOffload] = mEvictionPolicy-&gt;<span class="built_in">getFreeBlock</span>(kPrimaryLevel);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 2. 如果需要，执行offload到secondary memory</span></span><br><span class="line">    <span class="keyword">if</span> (!block-&gt;<span class="built_in">getUniqueTokens</span>().<span class="built_in">empty</span>() &amp;&amp; canOffload &amp;&amp; </span><br><span class="line">        mEvictionPolicy-&gt;<span class="built_in">getNumFreeBlocks</span>(kSecondaryLevel) &gt; <span class="number">0</span> &amp;&amp; mOnboardBlocks) &#123;</span><br><span class="line">        <span class="keyword">auto</span> offloadBlock = std::<span class="built_in">get</span>&lt;<span class="number">0</span>&gt;(mEvictionPolicy-&gt;<span class="built_in">getFreeBlock</span>(kSecondaryLevel));</span><br><span class="line">        mTransferManager-&gt;<span class="built_in">offload</span>(block, offloadBlock, mPools);</span><br><span class="line">        block-&gt;<span class="built_in">swapMemoryPoolBlockOffset</span>(offloadBlock);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> block;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-内存池管理"><a href="#2-内存池管理" class="headerlink" title="2. 内存池管理"></a>2. 内存池管理</h3><h4 id="分层内存设计"><a href="#分层内存设计" class="headerlink" title="分层内存设计"></a>分层内存设计</h4><ul>
<li><strong>Primary Pool</strong>: GPU快速内存，用于活跃block</li>
<li><strong>Secondary Pool</strong>: CPU较慢内存，用于offload</li>
<li><strong>Block Pool</strong>: 按layer配置分组的物理内存</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KVCacheBlockPool</span> &#123;</span><br><span class="line">    SizeType32 numLayers;           <span class="comment">// layer数量</span></span><br><span class="line">    SizeType32 kvFactor;            <span class="comment">// KV因子(通常为2，K和V)</span></span><br><span class="line">    SizeType32 numKvHeads;          <span class="comment">// KV head数量</span></span><br><span class="line">    SizeType32 tokensPerBlock;      <span class="comment">// 每个block的token数</span></span><br><span class="line">    runtime::ITensor::SharedPtr primaryPtr;   <span class="comment">// 主内存池</span></span><br><span class="line">    runtime::ITensor::SharedPtr secondaryPtr; <span class="comment">// 辅助内存池</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="内存分配流程"><a href="#内存分配流程" class="headerlink" title="内存分配流程"></a>内存分配流程</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">WindowBlockManager::allocatePools</span><span class="params">(<span class="type">bool</span> useUvm)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; pool : mPools) &#123;</span><br><span class="line">        <span class="comment">// 计算block大小</span></span><br><span class="line">        <span class="keyword">auto</span> blockSize = pool.blockSize;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 主内存池分配 - 形状: [num_blocks, num_layers, kv_factor, block_size]</span></span><br><span class="line">        nvinfer1::Dims cacheShape = ITensor::<span class="built_in">makeShape</span>(</span><br><span class="line">            &#123;mNumPrimaryBlocks, pool.numLayers, mKVFactor, blockSize&#125;);</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> (useUvm)</span><br><span class="line">            pool.primaryPtr = BufferManager::<span class="built_in">managed</span>(cacheShape, poolDtype);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            pool.primaryPtr = mBufferManager.<span class="built_in">gpuSync</span>(cacheShape, poolDtype);</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 辅助内存池分配</span></span><br><span class="line">        <span class="keyword">if</span> (mNumSecondaryBlocks &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            nvinfer1::Dims cacheShapeOffload = ITensor::<span class="built_in">makeShape</span>(</span><br><span class="line">                &#123;mNumSecondaryBlocks, pool.numLayers, mKVFactor, blockSize&#125;);</span><br><span class="line">            pool.secondaryPtr = BufferManager::<span class="built_in">pinned</span>(cacheShapeOffload, poolDtype);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-哈希与缓存复用"><a href="#3-哈希与缓存复用" class="headerlink" title="3. 哈希与缓存复用"></a>3. 哈希与缓存复用</h3><h4 id="高性能哈希算法"><a href="#高性能哈希算法" class="headerlink" title="高性能哈希算法"></a>高性能哈希算法</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">size_t</span> <span class="title">BlockKeyHasher::hash</span><span class="params">(BlockKey <span class="type">const</span>&amp; blockKey, std::<span class="type">size_t</span> parentHash)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="type">size_t</span> seed = blockKey.uniqueTokens.<span class="built_in">size</span>() ^ parentHash * <span class="built_in">UINT64_C</span>(<span class="number">0xbf58476d1ce4e5b9</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> <span class="type">const</span>&amp; uniqueToken : blockKey.uniqueTokens) &#123;</span><br><span class="line">        <span class="comment">// 使用Wang hash算法优化token ID哈希</span></span><br><span class="line">        <span class="type">uint32_t</span> a = <span class="built_in">static_cast</span>&lt;<span class="type">uint32_t</span>&gt;(uniqueToken.tokenId);</span><br><span class="line">        a = ((a &gt;&gt; <span class="number">16</span>) ^ a) * <span class="number">0x45d9f3b</span>;</span><br><span class="line">        a = ((a &gt;&gt; <span class="number">16</span>) ^ a) * <span class="number">0x45d9f3b</span>; </span><br><span class="line">        a = (a &gt;&gt; <span class="number">16</span>) ^ a;</span><br><span class="line">        seed ^= a + <span class="number">0x9e3779b9</span> + (seed &lt;&lt; <span class="number">6</span>) + (seed &gt;&gt; <span class="number">2</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 处理额外ID（如LoRA task ID）</span></span><br><span class="line">        <span class="keyword">if</span> (blockKey.usesExtraIds) &#123;</span><br><span class="line">            <span class="type">uint64_t</span> b = uniqueToken.tokenExtraId;</span><br><span class="line">            <span class="comment">// 64位哈希处理...</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> seed;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-驱逐策略"><a href="#4-驱逐策略" class="headerlink" title="4. 驱逐策略"></a>4. 驱逐策略</h3><h4 id="LRU驱逐算法"><a href="#LRU驱逐算法" class="headerlink" title="LRU驱逐算法"></a>LRU驱逐算法</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LRUEvictionPolicy</span> &#123;</span><br><span class="line">    <span class="comment">// 分优先级的队列结构</span></span><br><span class="line">    std::vector&lt;std::vector&lt;FreeBlocksQueue&gt;&gt; mFreeQueues; <span class="comment">// [cache_level][priority]</span></span><br><span class="line">    std::vector&lt;std::unordered_set&lt;SizeType32&gt;&gt; mReleasedBlocks;</span><br><span class="line">    std::vector&lt;SizeType32&gt; mNumFreeBlocksPerLevel;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取空闲block</span></span><br><span class="line">    <span class="function">std::tuple&lt;BlockPtr, <span class="type">bool</span>&gt; <span class="title">getFreeBlock</span><span class="params">(SizeType32 level)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 按优先级顺序查找空闲block</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> priority = kMinPriority; priority &lt;= kMaxPriority; ++priority) &#123;</span><br><span class="line">            <span class="keyword">auto</span>&amp; freeQueue = mFreeQueues[level][<span class="built_in">getPriorityIdx</span>(priority)];</span><br><span class="line">            <span class="keyword">if</span> (!freeQueue.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                <span class="keyword">auto</span> block = freeQueue.<span class="built_in">front</span>();</span><br><span class="line">                freeQueue.<span class="built_in">pop_front</span>();</span><br><span class="line">                <span class="keyword">return</span> &#123;block, <span class="literal">true</span>&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="literal">nullptr</span>, <span class="literal">false</span>&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="vLLM-KV-Cache-管理"><a href="#vLLM-KV-Cache-管理" class="headerlink" title="vLLM KV Cache 管理"></a>vLLM KV Cache 管理</h2><h3 id="整体架构设计-1"><a href="#整体架构设计-1" class="headerlink" title="整体架构设计"></a>整体架构设计</h3><p>vLLM采用<strong>模块化block分配架构</strong>，核心设计理念是简洁性和可扩展性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 核心类层次结构  </span></span><br><span class="line">SelfAttnBlockSpaceManager</span><br><span class="line">├── CpuGpuBlockAllocator</span><br><span class="line">│   ├── PrefixCachingBlockAllocator (GPU)</span><br><span class="line">│   └── PrefixCachingBlockAllocator (CPU)</span><br><span class="line">├── ComputedBlocksTracker (prefix缓存跟踪)</span><br><span class="line">└── LastAccessBlocksTracker (访问时间跟踪)</span><br></pre></td></tr></table></figure>

<h3 id="1-Block分配器设计"><a href="#1-Block分配器设计" class="headerlink" title="1. Block分配器设计"></a>1. Block分配器设计</h3><h4 id="设备感知分配器"><a href="#设备感知分配器" class="headerlink" title="设备感知分配器"></a>设备感知分配器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CpuGpuBlockAllocator</span>(<span class="title class_ inherited__">DeviceAwareBlockAllocator</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cpu_block_allocator: BlockAllocator, </span></span><br><span class="line"><span class="params">                 gpu_block_allocator: BlockAllocator</span>):</span><br><span class="line">        <span class="variable language_">self</span>._allocators = &#123;</span><br><span class="line">            Device.CPU: cpu_block_allocator,</span><br><span class="line">            Device.GPU: gpu_block_allocator,</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="variable language_">self</span>._swap_mapping: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">int</span>] = &#123;&#125;  <span class="comment"># CPU-GPU交换映射</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">allocate_mutable_block</span>(<span class="params">self, prev_block: <span class="type">Optional</span>[Block], </span></span><br><span class="line"><span class="params">                              device: Device, extra_hash: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span></span>) -&gt; Block:</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._allocators[device].allocate_mutable_block(prev_block, extra_hash=extra_hash)</span><br></pre></td></tr></table></figure>

<h4 id="PrefixCaching分配器"><a href="#PrefixCaching分配器" class="headerlink" title="PrefixCaching分配器"></a>PrefixCaching分配器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrefixCachingBlockAllocator</span>(<span class="title class_ inherited__">BlockAllocator</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_blocks: <span class="built_in">int</span>, block_size: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 eviction_policy: EvictionPolicy = EvictionPolicy.LRU</span>):</span><br><span class="line">        <span class="comment"># prefix hash到block ID的映射</span></span><br><span class="line">        <span class="variable language_">self</span>._cached_blocks: <span class="type">Dict</span>[PrefixHash, BlockId] = &#123;&#125;</span><br><span class="line">        <span class="comment"># 被调度器触及的不可变block ID集合</span></span><br><span class="line">        <span class="variable language_">self</span>._touched_blocks: <span class="type">Set</span>[BlockId] = <span class="built_in">set</span>()</span><br><span class="line">        <span class="comment"># 每个物理block ID的状态跟踪</span></span><br><span class="line">        <span class="variable language_">self</span>._block_tracker: <span class="type">Dict</span>[BlockId, BlockTracker] = &#123;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-Block生命周期管理"><a href="#2-Block生命周期管理" class="headerlink" title="2. Block生命周期管理"></a>2. Block生命周期管理</h3><h4 id="Block状态跟踪"><a href="#Block状态跟踪" class="headerlink" title="Block状态跟踪"></a>Block状态跟踪</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BlockTracker</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.active: <span class="built_in">bool</span> = <span class="literal">False</span>           <span class="comment"># 是否活跃</span></span><br><span class="line">        <span class="variable language_">self</span>.last_accessed: <span class="built_in">float</span> = -<span class="number">1</span>      <span class="comment"># 最后访问时间</span></span><br><span class="line">        <span class="variable language_">self</span>.computed: <span class="built_in">bool</span> = <span class="literal">False</span>         <span class="comment"># 是否已计算</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">enable</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.active = <span class="literal">True</span></span><br><span class="line">        <span class="variable language_">self</span>.reset()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.last_accessed = _DEFAULT_LAST_ACCESSED_TIME</span><br><span class="line">        <span class="variable language_">self</span>.computed = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h4 id="Immutable-vs-Mutable-Block"><a href="#Immutable-vs-Mutable-Block" class="headerlink" title="Immutable vs Mutable Block"></a>Immutable vs Mutable Block</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">allocate_immutable_block</span>(<span class="params">self, prev_block: <span class="type">Optional</span>[Block], </span></span><br><span class="line"><span class="params">                           token_ids: <span class="type">List</span>[<span class="built_in">int</span>], extra_hash: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span></span>) -&gt; Block:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;分配不可变block用于prefix caching&quot;&quot;&quot;</span></span><br><span class="line">    block = <span class="variable language_">self</span>._create_block(prev_block, token_ids, <span class="variable language_">self</span>._block_size, </span><br><span class="line">                              <span class="variable language_">self</span>, computed=<span class="literal">True</span>, extra_hash=extra_hash)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 检查是否已缓存</span></span><br><span class="line">    <span class="keyword">if</span> block.content_hash <span class="keyword">in</span> <span class="variable language_">self</span>._cached_blocks:</span><br><span class="line">        cached_block_id = <span class="variable language_">self</span>._cached_blocks[block.content_hash]</span><br><span class="line">        <span class="variable language_">self</span>._incr_refcount_cached_block(<span class="variable language_">self</span>._blocks[cached_block_id])</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._blocks[cached_block_id]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分配新block</span></span><br><span class="line">    <span class="variable language_">self</span>._cached_blocks[block.content_hash] = block.block_id</span><br><span class="line">    <span class="keyword">return</span> block</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">allocate_mutable_block</span>(<span class="params">self, prev_block: <span class="type">Optional</span>[Block], </span></span><br><span class="line"><span class="params">                          extra_hash: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span></span>) -&gt; Block:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;分配可变block用于新生成的token&quot;&quot;&quot;</span></span><br><span class="line">    block_id = <span class="variable language_">self</span>._allocate_block_id()</span><br><span class="line">    block = <span class="variable language_">self</span>._create_block(prev_block, [], <span class="variable language_">self</span>._block_size, </span><br><span class="line">                              <span class="variable language_">self</span>, block_id, extra_hash=extra_hash)</span><br><span class="line">    <span class="keyword">return</span> block</span><br></pre></td></tr></table></figure>

<h3 id="3-内容哈希机制"><a href="#3-内容哈希机制" class="headerlink" title="3. 内容哈希机制"></a>3. 内容哈希机制</h3><h4 id="层次化哈希计算"><a href="#层次化哈希计算" class="headerlink" title="层次化哈希计算"></a>层次化哈希计算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrefixCachingBlock</span>(<span class="title class_ inherited__">Block</span>):</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hash_block_tokens</span>(<span class="params">cls, is_first_block: <span class="built_in">bool</span>, prev_block_hash: <span class="type">Optional</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">                         cur_block_token_ids: <span class="type">List</span>[<span class="built_in">int</span>], extra_hash: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;计算block的内容哈希&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> is_first_block:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">hash</span>((<span class="built_in">tuple</span>(cur_block_token_ids), extra_hash))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">hash</span>((prev_block_hash, <span class="built_in">tuple</span>(cur_block_token_ids), extra_hash))</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @property </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">content_hash</span>(<span class="params">self</span>) -&gt; <span class="type">Optional</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>._content_hash <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="variable language_">self</span>.token_ids:</span><br><span class="line">            <span class="variable language_">self</span>._content_hash = <span class="variable language_">self</span>.hash_block_tokens(</span><br><span class="line">                <span class="variable language_">self</span>._prev_block <span class="keyword">is</span> <span class="literal">None</span>,</span><br><span class="line">                <span class="variable language_">self</span>._prev_block.content_hash <span class="keyword">if</span> <span class="variable language_">self</span>._prev_block <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                <span class="variable language_">self</span>.token_ids,</span><br><span class="line">                <span class="variable language_">self</span>.extra_hash</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._content_hash</span><br></pre></td></tr></table></figure>

<h3 id="4-调度集成"><a href="#4-调度集成" class="headerlink" title="4. 调度集成"></a>4. 调度集成</h3><h4 id="Memory-aware调度"><a href="#Memory-aware调度" class="headerlink" title="Memory-aware调度"></a>Memory-aware调度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SelfAttnBlockSpaceManager</span>(<span class="title class_ inherited__">BlockSpaceManager</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">can_allocate</span>(<span class="params">self, seq_group: SequenceGroup, num_lookahead_slots: <span class="built_in">int</span> = <span class="number">0</span></span>) -&gt; AllocStatus:</span><br><span class="line">        <span class="comment"># 检查是否有足够的GPU blocks</span></span><br><span class="line">        num_required_blocks = <span class="variable language_">self</span>._get_seq_num_required_blocks(seq_group.get_seqs()[<span class="number">0</span>])</span><br><span class="line">        num_required_blocks += num_lookahead_slots</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.block_allocator.get_num_free_blocks(Device.GPU) &lt; num_required_blocks:</span><br><span class="line">            <span class="keyword">return</span> AllocStatus.NEVER</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> AllocStatus.OK</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">allocate</span>(<span class="params">self, seq_group: SequenceGroup</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;为sequence group分配blocks&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> seq <span class="keyword">in</span> seq_group.get_seqs():</span><br><span class="line">            block_table = <span class="variable language_">self</span>._allocate_sequence(seq)</span><br><span class="line">            seq.block_table = block_table</span><br></pre></td></tr></table></figure>

<h2 id="SGLang-KV-Cache-管理"><a href="#SGLang-KV-Cache-管理" class="headerlink" title="SGLang KV Cache 管理"></a>SGLang KV Cache 管理</h2><h3 id="整体架构设计-2"><a href="#整体架构设计-2" class="headerlink" title="整体架构设计"></a>整体架构设计</h3><p>SGLang采用<strong>三层内存池架构</strong>，这是三个框架中最复杂和最灵活的设计：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 三层架构设计</span></span><br><span class="line">ReqToTokenPool          <span class="comment"># 第一层：请求到token位置映射</span></span><br><span class="line">├── TokenToKVPoolAllocator    <span class="comment"># 第二层：token到KV pool分配</span></span><br><span class="line">│   ├── PagedTokenToKVPoolAllocator (分页版本)</span><br><span class="line">│   └── SWATokenToKVPoolAllocator (滑动窗口版本)  </span><br><span class="line">└── KVCache                   <span class="comment"># 第三层：物理KV cache存储</span></span><br><span class="line">    ├── MHATokenToKVPool     <span class="comment"># 多头注意力</span></span><br><span class="line">    ├── MLATokenToKVPool     <span class="comment"># MLA注意力  </span></span><br><span class="line">    └── SWAKVPool            <span class="comment"># 滑动窗口注意力</span></span><br></pre></td></tr></table></figure>

<h3 id="1-请求级内存管理"><a href="#1-请求级内存管理" class="headerlink" title="1. 请求级内存管理"></a>1. 请求级内存管理</h3><h4 id="ReqToTokenPool"><a href="#ReqToTokenPool" class="headerlink" title="ReqToTokenPool"></a>ReqToTokenPool</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReqToTokenPool</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, max_context_len: <span class="built_in">int</span>, device: <span class="built_in">str</span>, enable_memory_saver: <span class="built_in">bool</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.size = size</span><br><span class="line">        <span class="variable language_">self</span>.max_context_len = max_context_len</span><br><span class="line">        <span class="comment"># 核心张量：[size, max_context_len]，存储token位置</span></span><br><span class="line">        <span class="variable language_">self</span>.req_to_token = torch.zeros((size, max_context_len), </span><br><span class="line">                                       dtype=torch.int32, device=device)</span><br><span class="line">        <span class="variable language_">self</span>.free_slots = <span class="built_in">list</span>(<span class="built_in">range</span>(size))  <span class="comment"># 空闲slot列表</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">alloc</span>(<span class="params">self, need_size: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;分配指定数量的slots&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> need_size &gt; <span class="built_in">len</span>(<span class="variable language_">self</span>.free_slots):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        select_index = <span class="variable language_">self</span>.free_slots[:need_size]</span><br><span class="line">        <span class="variable language_">self</span>.free_slots = <span class="variable language_">self</span>.free_slots[need_size:]</span><br><span class="line">        <span class="keyword">return</span> select_index</span><br></pre></td></tr></table></figure>

<h3 id="2-分页Token分配器"><a href="#2-分页Token分配器" class="headerlink" title="2. 分页Token分配器"></a>2. 分页Token分配器</h3><h4 id="PagedTokenToKVPoolAllocator"><a href="#PagedTokenToKVPoolAllocator" class="headerlink" title="PagedTokenToKVPoolAllocator"></a>PagedTokenToKVPoolAllocator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PagedTokenToKVPoolAllocator</span>(<span class="title class_ inherited__">BaseTokenToKVPoolAllocator</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, page_size: <span class="built_in">int</span>, dtype: torch.dtype, device: <span class="built_in">str</span>, kvcache: KVCache</span>):</span><br><span class="line">        <span class="variable language_">self</span>.size = size</span><br><span class="line">        <span class="variable language_">self</span>.page_size = page_size</span><br><span class="line">        <span class="comment"># 空闲页面列表：每个页面包含page_size个tokens</span></span><br><span class="line">        <span class="variable language_">self</span>.free_pages = torch.arange(<span class="number">1</span>, (size // page_size) + <span class="number">1</span>, device=device)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">alloc_extend</span>(<span class="params">self, prefix_lens: torch.Tensor, seq_lens: torch.Tensor, </span></span><br><span class="line"><span class="params">                    last_loc: torch.Tensor, extend_num_tokens: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;为extend阶段分配内存（使用Triton kernel优化）&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> alloc_extend_kernel(prefix_lens, seq_lens, last_loc, </span><br><span class="line">                                 <span class="variable language_">self</span>.free_pages, extend_num_tokens, <span class="variable language_">self</span>.page_size)</span><br></pre></td></tr></table></figure>

<h4 id="高性能Triton-Kernel"><a href="#高性能Triton-Kernel" class="headerlink" title="高性能Triton Kernel"></a>高性能Triton Kernel</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">alloc_extend_kernel</span>(<span class="params">pre_lens_ptr, seq_lens_ptr, last_loc_ptr, free_page_ptr,</span></span><br><span class="line"><span class="params">                       out_indices, ret_values, bs_upper: tl.constexpr, </span></span><br><span class="line"><span class="params">                       page_size: tl.constexpr, max_num_extend_tokens: tl.constexpr</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;使用Triton实现的高性能内存分配kernel&quot;&quot;&quot;</span></span><br><span class="line">    bid = tl.program_id(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> bid &gt;= bs_upper:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 加载序列信息</span></span><br><span class="line">    pre_len = tl.load(pre_lens_ptr + bid)</span><br><span class="line">    seq_len = tl.load(seq_lens_ptr + bid)</span><br><span class="line">    last_loc = tl.load(last_loc_ptr + bid)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算需要的token数和页数</span></span><br><span class="line">    num_new_tokens = seq_len - pre_len</span><br><span class="line">    num_new_pages = (num_new_tokens + page_size - <span class="number">1</span>) // page_size</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 原子操作分配页面</span></span><br><span class="line">    global_start_page = tl.atomic_add(free_page_ptr, num_new_pages)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成连续的token indices</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_new_tokens):</span><br><span class="line">        page_idx = i // page_size</span><br><span class="line">        page_offset = i % page_size</span><br><span class="line">        token_idx = (global_start_page + page_idx) * page_size + page_offset</span><br><span class="line">        tl.store(out_indices + bid * max_num_extend_tokens + i, token_idx)</span><br></pre></td></tr></table></figure>

<h3 id="3-SWA-Sliding-Window-Attention-支持"><a href="#3-SWA-Sliding-Window-Attention-支持" class="headerlink" title="3. SWA (Sliding Window Attention) 支持"></a>3. SWA (Sliding Window Attention) 支持</h3><h4 id="SWATokenToKVPoolAllocator"><a href="#SWATokenToKVPoolAllocator" class="headerlink" title="SWATokenToKVPoolAllocator"></a>SWATokenToKVPoolAllocator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SWATokenToKVPoolAllocator</span>(<span class="title class_ inherited__">BaseTokenToKVPoolAllocator</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, size_swa: <span class="built_in">int</span>, dtype: torch.dtype, device: <span class="built_in">str</span>, kvcache: SWAKVPool</span>):</span><br><span class="line">        <span class="comment"># 全注意力内存池</span></span><br><span class="line">        <span class="variable language_">self</span>.size_full = size</span><br><span class="line">        <span class="variable language_">self</span>.free_pages_full = torch.arange(<span class="number">1</span>, size + <span class="number">1</span>, device=device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 滑动窗口注意力内存池  </span></span><br><span class="line">        <span class="variable language_">self</span>.size_swa = size_swa</span><br><span class="line">        <span class="variable language_">self</span>.free_pages_swa = torch.arange(<span class="number">1</span>, size_swa + <span class="number">1</span>, device=device)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">alloc</span>(<span class="params">self, need_size: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;优先从full pool分配，不足时使用swa pool&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> need_size &lt;= <span class="built_in">len</span>(<span class="variable language_">self</span>.free_pages_full):</span><br><span class="line">            <span class="comment"># 从full pool分配</span></span><br><span class="line">            select_index = <span class="variable language_">self</span>.free_pages_full[:need_size]</span><br><span class="line">            <span class="variable language_">self</span>.free_pages_full = <span class="variable language_">self</span>.free_pages_full[need_size:]</span><br><span class="line">            <span class="keyword">return</span> select_index, <span class="string">&quot;full&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> need_size &lt;= <span class="built_in">len</span>(<span class="variable language_">self</span>.free_pages_swa):</span><br><span class="line">            <span class="comment"># 从swa pool分配</span></span><br><span class="line">            select_index = <span class="variable language_">self</span>.free_pages_swa[:need_size]</span><br><span class="line">            <span class="variable language_">self</span>.free_pages_swa = <span class="variable language_">self</span>.free_pages_swa[need_size:]</span><br><span class="line">            <span class="comment"># 转换索引以区分不同池</span></span><br><span class="line">            select_index = <span class="variable language_">self</span>.translate_loc_from_full_to_swa(select_index)</span><br><span class="line">            <span class="keyword">return</span> select_index, <span class="string">&quot;swa&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span>, <span class="string">&quot;none&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="4-物理KV-Cache层"><a href="#4-物理KV-Cache层" class="headerlink" title="4. 物理KV Cache层"></a>4. 物理KV Cache层</h3><h4 id="MLA-Multi-Latent-Attention-支持"><a href="#MLA-Multi-Latent-Attention-支持" class="headerlink" title="MLA (Multi-Latent Attention) 支持"></a>MLA (Multi-Latent Attention) 支持</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLATokenToKVPool</span>(<span class="title class_ inherited__">KVCache</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span>, page_size: <span class="built_in">int</span>, dtype: torch.dtype, </span></span><br><span class="line"><span class="params">                 kv_lora_rank: <span class="built_in">int</span>, qk_rope_head_dim: <span class="built_in">int</span>, layer_num: <span class="built_in">int</span>, device: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="comment"># MLA特殊的KV cache形状：[size, layer_num, kv_lora_rank + qk_rope_head_dim]</span></span><br><span class="line">        <span class="variable language_">self</span>.kv_buffer = torch.empty((size, layer_num, kv_lora_rank + qk_rope_head_dim), </span><br><span class="line">                                    dtype=dtype, device=device)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_mla_kv_buffer</span>(<span class="params">self, layer: RadixAttention, loc: torch.Tensor,</span></span><br><span class="line"><span class="params">                         cache_k_nope: torch.Tensor, cache_k_rope: torch.Tensor</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;使用Triton kernel高效设置MLA KV buffer&quot;&quot;&quot;</span></span><br><span class="line">        set_mla_kv_buffer_triton(<span class="variable language_">self</span>.kv_buffer, loc, cache_k_nope, cache_k_rope)</span><br></pre></td></tr></table></figure>

<h4 id="高性能MLA-Kernel"><a href="#高性能MLA-Kernel" class="headerlink" title="高性能MLA Kernel"></a>高性能MLA Kernel</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_mla_kv_buffer_kernel</span>(<span class="params">kv_buffer_ptr, cache_k_nope_ptr, cache_k_rope_ptr, loc_ptr,</span></span><br><span class="line"><span class="params">                            buffer_stride: tl.constexpr, nope_stride: tl.constexpr, </span></span><br><span class="line"><span class="params">                            rope_stride: tl.constexpr, nope_dim: tl.constexpr, </span></span><br><span class="line"><span class="params">                            rope_dim: tl.constexpr, BLOCK: tl.constexpr</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;MLA KV buffer设置的优化kernel&quot;&quot;&quot;</span></span><br><span class="line">    bid = tl.program_id(<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 加载位置信息</span></span><br><span class="line">    loc = tl.load(loc_ptr + bid)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 加载nope部分</span></span><br><span class="line">    nope_offset = bid * nope_stride + tl.arange(<span class="number">0</span>, nope_dim)</span><br><span class="line">    cache_k_nope = tl.load(cache_k_nope_ptr + nope_offset)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 加载rope部分</span></span><br><span class="line">    rope_offset = bid * rope_stride + tl.arange(<span class="number">0</span>, rope_dim)  </span><br><span class="line">    cache_k_rope = tl.load(cache_k_rope_ptr + rope_offset)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 写入KV buffer</span></span><br><span class="line">    buffer_offset = loc * buffer_stride + tl.arange(<span class="number">0</span>, nope_dim + rope_dim)</span><br><span class="line">    combined_kv = tl.join(cache_k_nope, cache_k_rope)</span><br><span class="line">    tl.store(kv_buffer_ptr + buffer_offset, combined_kv)</span><br></pre></td></tr></table></figure>

<h3 id="5-RadixAttention集成"><a href="#5-RadixAttention集成" class="headerlink" title="5. RadixAttention集成"></a>5. RadixAttention集成</h3><h4 id="RadixCache树形结构"><a href="#RadixCache树形结构" class="headerlink" title="RadixCache树形结构"></a>RadixCache树形结构</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RadixCache</span>(<span class="title class_ inherited__">BasePrefixCache</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, req_to_token_pool: ReqToTokenPool, </span></span><br><span class="line"><span class="params">                 token_to_kv_pool: BaseTokenToKVPoolAllocator, page_size: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.req_to_token_pool = req_to_token_pool</span><br><span class="line">        <span class="variable language_">self</span>.token_to_kv_pool = token_to_kv_pool  </span><br><span class="line">        <span class="variable language_">self</span>.page_size = page_size</span><br><span class="line">        <span class="variable language_">self</span>.root = TreeNode()  <span class="comment"># 根节点</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">match_prefix</span>(<span class="params">self, key: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; MatchResult:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;匹配最长公共前缀&quot;&quot;&quot;</span></span><br><span class="line">        node = <span class="variable language_">self</span>.root</span><br><span class="line">        matched_len = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分页匹配，提高效率</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(key), <span class="variable language_">self</span>.page_size):</span><br><span class="line">            page_key = key[i:i+<span class="variable language_">self</span>.page_size]</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">tuple</span>(page_key) <span class="keyword">in</span> node.children:</span><br><span class="line">                node = node.children[<span class="built_in">tuple</span>(page_key)]</span><br><span class="line">                matched_len += <span class="built_in">len</span>(page_key)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> MatchResult(matched_len, node)</span><br></pre></td></tr></table></figure>

<h2 id="技术对比与深度分析"><a href="#技术对比与深度分析" class="headerlink" title="技术对比与深度分析"></a>技术对比与深度分析</h2><h3 id="1-内存管理策略对比"><a href="#1-内存管理策略对比" class="headerlink" title="1. 内存管理策略对比"></a>1. 内存管理策略对比</h3><table>
<thead>
<tr>
<th>特性</th>
<th>TensorRT-LLM</th>
<th>vLLM</th>
<th>SGLang</th>
</tr>
</thead>
<tbody><tr>
<td><strong>架构复杂度</strong></td>
<td>中等 (分层block)</td>
<td>简单 (模块化)</td>
<td>高 (三层架构)</td>
</tr>
<tr>
<td><strong>内存池设计</strong></td>
<td>按配置分池</td>
<td>CPU&#x2F;GPU分离</td>
<td>多类型Pool</td>
</tr>
<tr>
<td><strong>分页支持</strong></td>
<td>支持 (16,32,64,128)</td>
<td>支持 (可配置)</td>
<td>支持 (可配置)</td>
</tr>
<tr>
<td><strong>SWA支持</strong></td>
<td>支持</td>
<td>部分支持</td>
<td>原生支持</td>
</tr>
<tr>
<td><strong>量化支持</strong></td>
<td>FP8&#x2F;INT4&#x2F;AWQ&#x2F;GPTQ</td>
<td>FP8</td>
<td>基础支持</td>
</tr>
</tbody></table>
<h3 id="2-前缀缓存机制对比"><a href="#2-前缀缓存机制对比" class="headerlink" title="2. 前缀缓存机制对比"></a>2. 前缀缓存机制对比</h3><h4 id="哈希算法性能"><a href="#哈希算法性能" class="headerlink" title="哈希算法性能"></a>哈希算法性能</h4><ul>
<li><strong>TensorRT-LLM</strong>: Wang hash + 64位优化，支持层次化哈希</li>
<li><strong>vLLM</strong>: Python标准hash，简单高效</li>
<li><strong>SGLang</strong>: 分页哈希，树形前缀匹配</li>
</ul>
<h4 id="缓存共享策略"><a href="#缓存共享策略" class="headerlink" title="缓存共享策略"></a>缓存共享策略</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TensorRT-LLM: 引用计数 + 优先级管理</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KVCacheBlock</span> &#123;</span><br><span class="line">    <span class="type">int32_t</span> mRefCount;                  <span class="comment">// 引用计数</span></span><br><span class="line">    executor::RetentionPriority mPriority; <span class="comment">// 优先级</span></span><br><span class="line">    std::chrono::milliseconds mDurationMs; <span class="comment">// 生存时间</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vLLM: 内容哈希 + LRU</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PrefixCachingBlockAllocator</span> &#123;</span><br><span class="line">    _cached_blocks: <span class="type">Dict</span>[PrefixHash, BlockId]  <span class="comment"># 哈希到块ID映射</span></span><br><span class="line">    _touched_blocks: <span class="type">Set</span>[BlockId]              <span class="comment"># 调度器触及的块</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SGLang: 树形结构 + 分页匹配</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TreeNode</span> &#123;</span><br><span class="line">    children: defaultdict(TreeNode)     <span class="comment"># 子节点映射</span></span><br><span class="line">    value: <span class="type">Optional</span>[torch.Tensor]       <span class="comment"># 缓存值</span></span><br><span class="line">    last_access_time: <span class="built_in">float</span>            <span class="comment"># 最后访问时间</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-性能优化技术"><a href="#3-性能优化技术" class="headerlink" title="3. 性能优化技术"></a>3. 性能优化技术</h3><h4 id="内存访问优化"><a href="#内存访问优化" class="headerlink" title="内存访问优化"></a>内存访问优化</h4><ol>
<li><p><strong>TensorRT-LLM</strong>:</p>
<ul>
<li>CUDA kernel优化的paged attention</li>
<li>多级缓存 (primary&#x2F;secondary)</li>
<li>Fabric memory支持高速传输</li>
</ul>
</li>
<li><p><strong>vLLM</strong>: </p>
<ul>
<li>Triton kernel实现</li>
<li>FlashAttention集成</li>
<li>多后端支持 (CUDA&#x2F;ROCm&#x2F;CPU)</li>
</ul>
</li>
<li><p><strong>SGLang</strong>:</p>
<ul>
<li>最多Triton kernel优化</li>
<li>专门的MLA&#x2F;SWA支持  </li>
<li>硬件特定优化 (Ascend NPU)</li>
</ul>
</li>
</ol>
<h4 id="并发和同步"><a href="#并发和同步" class="headerlink" title="并发和同步"></a>并发和同步</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TensorRT-LLM: 细粒度锁</span></span><br><span class="line">std::mutex mAllocatedBlocksPerSeqMutex;</span><br><span class="line">std::condition_variable mCondVar;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调度期间的引用计数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">KVCacheBlock::startScheduling</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    mSchedulingRefCount = mRefCount;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vLLM: 简化的状态管理</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BlockTracker</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">enable</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">assert</span> <span class="keyword">not</span> <span class="variable language_">self</span>.active</span><br><span class="line">        <span class="variable language_">self</span>.active = <span class="literal">True</span></span><br><span class="line">        <span class="variable language_">self</span>.reset()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SGLang: 分组释放优化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">free_group_begin</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="variable language_">self</span>.is_not_in_free_group = <span class="literal">False</span></span><br><span class="line">    <span class="variable language_">self</span>.free_group = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">free_group_end</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.free_group:</span><br><span class="line">        <span class="variable language_">self</span>.free(torch.cat(<span class="variable language_">self</span>.free_group))  <span class="comment"># 批量释放</span></span><br></pre></td></tr></table></figure>

<h2 id="性能优化策略"><a href="#性能优化策略" class="headerlink" title="性能优化策略"></a>性能优化策略</h2><h3 id="1-内存分配优化"><a href="#1-内存分配优化" class="headerlink" title="1. 内存分配优化"></a>1. 内存分配优化</h3><h4 id="TensorRT-LLM优化要点"><a href="#TensorRT-LLM优化要点" class="headerlink" title="TensorRT-LLM优化要点"></a>TensorRT-LLM优化要点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 预分配策略 - 避免运行时分配</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">WindowBlockManager::allocatePools</span><span class="params">(<span class="type">bool</span> useUvm)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 预分配所有内存池</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; pool : mPools) &#123;</span><br><span class="line">        pool.primaryPtr = mBufferManager.<span class="built_in">gpuSync</span>(cacheShape, poolDtype);</span><br><span class="line">        <span class="keyword">if</span> (mNumSecondaryBlocks &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            pool.secondaryPtr = BufferManager::<span class="built_in">pinned</span>(cacheShapeOffload, poolDtype);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 智能驱逐策略</span></span><br><span class="line"><span class="function">BlockPtr <span class="title">getFreeBlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 优先级队列 + LRU</span></span><br><span class="line">    <span class="keyword">auto</span> [block, canOffload] = mEvictionPolicy-&gt;<span class="built_in">getFreeBlock</span>(kPrimaryLevel);</span><br><span class="line">    <span class="keyword">if</span> (canOffload &amp;&amp; needOffload) &#123;</span><br><span class="line">        <span class="comment">// 异步offload到secondary memory</span></span><br><span class="line">        mTransferManager-&gt;<span class="built_in">offload</span>(block, offloadBlock, mPools);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> block;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="vLLM优化要点"><a href="#vLLM优化要点" class="headerlink" title="vLLM优化要点"></a>vLLM优化要点</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 延迟计算 - 仅在需要时计算哈希</span></span><br><span class="line"><span class="meta">@property</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">content_hash</span>(<span class="params">self</span>) -&gt; <span class="type">Optional</span>[<span class="built_in">int</span>]:</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>._content_hash <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="variable language_">self</span>.token_ids:</span><br><span class="line">        <span class="variable language_">self</span>._content_hash = <span class="variable language_">self</span>.hash_block_tokens(...)</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>._content_hash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 设备感知分配</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">allocate_mutable_block</span>(<span class="params">self, device: Device</span>) -&gt; Block:</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>._allocators[device].allocate_mutable_block(...)</span><br></pre></td></tr></table></figure>

<h4 id="SGLang优化要点"><a href="#SGLang优化要点" class="headerlink" title="SGLang优化要点"></a>SGLang优化要点</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Triton kernel加速</span></span><br><span class="line"><span class="meta">@triton.jit  </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">alloc_extend_kernel</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="comment"># GPU并行分配，避免CPU-GPU同步</span></span><br><span class="line">    global_start_page = tl.atomic_add(free_page_ptr, num_new_pages)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 分组操作减少开销</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">free_group_end</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.free_group:</span><br><span class="line">        <span class="variable language_">self</span>.free(torch.cat(<span class="variable language_">self</span>.free_group))  <span class="comment"># 批量释放</span></span><br></pre></td></tr></table></figure>

<h3 id="2-缓存命中率优化"><a href="#2-缓存命中率优化" class="headerlink" title="2. 缓存命中率优化"></a>2. 缓存命中率优化</h3><h4 id="前缀匹配算法"><a href="#前缀匹配算法" class="headerlink" title="前缀匹配算法"></a>前缀匹配算法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SGLang: 分页前缀匹配</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_key_match_paged</span>(<span class="params">key0: <span class="type">List</span>, key1: <span class="type">List</span>, page_size: <span class="built_in">int</span></span>):</span><br><span class="line">    min_len = <span class="built_in">min</span>(<span class="built_in">len</span>(key0), <span class="built_in">len</span>(key1))</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; min_len:</span><br><span class="line">        <span class="keyword">if</span> key0[i : i + page_size] != key1[i : i + page_size]:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        i += page_size</span><br><span class="line">    <span class="keyword">return</span> i</span><br><span class="line"></span><br><span class="line"><span class="comment"># TensorRT-LLM: 部分块复用</span></span><br><span class="line">std::<span class="built_in">tuple</span>&lt;<span class="built_in">bool</span>, SizeType32, BlockPtr&gt; findMatchingBlock(</span><br><span class="line">    BlockKey const&amp; blockKey, <span class="built_in">bool</span> enablePartialReuse) &#123;</span><br><span class="line">    <span class="keyword">if</span> (enablePartialReuse) &#123;</span><br><span class="line">        // 查找最佳部分匹配</span><br><span class="line">        <span class="keyword">for</span> (auto const&amp; [key, block] : mNextBlocks) &#123;</span><br><span class="line">            SizeType32 numMatched = key.partialMatch(blockKey);</span><br><span class="line">            <span class="keyword">if</span> (numMatched &gt; bestNumMatched) &#123;</span><br><span class="line">                bestNumMatched = numMatched;</span><br><span class="line">                bestBlock = block;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="缓存替换策略"><a href="#缓存替换策略" class="headerlink" title="缓存替换策略"></a>缓存替换策略</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TensorRT-LLM: 多因素LRU</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LRUEvictionPolicy</span> &#123;</span><br><span class="line">    <span class="comment">// 考虑优先级、访问时间、引用计数</span></span><br><span class="line">    std::vector&lt;std::vector&lt;FreeBlocksQueue&gt;&gt; mFreeQueues; <span class="comment">// [level][priority]</span></span><br><span class="line">    </span><br><span class="line">    <span class="function">BlockPtr <span class="title">getLRUBlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 优先级 &gt; 最后访问时间 &gt; 引用计数</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> priority = kMinPriority; priority &lt;= kMaxPriority; ++priority) &#123;</span><br><span class="line">            <span class="keyword">auto</span>&amp; queue = mFreeQueues[level][priority];</span><br><span class="line">            <span class="keyword">if</span> (!queue.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                <span class="keyword">return</span> queue.<span class="built_in">front</span>(); <span class="comment">// LRU order</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="3-内存使用优化"><a href="#3-内存使用优化" class="headerlink" title="3. 内存使用优化"></a>3. 内存使用优化</h3><h4 id="动态内存管理"><a href="#动态内存管理" class="headerlink" title="动态内存管理"></a>动态内存管理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SGLang: 动态SWA池切换</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SWATokenToKVPoolAllocator</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">alloc</span>(<span class="params">self, need_size: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="keyword">if</span> need_size &lt;= <span class="built_in">len</span>(<span class="variable language_">self</span>.free_pages_full):</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.free_pages_full[:need_size], <span class="string">&quot;full&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> need_size &lt;= <span class="built_in">len</span>(<span class="variable language_">self</span>.free_pages_swa):</span><br><span class="line">            <span class="comment"># 动态切换到SWA池</span></span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.translate_loc_from_full_to_swa(</span><br><span class="line">                <span class="variable language_">self</span>.free_pages_swa[:need_size]), <span class="string">&quot;swa&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="内存碎片减少"><a href="#内存碎片减少" class="headerlink" title="内存碎片减少"></a>内存碎片减少</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TensorRT-LLM: 连续块分配</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">addSequence</span><span class="params">(GenerationRequest&amp; sequence, SizeType32 inputLength)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 尽量分配连续的blocks以减少碎片</span></span><br><span class="line">    <span class="keyword">auto</span> blockedUniqueTokens = <span class="built_in">chopVectorIntoBlocks</span>(uniqueTokens, inputLength<span class="number">-1</span>, mTokensPerBlock);</span><br><span class="line">    <span class="keyword">auto</span> prepopulatedPromptLen = <span class="built_in">loadOrAllocateBlocks</span>(blockKeys, numContextBlocks, sequence);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="总结与建议"><a href="#总结与建议" class="headerlink" title="总结与建议"></a>总结与建议</h2><h3 id="各框架优势总结"><a href="#各框架优势总结" class="headerlink" title="各框架优势总结"></a>各框架优势总结</h3><h4 id="TensorRT-LLM"><a href="#TensorRT-LLM" class="headerlink" title="TensorRT-LLM"></a>TensorRT-LLM</h4><p><strong>优势</strong>:</p>
<ul>
<li>生产级稳定性和性能</li>
<li>完善的量化支持</li>
<li>优秀的CUDA kernel优化</li>
<li>企业级特性 (优先级、过期时间等)</li>
</ul>
<p><strong>适用场景</strong>:</p>
<ul>
<li>大规模生产部署</li>
<li>高性能要求的应用</li>
<li>NVIDIA GPU集群环境</li>
</ul>
<h4 id="vLLM"><a href="#vLLM" class="headerlink" title="vLLM"></a>vLLM</h4><p><strong>优势</strong>:</p>
<ul>
<li>代码简洁，易于理解和扩展</li>
<li>良好的社区支持</li>
<li>灵活的后端支持</li>
<li>快速迭代和新特性集成</li>
</ul>
<p><strong>适用场景</strong>:</p>
<ul>
<li>研究和原型开发</li>
<li>多样化硬件环境</li>
<li>需要快速集成新特性</li>
</ul>
<h4 id="SGLang"><a href="#SGLang" class="headerlink" title="SGLang"></a>SGLang</h4><p><strong>优势</strong>:</p>
<ul>
<li>最先进的内存管理架构</li>
<li>原生多模态支持</li>
<li>尖端优化技术 (MLA, SWA等)</li>
<li>硬件异构支持</li>
</ul>
<p><strong>适用场景</strong>:</p>
<ul>
<li>前沿研究项目  </li>
<li>复杂attention模式需求</li>
<li>异构硬件环境</li>
</ul>
<h3 id="技术发展趋势"><a href="#技术发展趋势" class="headerlink" title="技术发展趋势"></a>技术发展趋势</h3><ol>
<li><strong>架构融合</strong>: 各框架正在互相借鉴优势特性</li>
<li><strong>硬件特化</strong>: 针对不同硬件的专门优化</li>
<li><strong>智能调度</strong>: AI驱动的内存管理和调度策略</li>
<li><strong>异构计算</strong>: CPU&#x2F;GPU&#x2F;NPU协同的KV cache管理</li>
</ol>
<h3 id="选择建议"><a href="#选择建议" class="headerlink" title="选择建议"></a>选择建议</h3><table>
<thead>
<tr>
<th>需求</th>
<th>推荐框架</th>
<th>理由</th>
</tr>
</thead>
<tbody><tr>
<td>生产部署</td>
<td>TensorRT-LLM</td>
<td>稳定性和性能最佳</td>
</tr>
<tr>
<td>研究开发</td>
<td>vLLM</td>
<td>开发效率和扩展性好</td>
</tr>
<tr>
<td>前沿探索</td>
<td>SGLang</td>
<td>最新技术和架构创新</td>
</tr>
<tr>
<td>多模态应用</td>
<td>SGLang</td>
<td>原生多模态支持</td>
</tr>
<tr>
<td>异构硬件</td>
<td>SGLang &gt; vLLM &gt; TensorRT-LLM</td>
<td>硬件支持广度</td>
</tr>
</tbody></table>
<p>选择框架时应综合考虑性能需求、开发资源、部署环境和长期维护等因素。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/14/System/LLM_KVCache_%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/" data-id="cme17ov000017wnon1uvudg73" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-System/DpAttentionInSGLang" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/11/System/DpAttentionInSGLang/" class="article-date">
  <time class="dt-published" datetime="2025-07-11T04:09:42.000Z" itemprop="datePublished">2025-07-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/System/">System</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/11/System/DpAttentionInSGLang/">SGLang中的DP Attention原理与DeepSeekMoE适配</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="SGLang中的DP-Attention原理与DeepSeekMoE适配"><a href="#SGLang中的DP-Attention原理与DeepSeekMoE适配" class="headerlink" title="SGLang中的DP Attention原理与DeepSeekMoE适配"></a>SGLang中的DP Attention原理与DeepSeekMoE适配</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>SGLang实现了专门针对DeepSeek系列模型的DP Attention（数据并行注意力）机制，这是一个创新的并行化方案，用于解决Multi-Head Latent Attention (MLA)在传统张量并行下的KV缓存重复问题。本文详细介绍DP Attention的工作原理以及它如何与DeepSeekMoE架构完美结合。</p>
<h2 id="背景：MLA的挑战"><a href="#背景：MLA的挑战" class="headerlink" title="背景：MLA的挑战"></a>背景：MLA的挑战</h2><h3 id="传统张量并行的问题"><a href="#传统张量并行的问题" class="headerlink" title="传统张量并行的问题"></a>传统张量并行的问题</h3><p>在传统的Multi-Head Attention (MHA)中，张量并行(TP)通过将KV缓存按头数维度切分到不同设备上来实现并行化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 传统MHA的张量并行</span></span><br><span class="line"><span class="comment"># 假设有8个头，TP=8，每个设备处理1个头</span></span><br><span class="line">device_0: heads[<span class="number">0</span>]</span><br><span class="line">device_1: heads[<span class="number">1</span>]</span><br><span class="line">...</span><br><span class="line">device_7: heads[<span class="number">7</span>]</span><br></pre></td></tr></table></figure>

<h3 id="MLA的特殊性"><a href="#MLA的特殊性" class="headerlink" title="MLA的特殊性"></a>MLA的特殊性</h3><p>DeepSeek的Multi-Head Latent Attention具有以下特点：</p>
<ol>
<li><strong>单一KV头</strong>: MLA的<code>head_num</code>为1，无法按头数切分</li>
<li><strong>低秩压缩</strong>: 使用压缩的潜在向量<code>c_kv</code>存储KV信息</li>
<li><strong>共享键值</strong>: 所有查询头共享相同的键值表示</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MLA的结构</span></span><br><span class="line">c_kv = W_down_kv @ hidden_states  <span class="comment"># 压缩的KV表示</span></span><br><span class="line">k_heads = W_up_k @ c_kv           <span class="comment"># 所有头共享相同的键</span></span><br><span class="line">v_heads = W_up_v @ c_kv           <span class="comment"># 所有头共享相同的值</span></span><br></pre></td></tr></table></figure>

<p>这导致在传统TP下，每个设备都必须保存完整的KV缓存，造成存储冗余。</p>
<h2 id="DP-Attention原理"><a href="#DP-Attention原理" class="headerlink" title="DP Attention原理"></a>DP Attention原理</h2><h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><p>DP Attention采用<strong>数据并行</strong>而非<strong>张量并行</strong>的方式处理MLA：</p>
<ul>
<li><strong>按请求分割</strong>: 将不同的请求分配给不同的设备</li>
<li><strong>阶段分离</strong>: 不同设备可以处理不同的计算阶段（prefill&#x2F;decode）</li>
<li><strong>通信协调</strong>: 在MLA和MoE之间进行必要的通信同步</li>
</ul>
<h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DP Attention的工作流程</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DPAttention</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, hidden_states, batch_info</span>):</span><br><span class="line">        <span class="comment"># 1. 每个设备处理分配给它的请求</span></span><br><span class="line">        local_hidden_states = hidden_states[device_batch_slice]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 本地MLA计算</span></span><br><span class="line">        local_output = <span class="variable language_">self</span>.mla_forward(local_hidden_states)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. AllGather收集所有设备的输出</span></span><br><span class="line">        global_output = all_gather(local_output)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. MoE计算（需要全局信息）</span></span><br><span class="line">        moe_output = <span class="variable language_">self</span>.moe_forward(global_output)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 5. 切片提取本设备负责的结果</span></span><br><span class="line">        final_output = moe_output[device_batch_slice]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> final_output</span><br></pre></td></tr></table></figure>

<h3 id="内存优化"><a href="#内存优化" class="headerlink" title="内存优化"></a>内存优化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 内存使用对比</span></span><br><span class="line"><span class="comment"># 传统TP (8设备)</span></span><br><span class="line">memory_per_device = &#123;</span><br><span class="line">    <span class="string">&#x27;model_params&#x27;</span>: total_params / tp_size,</span><br><span class="line">    <span class="string">&#x27;kv_cache&#x27;</span>: full_kv_cache,  <span class="comment"># 每个设备都需要完整KV缓存</span></span><br><span class="line">    <span class="string">&#x27;activations&#x27;</span>: batch_size * hidden_size</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># DP Attention (8设备)</span></span><br><span class="line">memory_per_device = &#123;</span><br><span class="line">    <span class="string">&#x27;model_params&#x27;</span>: total_params,  <span class="comment"># 每个设备有完整参数</span></span><br><span class="line">    <span class="string">&#x27;kv_cache&#x27;</span>: kv_cache / dp_size,  <span class="comment"># KV缓存按请求分割</span></span><br><span class="line">    <span class="string">&#x27;activations&#x27;</span>: (batch_size / dp_size) * hidden_size</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="与DeepSeekMoE的集成"><a href="#与DeepSeekMoE的集成" class="headerlink" title="与DeepSeekMoE的集成"></a>与DeepSeekMoE的集成</h2><h3 id="DeepSeekMoE架构回顾"><a href="#DeepSeekMoE架构回顾" class="headerlink" title="DeepSeekMoE架构回顾"></a>DeepSeekMoE架构回顾</h3><p>DeepSeekMoE采用以下设计：</p>
<ol>
<li><strong>共享专家</strong>: 所有token都会访问的专家</li>
<li><strong>路由专家</strong>: 通过路由机制选择的专家</li>
<li><strong>细粒度分割</strong>: 专家参数进行更细致的分割</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DeepSeekMoE结构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DeepSeekMoE</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.shared_experts = nn.ModuleList(shared_experts)</span><br><span class="line">        <span class="variable language_">self</span>.routed_experts = nn.ModuleList(routed_experts)</span><br><span class="line">        <span class="variable language_">self</span>.router = Router()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 共享专家处理</span></span><br><span class="line">        shared_output = <span class="built_in">sum</span>(expert(x) <span class="keyword">for</span> expert <span class="keyword">in</span> <span class="variable language_">self</span>.shared_experts)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 路由专家处理</span></span><br><span class="line">        router_weights = <span class="variable language_">self</span>.router(x)</span><br><span class="line">        routed_output = <span class="variable language_">self</span>.route_to_experts(x, router_weights)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x + shared_output + routed_output</span><br></pre></td></tr></table></figure>

<h3 id="DP-Attention与MoE的协作"><a href="#DP-Attention与MoE的协作" class="headerlink" title="DP Attention与MoE的协作"></a>DP Attention与MoE的协作</h3><h4 id="1-通信模式"><a href="#1-通信模式" class="headerlink" title="1. 通信模式"></a>1. 通信模式</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DP Attention + MoE的通信模式</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dp_attention_moe_forward</span>(<span class="params">hidden_states</span>):</span><br><span class="line">    <span class="comment"># 阶段1: 本地MLA计算</span></span><br><span class="line">    local_attn_output = local_mla_attention(hidden_states)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 阶段2: AllGather - 收集所有设备的注意力输出</span></span><br><span class="line">    global_attn_output = all_gather(local_attn_output)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 阶段3: MoE计算 - 需要全局信息进行专家路由</span></span><br><span class="line">    moe_output = deepseek_moe_forward(global_attn_output)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 阶段4: Slice - 提取本设备负责的部分</span></span><br><span class="line">    local_final_output = moe_output[local_slice]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> local_final_output</span><br></pre></td></tr></table></figure>

<h4 id="2-专家路由适配"><a href="#2-专家路由适配" class="headerlink" title="2. 专家路由适配"></a>2. 专家路由适配</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 专家路由在DP环境下的适配</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DPAdaptedRouter</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_experts, dp_size</span>):</span><br><span class="line">        <span class="variable language_">self</span>.num_experts = num_experts</span><br><span class="line">        <span class="variable language_">self</span>.dp_size = dp_size</span><br><span class="line">        <span class="variable language_">self</span>.device_expert_map = <span class="variable language_">self</span>._create_expert_mapping()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, tokens</span>):</span><br><span class="line">        <span class="comment"># 路由计算需要考虑设备分布</span></span><br><span class="line">        routing_weights = <span class="variable language_">self</span>.compute_routing_weights(tokens)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 专家负载均衡</span></span><br><span class="line">        balanced_weights = <span class="variable language_">self</span>.balance_across_devices(routing_weights)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> balanced_weights</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_create_expert_mapping</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 将专家均匀分布到不同设备</span></span><br><span class="line">        experts_per_device = <span class="variable language_">self</span>.num_experts // <span class="variable language_">self</span>.dp_size</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            device_id: <span class="built_in">list</span>(<span class="built_in">range</span>(</span><br><span class="line">                device_id * experts_per_device,</span><br><span class="line">                (device_id + <span class="number">1</span>) * experts_per_device</span><br><span class="line">            ))</span><br><span class="line">            <span class="keyword">for</span> device_id <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.dp_size)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-负载均衡机制"><a href="#3-负载均衡机制" class="headerlink" title="3. 负载均衡机制"></a>3. 负载均衡机制</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 专家负载均衡</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ExpertLoadBalancer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dp_size, num_experts</span>):</span><br><span class="line">        <span class="variable language_">self</span>.dp_size = dp_size</span><br><span class="line">        <span class="variable language_">self</span>.num_experts = num_experts</span><br><span class="line">        <span class="variable language_">self</span>.expert_usage_stats = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">balance_load</span>(<span class="params">self, routing_decisions</span>):</span><br><span class="line">        <span class="comment"># 统计每个设备的专家使用情况</span></span><br><span class="line">        device_loads = <span class="variable language_">self</span>.calculate_device_loads(routing_decisions)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 动态调整路由以平衡负载</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.is_imbalanced(device_loads):</span><br><span class="line">            routing_decisions = <span class="variable language_">self</span>.rebalance_routing(routing_decisions)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> routing_decisions</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">calculate_device_loads</span>(<span class="params">self, routing_decisions</span>):</span><br><span class="line">        loads = [<span class="number">0</span>] * <span class="variable language_">self</span>.dp_size</span><br><span class="line">        <span class="keyword">for</span> token_routing <span class="keyword">in</span> routing_decisions:</span><br><span class="line">            <span class="keyword">for</span> expert_id <span class="keyword">in</span> token_routing:</span><br><span class="line">                device_id = <span class="variable language_">self</span>.get_expert_device(expert_id)</span><br><span class="line">                loads[device_id] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> loads</span><br></pre></td></tr></table></figure>

<h2 id="性能优化策略"><a href="#性能优化策略" class="headerlink" title="性能优化策略"></a>性能优化策略</h2><h3 id="1-通信优化"><a href="#1-通信优化" class="headerlink" title="1. 通信优化"></a>1. 通信优化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 异步通信优化</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AsyncDPAttention</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.comm_stream = torch.cuda.Stream()</span><br><span class="line">        <span class="variable language_">self</span>.comp_stream = torch.cuda.Stream()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, hidden_states</span>):</span><br><span class="line">        <span class="keyword">with</span> torch.cuda.stream(<span class="variable language_">self</span>.comp_stream):</span><br><span class="line">            <span class="comment"># 本地MLA计算</span></span><br><span class="line">            local_output = <span class="variable language_">self</span>.mla_forward(hidden_states)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> torch.cuda.stream(<span class="variable language_">self</span>.comm_stream):</span><br><span class="line">            <span class="comment"># 异步AllGather</span></span><br><span class="line">            gathered_output = <span class="variable language_">self</span>.async_all_gather(local_output)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 同步点</span></span><br><span class="line">        torch.cuda.synchronize()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> gathered_output</span><br></pre></td></tr></table></figure>

<h3 id="2-内存优化"><a href="#2-内存优化" class="headerlink" title="2. 内存优化"></a>2. 内存优化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 内存池管理</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemoryPoolManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dp_size</span>):</span><br><span class="line">        <span class="variable language_">self</span>.dp_size = dp_size</span><br><span class="line">        <span class="variable language_">self</span>.kv_cache_pools = &#123;&#125;</span><br><span class="line">        <span class="variable language_">self</span>.activation_pools = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">allocate_kv_cache</span>(<span class="params">self, batch_size, seq_len</span>):</span><br><span class="line">        <span class="comment"># 按设备分配KV缓存</span></span><br><span class="line">        cache_size = batch_size // <span class="variable language_">self</span>.dp_size</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.get_or_create_cache(cache_size, seq_len)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_or_create_cache</span>(<span class="params">self, cache_size, seq_len</span>):</span><br><span class="line">        key = (cache_size, seq_len)</span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">not</span> <span class="keyword">in</span> <span class="variable language_">self</span>.kv_cache_pools:</span><br><span class="line">            <span class="variable language_">self</span>.kv_cache_pools[key] = torch.empty(</span><br><span class="line">                cache_size, seq_len, <span class="variable language_">self</span>.hidden_size,</span><br><span class="line">                dtype=torch.float16, device=<span class="string">&#x27;cuda&#x27;</span></span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.kv_cache_pools[key]</span><br></pre></td></tr></table></figure>

<h3 id="3-调度优化"><a href="#3-调度优化" class="headerlink" title="3. 调度优化"></a>3. 调度优化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 批次调度优化</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DPBatchScheduler</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dp_size</span>):</span><br><span class="line">        <span class="variable language_">self</span>.dp_size = dp_size</span><br><span class="line">        <span class="variable language_">self</span>.device_queues = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(dp_size)]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">schedule_requests</span>(<span class="params">self, requests</span>):</span><br><span class="line">        <span class="comment"># 根据请求特征分配到不同设备</span></span><br><span class="line">        <span class="keyword">for</span> request <span class="keyword">in</span> requests:</span><br><span class="line">            device_id = <span class="variable language_">self</span>.select_device(request)</span><br><span class="line">            <span class="variable language_">self</span>.device_queues[device_id].append(request)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_device</span>(<span class="params">self, request</span>):</span><br><span class="line">        <span class="comment"># 负载均衡策略</span></span><br><span class="line">        loads = [<span class="built_in">len</span>(queue) <span class="keyword">for</span> queue <span class="keyword">in</span> <span class="variable language_">self</span>.device_queues]</span><br><span class="line">        <span class="keyword">return</span> loads.index(<span class="built_in">min</span>(loads))</span><br></pre></td></tr></table></figure>

<h2 id="实际应用案例"><a href="#实际应用案例" class="headerlink" title="实际应用案例"></a>实际应用案例</h2><h3 id="1-启动配置"><a href="#1-启动配置" class="headerlink" title="1. 启动配置"></a>1. 启动配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动带有DP Attention的SGLang服务</span></span><br><span class="line">python -m sglang.launch_server \</span><br><span class="line">    --model deepseek-ai/DeepSeek-V3 \</span><br><span class="line">    --tp 8 \</span><br><span class="line">    --dp 8 \</span><br><span class="line">    --enable-dp-attention \</span><br><span class="line">    --trust-remote-code \</span><br><span class="line">    --mem-fraction-static 0.9</span><br></pre></td></tr></table></figure>

<h3 id="2-性能对比"><a href="#2-性能对比" class="headerlink" title="2. 性能对比"></a>2. 性能对比</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 性能测试结果</span></span><br><span class="line">performance_comparison = &#123;</span><br><span class="line">    <span class="string">&#x27;traditional_tp&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;memory_per_device&#x27;</span>: <span class="string">&#x27;40GB&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;throughput&#x27;</span>: <span class="string">&#x27;1000 tokens/s&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;latency&#x27;</span>: <span class="string">&#x27;100ms&#x27;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&#x27;dp_attention&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;memory_per_device&#x27;</span>: <span class="string">&#x27;25GB&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;throughput&#x27;</span>: <span class="string">&#x27;1900 tokens/s&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;latency&#x27;</span>: <span class="string">&#x27;85ms&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-扩展性分析"><a href="#3-扩展性分析" class="headerlink" title="3. 扩展性分析"></a>3. 扩展性分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 扩展性测试</span></span><br><span class="line">scaling_results = &#123;</span><br><span class="line">    <span class="string">&#x27;batch_size_1&#x27;</span>: &#123;<span class="string">&#x27;improvement&#x27;</span>: <span class="string">&#x27;1.2x&#x27;</span>&#125;,</span><br><span class="line">    <span class="string">&#x27;batch_size_8&#x27;</span>: &#123;<span class="string">&#x27;improvement&#x27;</span>: <span class="string">&#x27;1.6x&#x27;</span>&#125;,</span><br><span class="line">    <span class="string">&#x27;batch_size_32&#x27;</span>: &#123;<span class="string">&#x27;improvement&#x27;</span>: <span class="string">&#x27;1.9x&#x27;</span>&#125;,</span><br><span class="line">    <span class="string">&#x27;batch_size_128&#x27;</span>: &#123;<span class="string">&#x27;improvement&#x27;</span>: <span class="string">&#x27;2.1x&#x27;</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="16用户请求处理流程图"><a href="#16用户请求处理流程图" class="headerlink" title="16用户请求处理流程图"></a>16用户请求处理流程图</h2><p>下图展示了SGLang中DP Attention处理16个用户请求的完整流程，包括数据并行分配、MLA层处理、专家路由和输出聚合的全过程：</p>
<pre class="mermaid">graph TD
    subgraph "输入层 - 16个用户请求"
        U1[Request 1] 
        U2[Request 2]
        U3[Request 3]
        U4[Request 4]
        U5[Request 5]
        U6[Request 6]
        U7[Request 7]
        U8[Request 8]
        U9[Request 9]
        U10[Request 10]
        U11[Request 11]
        U12[Request 12]
        U13[Request 13]
        U14[Request 14]
        U15[Request 15]
        U16[Request 16]
    end

    subgraph "数据并行分配 - 4个节点"
        subgraph "Node 0"
            N0[Requests 1-4<br/>Batch Size: 4]
        end
        subgraph "Node 1"
            N1[Requests 5-8<br/>Batch Size: 4]
        end
        subgraph "Node 2"
            N2[Requests 9-12<br/>Batch Size: 4]
        end
        subgraph "Node 3"
            N3[Requests 13-16<br/>Batch Size: 4]
        end
    end

    subgraph "MLA层 - DP Attention处理"
        subgraph "Node 0 MLA"
            MLA0[MLA Computation<br/>KV Cache: Local 4 requests<br/>c_kv compression]
        end
        subgraph "Node 1 MLA"
            MLA1[MLA Computation<br/>KV Cache: Local 4 requests<br/>c_kv compression]
        end
        subgraph "Node 2 MLA"
            MLA2[MLA Computation<br/>KV Cache: Local 4 requests<br/>c_kv compression]
        end
        subgraph "Node 3 MLA"
            MLA3[MLA Computation<br/>KV Cache: Local 4 requests<br/>c_kv compression]
        end
    end

    subgraph "AllGather - 注意力输出聚合"
        AG[AllGather Operation<br/>收集所有节点的注意力输出<br/>每个节点获得完整的16个输出]
    end

    subgraph "MoE层 - 专家路由与并行"
        subgraph "Expert Routing"
            ER[Token-level Expert Routing<br/>每个token根据门控网络<br/>路由到对应专家]
        end
        
        subgraph "Expert Parallel Processing"
            subgraph "Node 0 - Expert 0,1"
                E0[Expert 0<br/>处理路由到的tokens]
                E1[Expert 1<br/>处理路由到的tokens]
            end
            subgraph "Node 1 - Expert 2,3"
                E2[Expert 2<br/>处理路由到的tokens]
                E3[Expert 3<br/>处理路由到的tokens]
            end
            subgraph "Node 2 - Expert 4,5"
                E4[Expert 4<br/>处理路由到的tokens]
                E5[Expert 5<br/>处理路由到的tokens]
            end
            subgraph "Node 3 - Expert 6,7"
                E6[Expert 6<br/>处理路由到的tokens]
                E7[Expert 7<br/>处理路由到的tokens]
            end
        end
    end

    subgraph "AllToAll - 专家输出重分布"
        ATA[AllToAll Communication<br/>将专家输出重新分布<br/>回到原始的数据并行分割]
    end

    subgraph "输出层 - 结果聚合"
        subgraph "Node 0 Output"
            O0[Output for<br/>Requests 1-4]
        end
        subgraph "Node 1 Output"
            O1[Output for<br/>Requests 5-8]
        end
        subgraph "Node 2 Output"
            O2[Output for<br/>Requests 9-12]
        end
        subgraph "Node 3 Output"
            O3[Output for<br/>Requests 13-16]
        end
    end

    subgraph "最终输出"
        OUT[16个完整的推理结果]
    end

    %% 连接关系
    U1 --> N0
    U2 --> N0
    U3 --> N0
    U4 --> N0
    U5 --> N1
    U6 --> N1
    U7 --> N1
    U8 --> N1
    U9 --> N2
    U10 --> N2
    U11 --> N2
    U12 --> N2
    U13 --> N3
    U14 --> N3
    U15 --> N3
    U16 --> N3

    N0 --> MLA0
    N1 --> MLA1
    N2 --> MLA2
    N3 --> MLA3

    MLA0 --> AG
    MLA1 --> AG
    MLA2 --> AG
    MLA3 --> AG

    AG --> ER
    ER --> E0
    ER --> E1
    ER --> E2
    ER --> E3
    ER --> E4
    ER --> E5
    ER --> E6
    ER --> E7

    E0 --> ATA
    E1 --> ATA
    E2 --> ATA
    E3 --> ATA
    E4 --> ATA
    E5 --> ATA
    E6 --> ATA
    E7 --> ATA

    ATA --> O0
    ATA --> O1
    ATA --> O2
    ATA --> O3

    O0 --> OUT
    O1 --> OUT
    O2 --> OUT
    O3 --> OUT

    %% 样式
    classDef nodeStyle fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    classDef mlaStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef expertStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef commStyle fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef outputStyle fill:#fce4ec,stroke:#c2185b,stroke-width:2px

    class N0,N1,N2,N3 nodeStyle
    class MLA0,MLA1,MLA2,MLA3 mlaStyle
    class E0,E1,E2,E3,E4,E5,E6,E7 expertStyle
    class AG,ATA commStyle
    class O0,O1,O2,O3,OUT outputStyle</pre>

<h3 id="流程关键点说明"><a href="#流程关键点说明" class="headerlink" title="流程关键点说明"></a>流程关键点说明</h3><ol>
<li><strong>数据并行分配</strong>：16个请求均匀分配到4个节点，每个节点处理4个请求</li>
<li><strong>MLA层处理</strong>：每个节点独立处理本地请求，只需维护1&#x2F;4的KV缓存</li>
<li><strong>AllGather聚合</strong>：收集所有节点的注意力输出，为MoE层提供完整上下文</li>
<li><strong>专家路由</strong>：基于门控网络将tokens路由到不同专家</li>
<li><strong>专家并行</strong>：8个专家分布在4个节点上并行处理</li>
<li><strong>AllToAll重分布</strong>：将专家输出重新分布回原始的数据并行布局</li>
<li><strong>结果输出</strong>：每个节点输出对应请求的完整结果</li>
</ol>
<blockquote>
<p>流程图源文件：<a href="../images/sglang-dpattention-flow.mermaid">sglang-dpattention-flow.mermaid</a></p>
</blockquote>
<h2 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h2><h3 id="1-通信原语使用"><a href="#1-通信原语使用" class="headerlink" title="1. 通信原语使用"></a>1. 通信原语使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SGLang中使用的通信原语</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DPCommunication</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dp_size</span>):</span><br><span class="line">        <span class="variable language_">self</span>.dp_size = dp_size</span><br><span class="line">        <span class="variable language_">self</span>.comm_group = dist.new_group(<span class="built_in">range</span>(dp_size))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">all_gather_attention_output</span>(<span class="params">self, local_output</span>):</span><br><span class="line">        <span class="comment"># 收集所有设备的注意力输出</span></span><br><span class="line">        gathered_outputs = [torch.zeros_like(local_output) </span><br><span class="line">                          <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.dp_size)]</span><br><span class="line">        dist.all_gather(gathered_outputs, local_output, </span><br><span class="line">                       group=<span class="variable language_">self</span>.comm_group)</span><br><span class="line">        <span class="keyword">return</span> torch.cat(gathered_outputs, dim=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">scatter_moe_input</span>(<span class="params">self, global_input</span>):</span><br><span class="line">        <span class="comment"># 分散MoE输入到各设备</span></span><br><span class="line">        chunk_size = global_input.size(<span class="number">0</span>) // <span class="variable language_">self</span>.dp_size</span><br><span class="line">        chunks = torch.split(global_input, chunk_size, dim=<span class="number">0</span>)</span><br><span class="line">        local_chunk = torch.empty_like(chunks[<span class="number">0</span>])</span><br><span class="line">        dist.scatter(local_chunk, <span class="built_in">list</span>(chunks) <span class="keyword">if</span> dist.get_rank() == <span class="number">0</span> <span class="keyword">else</span> [], </span><br><span class="line">                    src=<span class="number">0</span>, group=<span class="variable language_">self</span>.comm_group)</span><br><span class="line">        <span class="keyword">return</span> local_chunk</span><br></pre></td></tr></table></figure>

<h3 id="2-错误处理与容错"><a href="#2-错误处理与容错" class="headerlink" title="2. 错误处理与容错"></a>2. 错误处理与容错</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 容错机制</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DPFaultTolerance</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dp_size</span>):</span><br><span class="line">        <span class="variable language_">self</span>.dp_size = dp_size</span><br><span class="line">        <span class="variable language_">self</span>.health_status = [<span class="literal">True</span>] * dp_size</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">handle_device_failure</span>(<span class="params">self, failed_device_id</span>):</span><br><span class="line">        <span class="comment"># 设备故障处理</span></span><br><span class="line">        <span class="variable language_">self</span>.health_status[failed_device_id] = <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 重新分配负载</span></span><br><span class="line">        healthy_devices = [i <span class="keyword">for</span> i, status <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.health_status) <span class="keyword">if</span> status]</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.redistribute_load(healthy_devices)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">redistribute_load</span>(<span class="params">self, healthy_devices</span>):</span><br><span class="line">        <span class="comment"># 负载重分配逻辑</span></span><br><span class="line">        new_dp_size = <span class="built_in">len</span>(healthy_devices)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.create_new_dp_group(healthy_devices, new_dp_size)</span><br></pre></td></tr></table></figure>

<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="1-配置建议"><a href="#1-配置建议" class="headerlink" title="1. 配置建议"></a>1. 配置建议</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 推荐配置</span></span><br><span class="line">recommended_config = &#123;</span><br><span class="line">    <span class="string">&#x27;small_batch&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;dp_size&#x27;</span>: <span class="number">2</span>,</span><br><span class="line">        <span class="string">&#x27;tp_size&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">        <span class="string">&#x27;enable_overlap&#x27;</span>: <span class="literal">True</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&#x27;large_batch&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;dp_size&#x27;</span>: <span class="number">8</span>,</span><br><span class="line">        <span class="string">&#x27;tp_size&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;enable_overlap&#x27;</span>: <span class="literal">True</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&#x27;mixed_workload&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;dp_size&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">        <span class="string">&#x27;tp_size&#x27;</span>: <span class="number">2</span>,</span><br><span class="line">        <span class="string">&#x27;enable_overlap&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&#x27;adaptive_scheduling&#x27;</span>: <span class="literal">True</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-监控指标"><a href="#2-监控指标" class="headerlink" title="2. 监控指标"></a>2. 监控指标</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关键监控指标</span></span><br><span class="line">monitoring_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;communication_overhead&#x27;</span>: <span class="string">&#x27;AllGather和Scatter的耗时&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;load_balance&#x27;</span>: <span class="string">&#x27;各设备间的负载均衡度&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;memory_utilization&#x27;</span>: <span class="string">&#x27;KV缓存的内存使用率&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;expert_utilization&#x27;</span>: <span class="string">&#x27;专家的使用频率分布&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;throughput&#x27;</span>: <span class="string">&#x27;整体吞吐量&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;latency&#x27;</span>: <span class="string">&#x27;端到端延迟&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-调优策略"><a href="#3-调优策略" class="headerlink" title="3. 调优策略"></a>3. 调优策略</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 性能调优</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DPTuningStrategy</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.tuning_params = &#123;</span><br><span class="line">            <span class="string">&#x27;comm_overlap_ratio&#x27;</span>: <span class="number">0.8</span>,</span><br><span class="line">            <span class="string">&#x27;batch_size_threshold&#x27;</span>: <span class="number">64</span>,</span><br><span class="line">            <span class="string">&#x27;expert_capacity_factor&#x27;</span>: <span class="number">1.2</span>,</span><br><span class="line">            <span class="string">&#x27;load_balance_threshold&#x27;</span>: <span class="number">0.1</span></span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">auto_tune</span>(<span class="params">self, workload_characteristics</span>):</span><br><span class="line">        <span class="comment"># 根据工作负载特征自动调优</span></span><br><span class="line">        <span class="keyword">if</span> workload_characteristics[<span class="string">&#x27;avg_batch_size&#x27;</span>] &gt; <span class="number">64</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.large_batch_config()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.small_batch_config()</span><br></pre></td></tr></table></figure>

<h2 id="未来发展方向"><a href="#未来发展方向" class="headerlink" title="未来发展方向"></a>未来发展方向</h2><h3 id="1-算法优化"><a href="#1-算法优化" class="headerlink" title="1. 算法优化"></a>1. 算法优化</h3><ul>
<li><strong>更智能的负载均衡</strong>: 基于历史负载模式的预测性调度</li>
<li><strong>动态专家分配</strong>: 根据访问模式动态调整专家分布</li>
<li><strong>通信压缩</strong>: 利用量化和压缩技术减少通信开销</li>
</ul>
<h3 id="2-硬件适配"><a href="#2-硬件适配" class="headerlink" title="2. 硬件适配"></a>2. 硬件适配</h3><ul>
<li><strong>新架构支持</strong>: 适配更新的GPU架构和interconnect</li>
<li><strong>异构计算</strong>: 支持CPU-GPU混合计算</li>
<li><strong>分布式存储</strong>: 与分布式存储系统的深度集成</li>
</ul>
<h3 id="3-系统集成"><a href="#3-系统集成" class="headerlink" title="3. 系统集成"></a>3. 系统集成</h3><ul>
<li><strong>容器化部署</strong>: 更好的容器化和编排支持</li>
<li><strong>云原生</strong>: 与Kubernetes等云原生技术的集成</li>
<li><strong>边缘计算</strong>: 适配边缘计算场景的轻量化版本</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>SGLang的DP Attention机制为DeepSeek系列模型提供了高效的并行化解决方案，通过数据并行而非传统的张量并行，成功解决了MLA架构下的KV缓存重复问题。与DeepSeekMoE的集成进一步提升了系统的整体性能和扩展性。</p>
<p><strong>关键优势</strong>:</p>
<ol>
<li><strong>内存效率</strong>: 显著减少KV缓存的内存占用</li>
<li><strong>计算效率</strong>: 提高整体计算吞吐量</li>
<li><strong>扩展性</strong>: 支持更大规模的批处理</li>
<li><strong>适应性</strong>: 能够适应不同的工作负载特征</li>
</ol>
<p><strong>应用建议</strong>:</p>
<ol>
<li>大批量场景优先使用DP Attention</li>
<li>合理配置DP和TP的比例</li>
<li>关注通信开销和负载均衡</li>
<li>持续监控和优化性能指标</li>
</ol>
<p>这种创新的并行化策略为大规模语言模型的高效部署提供了新的思路，值得在实际应用中深入探索和优化。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/11/System/DpAttentionInSGLang/" data-id="cme17ouzv000twnoneh3h0an7" data-title="SGLang中的DP Attention原理与DeepSeekMoE适配" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Attention/" rel="tag">Attention</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepSeek/" rel="tag">DeepSeek</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MoE/" rel="tag">MoE</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SGLang/" rel="tag">SGLang</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/System/" rel="tag">System</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-System/通信原语" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/11/System/%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD/" class="article-date">
  <time class="dt-published" datetime="2025-07-11T03:39:50.000Z" itemprop="datePublished">2025-07-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/System/">System</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/07/11/System/%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD/">通信原语 - 大模型推理中的分布式通信</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="通信原语-大模型推理中的分布式通信"><a href="#通信原语-大模型推理中的分布式通信" class="headerlink" title="通信原语 - 大模型推理中的分布式通信"></a>通信原语 - 大模型推理中的分布式通信</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>在大模型推理、分布式推理和MoE（Mixture of Experts）模型中，通信原语是实现高效分布式计算的核心组件。本文总结了常用的通信原语及其在不同场景中的应用。</p>
<h2 id="基础通信原语"><a href="#基础通信原语" class="headerlink" title="基础通信原语"></a>基础通信原语</h2><h3 id="1-AllReduce"><a href="#1-AllReduce" class="headerlink" title="1. AllReduce"></a>1. AllReduce</h3><p><strong>定义</strong>: 所有进程都参与归约操作，每个进程都获得相同的归约结果。</p>
<p><strong>实现</strong>: </p>
<ul>
<li>Ring-AllReduce: 通过环形拓扑结构，分两个阶段完成</li>
<li>Tree-AllReduce: 通过树形结构，适合小数据量</li>
</ul>
<p><strong>使用场景</strong>:</p>
<ul>
<li><strong>数据并行训练</strong>: 梯度同步</li>
<li><strong>模型并行推理</strong>: 跨设备的激活值聚合</li>
<li><strong>参数同步</strong>: 分布式优化器状态同步</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 伪代码示例</span></span><br><span class="line"><span class="comment"># 所有GPU上的梯度求和并分发到每个GPU</span></span><br><span class="line">torch.distributed.all_reduce(tensor, op=torch.distributed.ReduceOp.SUM)</span><br></pre></td></tr></table></figure>

<h3 id="2-AllGather"><a href="#2-AllGather" class="headerlink" title="2. AllGather"></a>2. AllGather</h3><p><strong>定义</strong>: 收集所有进程的数据，每个进程都获得完整的数据集合。</p>
<p><strong>特点</strong>:</p>
<ul>
<li>不进行归约操作，只是收集</li>
<li>输出大小是输入的N倍（N为进程数）</li>
</ul>
<p><strong>使用场景</strong>:</p>
<ul>
<li><strong>序列并行</strong>: 收集分片的序列数据</li>
<li><strong>专家并行</strong>: 收集所有专家的输出</li>
<li><strong>张量并行</strong>: 收集分片的权重矩阵</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 收集所有进程的张量</span></span><br><span class="line">output_tensors = [torch.zeros_like(input_tensor) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(world_size)]</span><br><span class="line">torch.distributed.all_gather(output_tensors, input_tensor)</span><br></pre></td></tr></table></figure>

<h3 id="3-ReduceScatter"><a href="#3-ReduceScatter" class="headerlink" title="3. ReduceScatter"></a>3. ReduceScatter</h3><p><strong>定义</strong>: 先归约再分发，每个进程只获得归约结果的一部分。</p>
<p><strong>特点</strong>:</p>
<ul>
<li>AllReduce的逆操作</li>
<li>输出大小是输入的1&#x2F;N</li>
</ul>
<p><strong>使用场景</strong>:</p>
<ul>
<li><strong>张量并行</strong>: 分发归约后的激活值</li>
<li><strong>流水线并行</strong>: 梯度分发</li>
<li><strong>MoE模型</strong>: 专家权重更新</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 归约后分发到不同进程</span></span><br><span class="line">torch.distributed.reduce_scatter(output_tensor, input_tensor_list, op=torch.distributed.ReduceOp.SUM)</span><br></pre></td></tr></table></figure>

<h3 id="4-Broadcast"><a href="#4-Broadcast" class="headerlink" title="4. Broadcast"></a>4. Broadcast</h3><p><strong>定义</strong>: 从一个进程向所有其他进程发送数据。</p>
<p><strong>使用场景</strong>:</p>
<ul>
<li><strong>模型初始化</strong>: 主进程向其他进程广播初始权重</li>
<li><strong>超参数同步</strong>: 配置参数分发</li>
<li><strong>控制信号</strong>: 训练状态同步</li>
</ul>
<h3 id="5-Point-to-Point-P2P"><a href="#5-Point-to-Point-P2P" class="headerlink" title="5. Point-to-Point (P2P)"></a>5. Point-to-Point (P2P)</h3><p><strong>定义</strong>: 两个进程间的直接通信。</p>
<p><strong>类型</strong>:</p>
<ul>
<li>Send&#x2F;Recv: 阻塞式点对点通信</li>
<li>Isend&#x2F;Irecv: 非阻塞式点对点通信</li>
</ul>
<p><strong>使用场景</strong>:</p>
<ul>
<li><strong>流水线并行</strong>: 相邻stage间的激活值传递</li>
<li><strong>MoE路由</strong>: 专家间的token传递</li>
<li><strong>异步通信</strong>: 计算与通信重叠</li>
</ul>
<h2 id="大模型推理中的通信模式"><a href="#大模型推理中的通信模式" class="headerlink" title="大模型推理中的通信模式"></a>大模型推理中的通信模式</h2><h3 id="1-数据并行-Data-Parallelism"><a href="#1-数据并行-Data-Parallelism" class="headerlink" title="1. 数据并行 (Data Parallelism)"></a>1. 数据并行 (Data Parallelism)</h3><p><strong>通信模式</strong>: </p>
<ul>
<li>AllReduce用于梯度同步</li>
<li>Broadcast用于参数同步</li>
</ul>
<p><strong>优化</strong>:</p>
<ul>
<li>梯度累积减少通信频次</li>
<li>混合精度减少通信量</li>
</ul>
<h3 id="2-张量并行-Tensor-Parallelism"><a href="#2-张量并行-Tensor-Parallelism" class="headerlink" title="2. 张量并行 (Tensor Parallelism)"></a>2. 张量并行 (Tensor Parallelism)</h3><p><strong>通信模式</strong>:</p>
<ul>
<li>AllGather: 收集分片权重</li>
<li>ReduceScatter: 分发计算结果</li>
<li>AllReduce: 跨分片聚合</li>
</ul>
<p><strong>关键点</strong>:</p>
<ul>
<li>通信与计算重叠</li>
<li>减少通信数据量</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 张量并行中的通信示例</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ColumnParallelLinear</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># AllGather输入</span></span><br><span class="line">        x_gathered = all_gather(x)</span><br><span class="line">        <span class="comment"># 本地计算</span></span><br><span class="line">        output = F.linear(x_gathered, <span class="variable language_">self</span>.weight)</span><br><span class="line">        <span class="comment"># ReduceScatter输出</span></span><br><span class="line">        output = reduce_scatter(output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<h3 id="3-流水线并行-Pipeline-Parallelism"><a href="#3-流水线并行-Pipeline-Parallelism" class="headerlink" title="3. 流水线并行 (Pipeline Parallelism)"></a>3. 流水线并行 (Pipeline Parallelism)</h3><p><strong>通信模式</strong>:</p>
<ul>
<li>P2P Send&#x2F;Recv: stage间激活值传递</li>
<li>双向通信: 前向和反向传播</li>
</ul>
<p><strong>优化策略</strong>:</p>
<ul>
<li>微批次(Micro-batch)减少气泡</li>
<li>异步通信隐藏延迟</li>
</ul>
<h3 id="4-序列并行-Sequence-Parallelism"><a href="#4-序列并行-Sequence-Parallelism" class="headerlink" title="4. 序列并行 (Sequence Parallelism)"></a>4. 序列并行 (Sequence Parallelism)</h3><p><strong>通信模式</strong>:</p>
<ul>
<li>AllGather: 收集序列片段</li>
<li>ReduceScatter: 分发计算结果</li>
</ul>
<p><strong>应用</strong>:</p>
<ul>
<li>长序列处理</li>
<li>注意力机制并行化</li>
</ul>
<h2 id="MoE模型中的通信原语"><a href="#MoE模型中的通信原语" class="headerlink" title="MoE模型中的通信原语"></a>MoE模型中的通信原语</h2><h3 id="1-专家路由-Expert-Routing"><a href="#1-专家路由-Expert-Routing" class="headerlink" title="1. 专家路由 (Expert Routing)"></a>1. 专家路由 (Expert Routing)</h3><p><strong>通信需求</strong>:</p>
<ul>
<li>Token到专家的路由</li>
<li>专家输出的收集</li>
</ul>
<p><strong>通信模式</strong>:</p>
<ul>
<li>AlltoAll: token重分布</li>
<li>AllGather: 收集专家输出</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MoE路由通信</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MoELayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 路由计算</span></span><br><span class="line">        router_output = <span class="variable language_">self</span>.router(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># AlltoAll: token重分布到专家</span></span><br><span class="line">        expert_inputs = all_to_all(x, router_output)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 专家计算</span></span><br><span class="line">        expert_outputs = <span class="variable language_">self</span>.experts(expert_inputs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># AlltoAll: 收集专家输出</span></span><br><span class="line">        output = all_to_all(expert_outputs, router_output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<h3 id="2-专家并行-Expert-Parallelism"><a href="#2-专家并行-Expert-Parallelism" class="headerlink" title="2. 专家并行 (Expert Parallelism)"></a>2. 专家并行 (Expert Parallelism)</h3><p><strong>通信模式</strong>:</p>
<ul>
<li>AlltoAll: 专家间token交换</li>
<li>ReduceScatter: 专家梯度分发</li>
</ul>
<p><strong>优化</strong>:</p>
<ul>
<li>专家放置策略</li>
<li>负载均衡</li>
</ul>
<h3 id="3-层次化MoE"><a href="#3-层次化MoE" class="headerlink" title="3. 层次化MoE"></a>3. 层次化MoE</h3><p><strong>通信层次</strong>:</p>
<ul>
<li>节点内: 高带宽通信</li>
<li>节点间: 低延迟通信</li>
</ul>
<p><strong>策略</strong>:</p>
<ul>
<li>本地专家优先</li>
<li>远程专家缓存</li>
</ul>
<h2 id="性能优化策略"><a href="#性能优化策略" class="headerlink" title="性能优化策略"></a>性能优化策略</h2><h3 id="1-通信与计算重叠"><a href="#1-通信与计算重叠" class="headerlink" title="1. 通信与计算重叠"></a>1. 通信与计算重叠</h3><p><strong>技术</strong>:</p>
<ul>
<li>异步通信</li>
<li>流水线执行</li>
<li>双缓冲</li>
</ul>
<p><strong>实现</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 异步通信示例</span></span><br><span class="line">handle = torch.distributed.all_reduce(tensor, async_op=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 并行计算</span></span><br><span class="line">local_computation()</span><br><span class="line"><span class="comment"># 等待通信完成</span></span><br><span class="line">handle.wait()</span><br></pre></td></tr></table></figure>

<h3 id="2-通信融合"><a href="#2-通信融合" class="headerlink" title="2. 通信融合"></a>2. 通信融合</h3><p><strong>策略</strong>:</p>
<ul>
<li>小张量合并</li>
<li>批量操作</li>
<li>连续内存布局</li>
</ul>
<h3 id="3-拓扑感知通信"><a href="#3-拓扑感知通信" class="headerlink" title="3. 拓扑感知通信"></a>3. 拓扑感知通信</h3><p><strong>考虑因素</strong>:</p>
<ul>
<li>网络带宽</li>
<li>延迟特性</li>
<li>硬件拓扑</li>
</ul>
<p><strong>优化</strong>:</p>
<ul>
<li>层次化通信</li>
<li>就近通信</li>
</ul>
<h2 id="实际应用案例"><a href="#实际应用案例" class="headerlink" title="实际应用案例"></a>实际应用案例</h2><h3 id="1-GPT-3训练"><a href="#1-GPT-3训练" class="headerlink" title="1. GPT-3训练"></a>1. GPT-3训练</h3><p><strong>并行策略</strong>:</p>
<ul>
<li>数据并行 + 模型并行</li>
<li>流水线并行</li>
</ul>
<p><strong>通信原语使用</strong>:</p>
<ul>
<li>AllReduce: 梯度同步</li>
<li>P2P: 流水线通信</li>
</ul>
<h3 id="2-Switch-Transformer"><a href="#2-Switch-Transformer" class="headerlink" title="2. Switch Transformer"></a>2. Switch Transformer</h3><p><strong>MoE实现</strong>:</p>
<ul>
<li>专家路由: AlltoAll</li>
<li>负载均衡: AllReduce</li>
</ul>
<h3 id="3-PaLM推理"><a href="#3-PaLM推理" class="headerlink" title="3. PaLM推理"></a>3. PaLM推理</h3><p><strong>分布式推理</strong>:</p>
<ul>
<li>张量并行: AllGather&#x2F;ReduceScatter</li>
<li>序列并行: 长序列处理</li>
</ul>
<h2 id="工具和框架"><a href="#工具和框架" class="headerlink" title="工具和框架"></a>工具和框架</h2><h3 id="1-NCCL-NVIDIA-Collective-Communications-Library"><a href="#1-NCCL-NVIDIA-Collective-Communications-Library" class="headerlink" title="1. NCCL (NVIDIA Collective Communications Library)"></a>1. NCCL (NVIDIA Collective Communications Library)</h3><p><strong>特点</strong>:</p>
<ul>
<li>GPU优化</li>
<li>高性能集合通信</li>
</ul>
<p><strong>支持原语</strong>:</p>
<ul>
<li>AllReduce, AllGather, ReduceScatter</li>
<li>Broadcast, Reduce</li>
</ul>
<h3 id="2-Gloo"><a href="#2-Gloo" class="headerlink" title="2. Gloo"></a>2. Gloo</h3><p><strong>特点</strong>:</p>
<ul>
<li>CPU&#x2F;GPU通用</li>
<li>多种后端支持</li>
</ul>
<h3 id="3-MPI-Message-Passing-Interface"><a href="#3-MPI-Message-Passing-Interface" class="headerlink" title="3. MPI (Message Passing Interface)"></a>3. MPI (Message Passing Interface)</h3><p><strong>特点</strong>:</p>
<ul>
<li>标准化接口</li>
<li>丰富的通信原语</li>
</ul>
<h3 id="4-高层框架"><a href="#4-高层框架" class="headerlink" title="4. 高层框架"></a>4. 高层框架</h3><p><strong>PyTorch Distributed</strong>:</p>
<ul>
<li>简化的API</li>
<li>自动优化</li>
</ul>
<p><strong>DeepSpeed</strong>:</p>
<ul>
<li>ZeRO优化</li>
<li>通信调度</li>
</ul>
<p><strong>FairScale</strong>:</p>
<ul>
<li>模块化设计</li>
<li>灵活配置</li>
</ul>
<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="1-通信原语选择"><a href="#1-通信原语选择" class="headerlink" title="1. 通信原语选择"></a>1. 通信原语选择</h3><p><strong>原则</strong>:</p>
<ul>
<li>根据数据流选择合适原语</li>
<li>考虑通信开销</li>
<li>平衡计算与通信</li>
</ul>
<h3 id="2-性能调优"><a href="#2-性能调优" class="headerlink" title="2. 性能调优"></a>2. 性能调优</h3><p><strong>策略</strong>:</p>
<ul>
<li>通信与计算重叠</li>
<li>减少通信频次</li>
<li>优化数据布局</li>
</ul>
<h3 id="3-容错处理"><a href="#3-容错处理" class="headerlink" title="3. 容错处理"></a>3. 容错处理</h3><p><strong>机制</strong>:</p>
<ul>
<li>超时检测</li>
<li>错误重试</li>
<li>故障恢复</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通信原语是大模型分布式推理的基础，选择合适的通信模式和优化策略对性能至关重要。随着模型规模的不断增长，通信效率将成为系统性能的关键瓶颈，需要持续的技术创新和优化。</p>
<p><strong>关键要点</strong>:</p>
<ol>
<li>理解不同通信原语的特点和适用场景</li>
<li>根据并行策略选择合适的通信模式</li>
<li>重视通信与计算的重叠优化</li>
<li>考虑硬件拓扑和网络特性</li>
<li>持续监控和调优通信性能</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/11/System/%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD/" data-id="cme17ov0e0028wnonfhdz3p2k" data-title="通信原语 - 大模型推理中的分布式通信" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Communication/" rel="tag">Communication</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Distributed/" rel="tag">Distributed</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/System/" rel="tag">System</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Programming/CPP/modern cpu" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/10/Programming/CPP/modern%20cpu/" class="article-date">
  <time class="dt-published" datetime="2025-07-10T01:35:38.184Z" itemprop="datePublished">2025-07-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="现代CPU架构与性能优化详解"><a href="#现代CPU架构与性能优化详解" class="headerlink" title="现代CPU架构与性能优化详解"></a>现代CPU架构与性能优化详解</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>在现代高性能计算中，CPU绑定和NUMA感知编程是重要的优化技术。理解这些技术的底层原理对于开发高性能应用至关重要。</p>
<h2 id="1-CPU绑定-CPU-Affinity"><a href="#1-CPU绑定-CPU-Affinity" class="headerlink" title="1. CPU绑定 (CPU Affinity)"></a>1. CPU绑定 (CPU Affinity)</h2><h3 id="1-1-什么是CPU绑定"><a href="#1-1-什么是CPU绑定" class="headerlink" title="1.1 什么是CPU绑定"></a>1.1 什么是CPU绑定</h3><p>CPU绑定是指将进程或线程固定到特定的CPU核心上运行，避免操作系统调度器将其迁移到其他核心。</p>
<h3 id="1-2-为什么需要CPU绑定"><a href="#1-2-为什么需要CPU绑定" class="headerlink" title="1.2 为什么需要CPU绑定"></a>1.2 为什么需要CPU绑定</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 没有CPU绑定的问题</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">without_affinity</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 线程可能在不同核心间迁移，导致：</span></span><br><span class="line">    <span class="comment">// 1. 缓存失效 (Cache Miss)</span></span><br><span class="line">    <span class="comment">// 2. TLB失效 (Translation Lookaside Buffer)</span></span><br><span class="line">    <span class="comment">// 3. 上下文切换开销</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">        <span class="built_in">heavy_computation</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用CPU绑定</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">with_affinity</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">cpu_set_t</span> cpuset;</span><br><span class="line">    <span class="built_in">CPU_ZERO</span>(&amp;cpuset);</span><br><span class="line">    <span class="built_in">CPU_SET</span>(<span class="number">0</span>, &amp;cpuset);  <span class="comment">// 绑定到核心0</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">pthread_setaffinity_np</span>(<span class="built_in">pthread_self</span>(), <span class="built_in">sizeof</span>(<span class="type">cpu_set_t</span>), &amp;cpuset);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 现在线程固定在核心0上运行，避免迁移开销</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">        <span class="built_in">heavy_computation</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="1-3-性能影响分析"><a href="#1-3-性能影响分析" class="headerlink" title="1.3 性能影响分析"></a>1.3 性能影响分析</h3><h4 id="缓存局部性"><a href="#缓存局部性" class="headerlink" title="缓存局部性"></a>缓存局部性</h4><ul>
<li><strong>L1缓存</strong>：32KB，1个周期延迟</li>
<li><strong>L2缓存</strong>：256KB，10个周期延迟  </li>
<li><strong>L3缓存</strong>：8MB，40个周期延迟</li>
<li><strong>主内存</strong>：100-300个周期延迟</li>
</ul>
<p>线程迁移会导致缓存失效，大幅增加内存访问延迟。</p>
<h4 id="TLB-Translation-Lookaside-Buffer-优化"><a href="#TLB-Translation-Lookaside-Buffer-优化" class="headerlink" title="TLB (Translation Lookaside Buffer) 优化"></a>TLB (Translation Lookaside Buffer) 优化</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TLB友好的内存分配</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TLBOptimizedAllocator</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">size_t</span> PAGE_SIZE = <span class="number">4096</span>;</span><br><span class="line">    <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">size_t</span> TLB_ENTRIES = <span class="number">64</span>;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span>* <span class="title">allocate_aligned</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 按页对齐分配，减少TLB缺失</span></span><br><span class="line">        <span class="type">size_t</span> aligned_size = (size + PAGE_SIZE - <span class="number">1</span>) &amp; ~(PAGE_SIZE - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">aligned_alloc</span>(PAGE_SIZE, aligned_size);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="2-NUMA架构详解"><a href="#2-NUMA架构详解" class="headerlink" title="2. NUMA架构详解"></a>2. NUMA架构详解</h2><h3 id="2-1-什么是NUMA"><a href="#2-1-什么是NUMA" class="headerlink" title="2.1 什么是NUMA"></a>2.1 什么是NUMA</h3><p>NUMA (Non-Uniform Memory Access) 是一种内存架构，其中内存访问时间取决于内存相对于处理器的位置。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">NUMA架构示意图：</span><br><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│                        NUMA Node 0                          │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  CPU 0  │  CPU 1  │  CPU 2  │  CPU 3  │  Memory Controller  │</span><br><span class="line">│         │         │         │         │                     │</span><br><span class="line">│  L1/L2  │  L1/L2  │  L1/L2  │  L1/L2  │  Local Memory      │</span><br><span class="line">│  Cache  │  Cache  │  Cache  │  Cache  │  (Fast Access)     │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br><span class="line">         │                    │</span><br><span class="line">         │   Interconnect     │</span><br><span class="line">         │   (Slower)         │</span><br><span class="line">         │                    │</span><br><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│                        NUMA Node 1                          │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  CPU 4  │  CPU 5  │  CPU 6  │  CPU 7  │  Memory Controller  │</span><br><span class="line">│         │         │         │         │                     │</span><br><span class="line">│  L1/L2  │  L1/L2  │  L1/L2  │  L1/L2  │  Remote Memory     │</span><br><span class="line">│  Cache  │  Cache  │  Cache  │  Cache  │  (Slow Access)     │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="2-2-NUMA访问延迟"><a href="#2-2-NUMA访问延迟" class="headerlink" title="2.2 NUMA访问延迟"></a>2.2 NUMA访问延迟</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NUMA感知的内存访问</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NUMAOptimized</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span>* local_data_;</span><br><span class="line">    <span class="type">int</span>* remote_data_;</span><br><span class="line">    <span class="type">int</span> numa_node_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">NUMAOptimized</span>(<span class="type">int</span> numa_node) : <span class="built_in">numa_node_</span>(numa_node) &#123;</span><br><span class="line">        <span class="comment">// 在本地NUMA节点分配内存</span></span><br><span class="line">        local_data_ = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>*&gt;(</span><br><span class="line">            <span class="built_in">numa_alloc_onnode</span>(<span class="number">1024</span> * <span class="built_in">sizeof</span>(<span class="type">int</span>), numa_node_));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 在远程NUMA节点分配内存</span></span><br><span class="line">        remote_data_ = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>*&gt;(</span><br><span class="line">            <span class="built_in">numa_alloc_onnode</span>(<span class="number">1024</span> * <span class="built_in">sizeof</span>(<span class="type">int</span>), (numa_node_ + <span class="number">1</span>) % <span class="number">2</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">benchmark_access</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> start = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 访问本地内存</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1024</span>; ++i) &#123;</span><br><span class="line">            local_data_[i] = i;  <span class="comment">// 快速访问</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">auto</span> local_end = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 访问远程内存</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1024</span>; ++i) &#123;</span><br><span class="line">            remote_data_[i] = i;  <span class="comment">// 慢速访问</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">auto</span> remote_end = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">auto</span> local_time = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::nanoseconds&gt;(</span><br><span class="line">            local_end - start).<span class="built_in">count</span>();</span><br><span class="line">        <span class="keyword">auto</span> remote_time = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::nanoseconds&gt;(</span><br><span class="line">            remote_end - local_end).<span class="built_in">count</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Local access: %ld ns, Remote access: %ld ns\n&quot;</span>, </span><br><span class="line">               local_time, remote_time);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-NUMA感知编程"><a href="#2-3-NUMA感知编程" class="headerlink" title="2.3 NUMA感知编程"></a>2.3 NUMA感知编程</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NUMA感知的线程池</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NUMAThreadPool</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">NUMAWorker</span> &#123;</span><br><span class="line">        std::thread thread;</span><br><span class="line">        <span class="type">int</span> numa_node;</span><br><span class="line">        std::queue&lt;std::function&lt;<span class="type">void</span>()&gt;&gt; tasks;</span><br><span class="line">        std::mutex mutex;</span><br><span class="line">        std::condition_variable cv;</span><br><span class="line">        <span class="type">bool</span> stop;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    std::vector&lt;NUMAWorker&gt; workers_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">NUMAThreadPool</span>() &#123;</span><br><span class="line">        <span class="type">int</span> num_numa_nodes = <span class="built_in">numa_num_configured_nodes</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> node = <span class="number">0</span>; node &lt; num_numa_nodes; ++node) &#123;</span><br><span class="line">            <span class="type">int</span> num_cpus = <span class="built_in">numa_num_configured_cpus</span>();</span><br><span class="line">            <span class="type">int</span> cpus_per_node = num_cpus / num_numa_nodes;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; cpus_per_node; ++i) &#123;</span><br><span class="line">                NUMAWorker worker;</span><br><span class="line">                worker.numa_node = node;</span><br><span class="line">                worker.stop = <span class="literal">false</span>;</span><br><span class="line">                </span><br><span class="line">                worker.thread = std::<span class="built_in">thread</span>([<span class="keyword">this</span>, &amp;worker]() &#123;</span><br><span class="line">                    <span class="comment">// 绑定到特定NUMA节点的CPU</span></span><br><span class="line">                    <span class="type">cpu_set_t</span> cpuset;</span><br><span class="line">                    <span class="built_in">CPU_ZERO</span>(&amp;cpuset);</span><br><span class="line">                    </span><br><span class="line">                    <span class="type">int</span> cpu_id = worker.numa_node * (<span class="built_in">numa_num_configured_cpus</span>() / </span><br><span class="line">                                                   <span class="built_in">numa_num_configured_nodes</span>()) + </span><br><span class="line">                               worker.thread.<span class="built_in">get_id</span>() % (<span class="built_in">numa_num_configured_cpus</span>() / </span><br><span class="line">                                                       <span class="built_in">numa_num_configured_nodes</span>());</span><br><span class="line">                    <span class="built_in">CPU_SET</span>(cpu_id, &amp;cpuset);</span><br><span class="line">                    </span><br><span class="line">                    <span class="built_in">pthread_setaffinity_np</span>(worker.thread.<span class="built_in">native_handle</span>(), </span><br><span class="line">                                          <span class="built_in">sizeof</span>(<span class="type">cpu_set_t</span>), &amp;cpuset);</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">// 在本地NUMA节点分配内存</span></span><br><span class="line">                    <span class="built_in">numa_set_preferred</span>(node);</span><br><span class="line">                    </span><br><span class="line">                    <span class="keyword">while</span> (!worker.stop) &#123;</span><br><span class="line">                        std::function&lt;<span class="built_in">void</span>()&gt; task;</span><br><span class="line">                        &#123;</span><br><span class="line">                            std::unique_lock&lt;std::mutex&gt; <span class="built_in">lock</span>(worker.mutex);</span><br><span class="line">                            worker.cv.<span class="built_in">wait</span>(lock, [&amp;worker]() &#123;</span><br><span class="line">                                <span class="keyword">return</span> !worker.tasks.<span class="built_in">empty</span>() || worker.stop;</span><br><span class="line">                            &#125;);</span><br><span class="line">                            </span><br><span class="line">                            <span class="keyword">if</span> (worker.stop) <span class="keyword">break</span>;</span><br><span class="line">                            </span><br><span class="line">                            task = std::<span class="built_in">move</span>(worker.tasks.<span class="built_in">front</span>());</span><br><span class="line">                            worker.tasks.<span class="built_in">pop</span>();</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="built_in">task</span>();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">                </span><br><span class="line">                workers_.<span class="built_in">push_back</span>(std::<span class="built_in">move</span>(worker));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> F&gt;</span></span><br><span class="line"><span class="function">    <span class="type">void</span> <span class="title">enqueue</span><span class="params">(F&amp;&amp; task, <span class="type">int</span> preferred_numa_node = <span class="number">-1</span>)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (preferred_numa_node &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// 将任务分配给指定NUMA节点的worker</span></span><br><span class="line">            <span class="type">int</span> worker_index = preferred_numa_node * </span><br><span class="line">                              (<span class="built_in">numa_num_configured_cpus</span>() / <span class="built_in">numa_num_configured_nodes</span>());</span><br><span class="line">            </span><br><span class="line">            <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(workers_[worker_index].mutex)</span></span>;</span><br><span class="line">            workers_[worker_index].tasks.<span class="built_in">emplace</span>(std::forward&lt;F&gt;(task));</span><br><span class="line">            workers_[worker_index].cv.<span class="built_in">notify_one</span>();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 轮询分配</span></span><br><span class="line">            <span class="type">static</span> <span class="type">int</span> current_worker = <span class="number">0</span>;</span><br><span class="line">            <span class="type">int</span> worker_index = current_worker++ % workers_.<span class="built_in">size</span>();</span><br><span class="line">            </span><br><span class="line">            <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(workers_[worker_index].mutex)</span></span>;</span><br><span class="line">            workers_[worker_index].tasks.<span class="built_in">emplace</span>(std::forward&lt;F&gt;(task));</span><br><span class="line">            workers_[worker_index].cv.<span class="built_in">notify_one</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="3-缓存层次结构"><a href="#3-缓存层次结构" class="headerlink" title="3. 缓存层次结构"></a>3. 缓存层次结构</h2><h3 id="3-1-现代CPU缓存架构"><a href="#3-1-现代CPU缓存架构" class="headerlink" title="3.1 现代CPU缓存架构"></a>3.1 现代CPU缓存架构</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 缓存层次结构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CacheHierarchy</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">CacheInfo</span> &#123;</span><br><span class="line">        <span class="type">size_t</span> size;      <span class="comment">// 缓存大小</span></span><br><span class="line">        <span class="type">size_t</span> line_size; <span class="comment">// 缓存行大小</span></span><br><span class="line">        <span class="type">int</span> associativity; <span class="comment">// 关联度</span></span><br><span class="line">        <span class="type">int</span> latency;      <span class="comment">// 访问延迟</span></span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> CacheInfo <span class="title">get_cache_info</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        CacheInfo info;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// L1数据缓存</span></span><br><span class="line">        info.size = <span class="number">32</span> * <span class="number">1024</span>;        <span class="comment">// 32KB</span></span><br><span class="line">        info.line_size = <span class="number">64</span>;          <span class="comment">// 64字节</span></span><br><span class="line">        info.associativity = <span class="number">8</span>;       <span class="comment">// 8路组关联</span></span><br><span class="line">        info.latency = <span class="number">1</span>;             <span class="comment">// 1个周期</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> info;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 缓存友好的数据结构</span></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">CacheFriendlyArray</span> &#123;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        std::vector&lt;T&gt; data_;</span><br><span class="line">        <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">size_t</span> CACHE_LINE_SIZE = <span class="number">64</span>;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">CacheFriendlyArray</span>(<span class="type">size_t</span> size) : <span class="built_in">data_</span>(size) &#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 确保数据按缓存行对齐</span></span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">align_to_cache_line</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="type">size_t</span> alignment = CACHE_LINE_SIZE / <span class="built_in">sizeof</span>(T);</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; data_.<span class="built_in">size</span>(); i += alignment) &#123;</span><br><span class="line">                <span class="comment">// 预取下一个缓存行</span></span><br><span class="line">                __builtin_prefetch(&amp;data_[i + alignment], <span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 缓存友好的访问模式</span></span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">cache_friendly_access</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; data_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">                <span class="comment">// 顺序访问，最大化缓存利用率</span></span><br><span class="line">                data_[i] = <span class="built_in">process</span>(data_[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-预取优化"><a href="#3-2-预取优化" class="headerlink" title="3.2 预取优化"></a>3.2 预取优化</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 硬件预取优化</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PrefetchOptimization</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; data_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">PrefetchOptimization</span>(<span class="type">size_t</span> size) : <span class="built_in">data_</span>(size) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">            data_[i] = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 使用软件预取</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">software_prefetch</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">size_t</span> prefetch_distance = <span class="number">16</span>;  <span class="comment">// 预取距离</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; data_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            <span class="comment">// 预取未来要访问的数据</span></span><br><span class="line">            <span class="keyword">if</span> (i + prefetch_distance &lt; data_.<span class="built_in">size</span>()) &#123;</span><br><span class="line">                __builtin_prefetch(&amp;data_[i + prefetch_distance], <span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 处理当前数据</span></span><br><span class="line">            data_[i] = <span class="built_in">heavy_computation</span>(data_[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 使用硬件预取友好的访问模式</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">hardware_prefetch_friendly</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 大步长访问，触发硬件预取</span></span><br><span class="line">        <span class="type">const</span> <span class="type">size_t</span> stride = <span class="number">64</span> / <span class="built_in">sizeof</span>(<span class="type">int</span>);  <span class="comment">// 一个缓存行的大小</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; data_.<span class="built_in">size</span>(); i += stride) &#123;</span><br><span class="line">            data_[i] = <span class="built_in">heavy_computation</span>(data_[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">heavy_computation</span><span class="params">(<span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> value * value + value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="4-实际应用示例"><a href="#4-实际应用示例" class="headerlink" title="4. 实际应用示例"></a>4. 实际应用示例</h2><h3 id="4-1-高性能矩阵乘法"><a href="#4-1-高性能矩阵乘法" class="headerlink" title="4.1 高性能矩阵乘法"></a>4.1 高性能矩阵乘法</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NUMA感知的矩阵乘法</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NUMAOptimizedMatrix</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">double</span>* matrix_a_;</span><br><span class="line">    <span class="type">double</span>* matrix_b_;</span><br><span class="line">    <span class="type">double</span>* matrix_c_;</span><br><span class="line">    <span class="type">int</span> size_;</span><br><span class="line">    <span class="type">int</span> numa_node_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">NUMAOptimizedMatrix</span>(<span class="type">int</span> size, <span class="type">int</span> numa_node) </span><br><span class="line">        : <span class="built_in">size_</span>(size), <span class="built_in">numa_node_</span>(numa_node) &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 在本地NUMA节点分配内存</span></span><br><span class="line">        matrix_a_ = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>*&gt;(</span><br><span class="line">            <span class="built_in">numa_alloc_onnode</span>(size * size * <span class="built_in">sizeof</span>(<span class="type">double</span>), numa_node_));</span><br><span class="line">        matrix_b_ = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>*&gt;(</span><br><span class="line">            <span class="built_in">numa_alloc_onnode</span>(size * size * <span class="built_in">sizeof</span>(<span class="type">double</span>), numa_node_));</span><br><span class="line">        matrix_c_ = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>*&gt;(</span><br><span class="line">            <span class="built_in">numa_alloc_onnode</span>(size * size * <span class="built_in">sizeof</span>(<span class="type">double</span>), numa_node_));</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">initialize_matrices</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">multiply_optimized</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> block_size = <span class="number">64</span>;  <span class="comment">// 缓存友好的块大小</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 分块矩阵乘法</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size_; i += block_size) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; size_; j += block_size) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; size_; k += block_size) &#123;</span><br><span class="line">                    <span class="built_in">multiply_block</span>(i, j, k, block_size);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">multiply_block</span><span class="params">(<span class="type">int</span> i_start, <span class="type">int</span> j_start, <span class="type">int</span> k_start, <span class="type">int</span> block_size)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> i_end = std::<span class="built_in">min</span>(i_start + block_size, size_);</span><br><span class="line">        <span class="type">int</span> j_end = std::<span class="built_in">min</span>(j_start + block_size, size_);</span><br><span class="line">        <span class="type">int</span> k_end = std::<span class="built_in">min</span>(k_start + block_size, size_);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = i_start; i &lt; i_end; ++i) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = j_start; j &lt; j_end; ++j) &#123;</span><br><span class="line">                <span class="type">double</span> sum = <span class="number">0.0</span>;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> k = k_start; k &lt; k_end; ++k) &#123;</span><br><span class="line">                    sum += matrix_a_[i * size_ + k] * matrix_b_[k * size_ + j];</span><br><span class="line">                &#125;</span><br><span class="line">                matrix_c_[i * size_ + j] += sum;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">initialize_matrices</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size_ * size_; ++i) &#123;</span><br><span class="line">            matrix_a_[i] = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(<span class="built_in">rand</span>()) / RAND_MAX;</span><br><span class="line">            matrix_b_[i] = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(<span class="built_in">rand</span>()) / RAND_MAX;</span><br><span class="line">            matrix_c_[i] = <span class="number">0.0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="5-性能监控和调优"><a href="#5-性能监控和调优" class="headerlink" title="5. 性能监控和调优"></a>5. 性能监控和调优</h2><h3 id="5-1-性能计数器"><a href="#5-1-性能计数器" class="headerlink" title="5.1 性能计数器"></a>5.1 性能计数器</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用性能计数器监控缓存性能</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CachePerformanceMonitor</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">CacheStats</span> &#123;</span><br><span class="line">        <span class="type">uint64_t</span> l1_misses;</span><br><span class="line">        <span class="type">uint64_t</span> l2_misses;</span><br><span class="line">        <span class="type">uint64_t</span> l3_misses;</span><br><span class="line">        <span class="type">uint64_t</span> tlb_misses;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> CacheStats <span class="title">get_cache_stats</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        CacheStats stats = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">        </span><br><span class="line">        <span class="meta">#<span class="keyword">ifdef</span> __linux__</span></span><br><span class="line">        <span class="comment">// 使用perf_event_open读取硬件计数器</span></span><br><span class="line">        <span class="type">int</span> fd = <span class="built_in">perf_event_open</span>(&amp;pe, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (fd != <span class="number">-1</span>) &#123;</span><br><span class="line">            <span class="built_in">read</span>(fd, &amp;stats, <span class="built_in">sizeof</span>(stats));</span><br><span class="line">            <span class="built_in">close</span>(fd);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> stats;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">print_cache_stats</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        CacheStats stats = <span class="built_in">get_cache_stats</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Cache Performance:\n&quot;</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  L1 Misses: %lu\n&quot;</span>, stats.l1_misses);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  L2 Misses: %lu\n&quot;</span>, stats.l2_misses);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  L3 Misses: %lu\n&quot;</span>, stats.l3_misses);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  TLB Misses: %lu\n&quot;</span>, stats.tlb_misses);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="5-2-NUMA统计信息"><a href="#5-2-NUMA统计信息" class="headerlink" title="5.2 NUMA统计信息"></a>5.2 NUMA统计信息</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NUMA性能监控</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NUMAPerformanceMonitor</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">print_numa_stats</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> num_nodes = <span class="built_in">numa_num_configured_nodes</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;NUMA Statistics:\n&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> node = <span class="number">0</span>; node &lt; num_nodes; ++node) &#123;</span><br><span class="line">            <span class="keyword">struct</span> <span class="title class_">bitmask</span>* cpus = <span class="built_in">numa_allocate_cpumask</span>();</span><br><span class="line">            <span class="built_in">numa_node_to_cpus</span>(node, cpus);</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;  Node %d:\n&quot;</span>, node);</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;    CPUs: &quot;</span>);</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> cpu = <span class="number">0</span>; cpu &lt; <span class="built_in">numa_num_configured_cpus</span>(); ++cpu) &#123;</span><br><span class="line">                <span class="keyword">if</span> (<span class="built_in">numa_bitmask_isbitset</span>(cpus, cpu)) &#123;</span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, cpu);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">numa_free_cpumask</span>(cpus);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">benchmark_numa_access</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> num_nodes = <span class="built_in">numa_num_configured_nodes</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> node = <span class="number">0</span>; node &lt; num_nodes; ++node) &#123;</span><br><span class="line">            <span class="comment">// 分配本地内存</span></span><br><span class="line">            <span class="type">void</span>* local_mem = <span class="built_in">numa_alloc_onnode</span>(<span class="number">1024</span> * <span class="number">1024</span>, node);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 分配远程内存</span></span><br><span class="line">            <span class="type">void</span>* remote_mem = <span class="built_in">numa_alloc_onnode</span>(<span class="number">1024</span> * <span class="number">1024</span>, (node + <span class="number">1</span>) % num_nodes);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 测试访问延迟</span></span><br><span class="line">            <span class="keyword">auto</span> start = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">                <span class="built_in">static_cast</span>&lt;<span class="type">char</span>*&gt;(local_mem)[i % <span class="number">1024</span>] = i;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">auto</span> local_end = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">                <span class="built_in">static_cast</span>&lt;<span class="type">char</span>*&gt;(remote_mem)[i % <span class="number">1024</span>] = i;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">auto</span> remote_end = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">auto</span> local_time = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::microseconds&gt;(</span><br><span class="line">                local_end - start).<span class="built_in">count</span>();</span><br><span class="line">            <span class="keyword">auto</span> remote_time = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::microseconds&gt;(</span><br><span class="line">                remote_end - local_end).<span class="built_in">count</span>();</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Node %d: Local=%ldμs, Remote=%ldμs, Ratio=%.2f\n&quot;</span>, </span><br><span class="line">                   node, local_time, remote_time, </span><br><span class="line">                   <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(remote_time) / local_time);</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">numa_free</span>(local_mem, <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">            <span class="built_in">numa_free</span>(remote_mem, <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="6-最佳实践总结"><a href="#6-最佳实践总结" class="headerlink" title="6. 最佳实践总结"></a>6. 最佳实践总结</h2><h3 id="6-1-CPU绑定最佳实践"><a href="#6-1-CPU绑定最佳实践" class="headerlink" title="6.1 CPU绑定最佳实践"></a>6.1 CPU绑定最佳实践</h3><ol>
<li><strong>选择合适的核心</strong>：避免绑定到同一个物理核心的超线程</li>
<li><strong>考虑NUMA节点</strong>：将线程绑定到同一NUMA节点的核心上</li>
<li><strong>监控性能</strong>：使用性能计数器验证绑定效果</li>
<li><strong>动态调整</strong>：根据负载情况动态调整绑定策略</li>
</ol>
<h3 id="6-2-NUMA优化最佳实践"><a href="#6-2-NUMA优化最佳实践" class="headerlink" title="6.2 NUMA优化最佳实践"></a>6.2 NUMA优化最佳实践</h3><ol>
<li><strong>本地内存分配</strong>：优先在本地NUMA节点分配内存</li>
<li><strong>数据局部性</strong>：将相关数据放在同一NUMA节点</li>
<li><strong>线程亲和性</strong>：将线程绑定到数据所在的NUMA节点</li>
<li><strong>负载均衡</strong>：避免单个NUMA节点过载</li>
</ol>
<h3 id="6-3-缓存优化最佳实践"><a href="#6-3-缓存优化最佳实践" class="headerlink" title="6.3 缓存优化最佳实践"></a>6.3 缓存优化最佳实践</h3><ol>
<li><strong>缓存行对齐</strong>：确保数据结构按缓存行对齐</li>
<li><strong>顺序访问</strong>：尽量使用顺序访问模式</li>
<li><strong>预取优化</strong>：合理使用软件和硬件预取</li>
<li><strong>减少伪共享</strong>：避免不同线程访问同一缓存行的不同部分</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>CPU绑定和NUMA感知编程是现代高性能计算的重要技术。通过理解底层原理并正确应用这些技术，可以显著提升应用程序的性能。关键是要根据具体的应用场景和硬件特性，选择合适的优化策略。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.intel.com/content/dam/doc/manual/64-ia-32-architectures-optimization-manual.pdf">Intel 64 and IA-32 Architectures Optimization Reference Manual</a></li>
<li><a target="_blank" rel="noopener" href="https://www.amd.com/system/files/TechDocs/24594.pdf">AMD64 Architecture Programmer’s Manual</a></li>
<li><a target="_blank" rel="noopener" href="https://lwn.net/Articles/254445/">NUMA-aware Programming</a></li>
<li><a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin-guide/cpu-affinity.html">CPU Affinity and Performance</a></li>
<li><a target="_blank" rel="noopener" href="https://www.intel.com/content/www/us/en/developer/articles/technical/cache-performance-and-optimization.html">Cache Performance and Optimization</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/10/Programming/CPP/modern%20cpu/" data-id="cme17ov0u003dwnon2smo4frn" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Programming/CPP/jemalloc" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/10/Programming/CPP/jemalloc/" class="article-date">
  <time class="dt-published" datetime="2025-07-10T01:24:11.149Z" itemprop="datePublished">2025-07-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="jemalloc-内存分配器详解"><a href="#jemalloc-内存分配器详解" class="headerlink" title="jemalloc 内存分配器详解"></a>jemalloc 内存分配器详解</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>jemalloc 是一个通用的内存分配器，由 Jason Evans 开发，最初为 FreeBSD 系统设计，现在被广泛应用于各种高性能系统中。它以其出色的内存碎片控制、多线程性能和可扩展性而闻名。</p>
<h2 id="1-jemalloc-核心原理"><a href="#1-jemalloc-核心原理" class="headerlink" title="1. jemalloc 核心原理"></a>1. jemalloc 核心原理</h2><h3 id="1-1-设计目标"><a href="#1-1-设计目标" class="headerlink" title="1.1 设计目标"></a>1.1 设计目标</h3><p>jemalloc 的设计目标包括：</p>
<ul>
<li><strong>减少内存碎片</strong>：通过精心设计的内存布局和分配策略</li>
<li><strong>提高多线程性能</strong>：减少线程间的锁竞争</li>
<li><strong>可扩展性</strong>：支持大内存分配和多种分配模式</li>
<li><strong>可观测性</strong>：提供详细的内存使用统计信息</li>
</ul>
<h3 id="1-2-内存布局架构"><a href="#1-2-内存布局架构" class="headerlink" title="1.2 内存布局架构"></a>1.2 内存布局架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">jemalloc 内存布局：</span><br><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│                    Arena (竞技场)                            │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  Chunk (2MB)  │  Chunk (2MB)  │  Chunk (2MB)  │  ...        │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  Run (页组)   │  Run (页组)   │  Run (页组)   │  ...        │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  Bin (大小类) │  Bin (大小类) │  Bin (大小类) │  ...        │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure>

<h3 id="1-3-核心组件"><a href="#1-3-核心组件" class="headerlink" title="1.3 核心组件"></a>1.3 核心组件</h3><h4 id="Arena-竞技场"><a href="#Arena-竞技场" class="headerlink" title="Arena (竞技场)"></a>Arena (竞技场)</h4><ul>
<li>每个 Arena 管理独立的内存池</li>
<li>默认情况下，每个 CPU 核心对应一个 Arena</li>
<li>减少线程间的锁竞争</li>
</ul>
<h4 id="Chunk-大块"><a href="#Chunk-大块" class="headerlink" title="Chunk (大块)"></a>Chunk (大块)</h4><ul>
<li>大小为 2MB 的内存块</li>
<li>是 Arena 分配的基本单位</li>
<li>支持不同的内存对齐要求</li>
</ul>
<h4 id="Run-页组"><a href="#Run-页组" class="headerlink" title="Run (页组)"></a>Run (页组)</h4><ul>
<li>由连续的页面组成</li>
<li>每个 Run 专门用于特定大小的分配</li>
<li>减少内存碎片</li>
</ul>
<h4 id="Bin-大小类"><a href="#Bin-大小类" class="headerlink" title="Bin (大小类)"></a>Bin (大小类)</h4><ul>
<li>将相似大小的分配请求归类</li>
<li>减少内存浪费</li>
<li>提高分配效率</li>
</ul>
<h2 id="2-分配策略"><a href="#2-分配策略" class="headerlink" title="2. 分配策略"></a>2. 分配策略</h2><h3 id="2-1-大小分类"><a href="#2-1-大小分类" class="headerlink" title="2.1 大小分类"></a>2.1 大小分类</h3><p>jemalloc 将分配请求按大小分为几类：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 小对象分配 (≤ 8KB)</span></span><br><span class="line"><span class="keyword">if</span> (size &lt;= <span class="number">8</span> * <span class="number">1024</span>) &#123;</span><br><span class="line">    <span class="comment">// 使用 Bin 分配</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">bin_alloc</span>(size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 大对象分配 (8KB - 2MB)</span></span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (size &lt;= <span class="number">2</span> * <span class="number">1024</span> * <span class="number">1024</span>) &#123;</span><br><span class="line">    <span class="comment">// 使用 Run 分配</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">run_alloc</span>(size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 超大对象分配 (&gt; 2MB)</span></span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 直接使用 mmap</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">huge_alloc</span>(size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-2-线程本地缓存-TLS"><a href="#2-2-线程本地缓存-TLS" class="headerlink" title="2.2 线程本地缓存 (TLS)"></a>2.2 线程本地缓存 (TLS)</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 线程本地缓存结构</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">tcache_s</span> &#123;</span><br><span class="line">    <span class="type">tcache_bin_t</span> bins[TCACHE_NBINS];  <span class="comment">// 每个大小类的缓存</span></span><br><span class="line">    <span class="type">uint32_t</span> gc_incr;                 <span class="comment">// 垃圾回收增量</span></span><br><span class="line">    <span class="type">uint32_t</span> counts[TCACHE_NBINS];    <span class="comment">// 每个bin的计数</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 快速分配路径</span></span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="title">fast_alloc</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="type">tcache_bin_t</span>* bin = &amp;tcache-&gt;bins[<span class="built_in">size_to_bin</span>(size)];</span><br><span class="line">    <span class="keyword">if</span> (bin-&gt;ncached &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 从线程本地缓存分配</span></span><br><span class="line">        <span class="keyword">return</span> bin-&gt;avail[--bin-&gt;ncached];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 回退到 Arena 分配</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">arena_alloc</span>(size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-内存回收策略"><a href="#2-3-内存回收策略" class="headerlink" title="2.3 内存回收策略"></a>2.3 内存回收策略</h3><h4 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h4><ul>
<li>定期触发垃圾回收</li>
<li>将线程本地缓存的对象归还给 Arena</li>
<li>减少内存占用</li>
</ul>
<h4 id="内存合并"><a href="#内存合并" class="headerlink" title="内存合并"></a>内存合并</h4><ul>
<li>合并相邻的空闲块</li>
<li>减少内存碎片</li>
<li>提高内存利用率</li>
</ul>
<h2 id="3-多线程优化"><a href="#3-多线程优化" class="headerlink" title="3. 多线程优化"></a>3. 多线程优化</h2><h3 id="3-1-Arena-分配"><a href="#3-1-Arena-分配" class="headerlink" title="3.1 Arena 分配"></a>3.1 Arena 分配</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Arena 分配策略</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">arena_s</span> &#123;</span><br><span class="line">    <span class="type">malloc_mutex_t</span> lock;           <span class="comment">// Arena 锁</span></span><br><span class="line">    <span class="type">chunk_alloc_t</span>* chunk_alloc;    <span class="comment">// Chunk 分配器</span></span><br><span class="line">    <span class="type">chunk_dalloc_t</span>* chunk_dalloc;  <span class="comment">// Chunk 释放器</span></span><br><span class="line">    <span class="type">arena_bin_t</span> bins[NBINS];       <span class="comment">// 大小类数组</span></span><br><span class="line">    <span class="type">arena_runs_dirty_t</span> runs_dirty; <span class="comment">// 脏页管理</span></span><br><span class="line">    <span class="type">arena_large_t</span>* large;          <span class="comment">// 大对象管理</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 线程到 Arena 的映射</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">arena_t</span>* <span class="title">arena_choose</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> arena_ind = <span class="built_in">atomic_fetch_add_u</span>(&amp;arenas_next_ind, <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> arenas[arena_ind % narenas_auto];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-锁优化"><a href="#3-2-锁优化" class="headerlink" title="3.2 锁优化"></a>3.2 锁优化</h3><ul>
<li><strong>细粒度锁</strong>：每个 Arena 有独立的锁</li>
<li><strong>无锁分配</strong>：线程本地缓存无需加锁</li>
<li><strong>锁分片</strong>：减少锁竞争</li>
</ul>
<h2 id="4-使用场景"><a href="#4-使用场景" class="headerlink" title="4. 使用场景"></a>4. 使用场景</h2><h3 id="4-1-高性能服务器"><a href="#4-1-高性能服务器" class="headerlink" title="4.1 高性能服务器"></a>4.1 高性能服务器</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在 C++ 项目中使用 jemalloc</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;jemalloc/jemalloc.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HighPerformanceServer</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 自定义内存分配器</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">JemallocAllocator</span> &#123;</span><br><span class="line">        <span class="function"><span class="type">void</span>* <span class="title">allocate</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">je_malloc</span>(size);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">            <span class="built_in">je_free</span>(ptr);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    std::vector&lt;<span class="type">int</span>, JemallocAllocator&gt; data_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">process_request</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 使用 jemalloc 进行内存分配</span></span><br><span class="line">        <span class="keyword">auto</span> buffer = std::<span class="built_in">make_unique</span>&lt;<span class="type">char</span>[]&gt;(<span class="number">1024</span>);</span><br><span class="line">        <span class="comment">// 处理请求...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="4-2-数据库系统"><a href="#4-2-数据库系统" class="headerlink" title="4.2 数据库系统"></a>4.2 数据库系统</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Redis 使用 jemalloc 的示例</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_JEMALLOC</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;jemalloc/jemalloc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> malloc je_malloc</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> free je_free</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> realloc je_realloc</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> calloc je_calloc</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 内存统计</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">print_memory_stats</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">size_t</span> allocated, active, metadata;</span><br><span class="line">    <span class="type">size_t</span> len = <span class="built_in">sizeof</span>(<span class="type">size_t</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">mallctl</span>(<span class="string">&quot;stats.allocated&quot;</span>, &amp;allocated, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">mallctl</span>(<span class="string">&quot;stats.active&quot;</span>, &amp;active, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">mallctl</span>(<span class="string">&quot;stats.metadata&quot;</span>, &amp;metadata, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Allocated: %zu, Active: %zu, Metadata: %zu\n&quot;</span>, </span><br><span class="line">           allocated, active, metadata);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-3-游戏引擎"><a href="#4-3-游戏引擎" class="headerlink" title="4.3 游戏引擎"></a>4.3 游戏引擎</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 游戏引擎中的内存管理</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GameEngine</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 对象池使用 jemalloc</span></span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">ObjectPool</span> &#123;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        std::vector&lt;T*, JemallocAllocator&gt; pool_;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function">T* <span class="title">acquire</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (pool_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">je_malloc</span>(<span class="built_in">sizeof</span>(T));</span><br><span class="line">            &#125;</span><br><span class="line">            T* obj = pool_.<span class="built_in">back</span>();</span><br><span class="line">            pool_.<span class="built_in">pop_back</span>();</span><br><span class="line">            <span class="keyword">return</span> obj;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">release</span><span class="params">(T* obj)</span> </span>&#123;</span><br><span class="line">            pool_.<span class="built_in">push_back</span>(obj);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="5-配置和调优"><a href="#5-配置和调优" class="headerlink" title="5. 配置和调优"></a>5. 配置和调优</h2><h3 id="5-1-编译时配置"><a href="#5-1-编译时配置" class="headerlink" title="5.1 编译时配置"></a>5.1 编译时配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译 jemalloc</span></span><br><span class="line">./configure --prefix=/usr/local/jemalloc \</span><br><span class="line">           --enable-prof \</span><br><span class="line">           --enable-stats \</span><br><span class="line">           --enable-debug</span><br><span class="line"></span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"></span><br><span class="line"><span class="comment"># 链接 jemalloc</span></span><br><span class="line">g++ -o myapp myapp.cpp -ljemalloc</span><br></pre></td></tr></table></figure>

<h3 id="5-2-运行时配置"><a href="#5-2-运行时配置" class="headerlink" title="5.2 运行时配置"></a>5.2 运行时配置</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置 Arena 数量</span></span><br><span class="line"><span class="built_in">mallctl</span>(<span class="string">&quot;arenas.narenas&quot;</span>, &amp;narenas, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置线程本地缓存大小</span></span><br><span class="line"><span class="type">size_t</span> tcache_max = <span class="number">1024</span>;</span><br><span class="line"><span class="built_in">mallctl</span>(<span class="string">&quot;tcache.max&quot;</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>, &amp;tcache_max, <span class="built_in">sizeof</span>(tcache_max));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 启用内存统计</span></span><br><span class="line"><span class="type">bool</span> stats_active = <span class="literal">true</span>;</span><br><span class="line"><span class="built_in">mallctl</span>(<span class="string">&quot;stats.active&quot;</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>, &amp;stats_active, <span class="built_in">sizeof</span>(stats_active));</span><br></pre></td></tr></table></figure>

<h3 id="5-3-环境变量"><a href="#5-3-环境变量" class="headerlink" title="5.3 环境变量"></a>5.3 环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置 Arena 数量</span></span><br><span class="line"><span class="built_in">export</span> MALLOC_CONF=<span class="string">&quot;narenas:8&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用内存统计</span></span><br><span class="line"><span class="built_in">export</span> MALLOC_CONF=<span class="string">&quot;stats:true&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置线程本地缓存</span></span><br><span class="line"><span class="built_in">export</span> MALLOC_CONF=<span class="string">&quot;tcache_max:1024&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用内存分析</span></span><br><span class="line"><span class="built_in">export</span> MALLOC_CONF=<span class="string">&quot;prof:true,prof_prefix:/tmp/jeprof&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="6-常见问题和解决方案"><a href="#6-常见问题和解决方案" class="headerlink" title="6. 常见问题和解决方案"></a>6. 常见问题和解决方案</h2><h3 id="6-1-内存泄漏检测"><a href="#6-1-内存泄漏检测" class="headerlink" title="6.1 内存泄漏检测"></a>6.1 内存泄漏检测</h3><p>jemalloc 可能会暴露原本存在的内存问题：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 问题代码：内存泄漏</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemoryLeakExample</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span>* data_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MemoryLeakExample</span>() &#123;</span><br><span class="line">        data_ = <span class="keyword">new</span> <span class="type">int</span>[<span class="number">1000</span>];  <span class="comment">// 分配内存</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ~<span class="built_in">MemoryLeakExample</span>() &#123;</span><br><span class="line">        <span class="comment">// 忘记释放内存！</span></span><br><span class="line">        <span class="comment">// delete[] data_;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 解决方案：使用智能指针</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SafeExample</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::unique_ptr&lt;<span class="type">int</span>[]&gt; data_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">SafeExample</span>() : <span class="built_in">data_</span>(std::<span class="built_in">make_unique</span>&lt;<span class="type">int</span>[]&gt;(<span class="number">1000</span>)) &#123;&#125;</span><br><span class="line">    <span class="comment">// 析构函数自动释放内存</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="6-2-内存碎片问题"><a href="#6-2-内存碎片问题" class="headerlink" title="6.2 内存碎片问题"></a>6.2 内存碎片问题</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 问题：频繁分配释放不同大小的内存</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">fragment_memory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;<span class="type">void</span>*&gt; ptrs;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; ++i) &#123;</span><br><span class="line">        <span class="comment">// 分配不同大小的内存</span></span><br><span class="line">        <span class="type">size_t</span> size = <span class="number">16</span> + (i % <span class="number">100</span>) * <span class="number">8</span>;</span><br><span class="line">        ptrs.<span class="built_in">push_back</span>(<span class="built_in">malloc</span>(size));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 随机释放一些内存</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">500</span>; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> idx = <span class="built_in">rand</span>() % ptrs.<span class="built_in">size</span>();</span><br><span class="line">        <span class="built_in">free</span>(ptrs[idx]);</span><br><span class="line">        ptrs.<span class="built_in">erase</span>(ptrs.<span class="built_in">begin</span>() + idx);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 释放剩余内存</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">void</span>* ptr : ptrs) &#123;</span><br><span class="line">        <span class="built_in">free</span>(ptr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 解决方案：使用对象池</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ObjectPool</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::stack&lt;T*&gt; pool_;</span><br><span class="line">    std::mutex mutex_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">T* <span class="title">acquire</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        <span class="keyword">if</span> (pool_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">T</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        T* obj = pool_.<span class="built_in">top</span>();</span><br><span class="line">        pool_.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">release</span><span class="params">(T* obj)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        pool_.<span class="built_in">push</span>(obj);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="6-3-性能调优"><a href="#6-3-性能调优" class="headerlink" title="6.3 性能调优"></a>6.3 性能调优</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 监控内存使用</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemoryMonitor</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">print_stats</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">size_t</span> allocated, active, metadata;</span><br><span class="line">        <span class="type">size_t</span> len = <span class="built_in">sizeof</span>(<span class="type">size_t</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.allocated&quot;</span>, &amp;allocated, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.active&quot;</span>, &amp;active, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.metadata&quot;</span>, &amp;metadata, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Memory Stats:\n&quot;</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  Allocated: %zu bytes\n&quot;</span>, allocated);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  Active: %zu bytes\n&quot;</span>, active);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  Metadata: %zu bytes\n&quot;</span>, metadata);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;  Fragmentation: %.2f%%\n&quot;</span>, </span><br><span class="line">               (<span class="type">double</span>)(active - allocated) / active * <span class="number">100</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">enable_profiling</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">bool</span> prof_active = <span class="literal">true</span>;</span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;prof.active&quot;</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>, &amp;prof_active, <span class="built_in">sizeof</span>(prof_active));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="7-性能对比"><a href="#7-性能对比" class="headerlink" title="7. 性能对比"></a>7. 性能对比</h2><h3 id="7-1-与系统-malloc-对比"><a href="#7-1-与系统-malloc-对比" class="headerlink" title="7.1 与系统 malloc 对比"></a>7.1 与系统 malloc 对比</h3><table>
<thead>
<tr>
<th>指标</th>
<th>系统 malloc</th>
<th>jemalloc</th>
<th>改进</th>
</tr>
</thead>
<tbody><tr>
<td>分配速度</td>
<td>基准</td>
<td>+15-25%</td>
<td>显著提升</td>
</tr>
<tr>
<td>内存碎片</td>
<td>基准</td>
<td>-50-70%</td>
<td>大幅减少</td>
</tr>
<tr>
<td>多线程性能</td>
<td>基准</td>
<td>+100-200%</td>
<td>显著提升</td>
</tr>
<tr>
<td>内存占用</td>
<td>基准</td>
<td>-10-20%</td>
<td>适度减少</td>
</tr>
</tbody></table>
<h3 id="7-2-实际测试数据"><a href="#7-2-实际测试数据" class="headerlink" title="7.2 实际测试数据"></a>7.2 实际测试数据</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 性能测试代码</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;chrono&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">benchmark_allocator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> num_allocations = <span class="number">1000000</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> num_threads = <span class="number">8</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">auto</span> start = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    </span><br><span class="line">    std::vector&lt;std::thread&gt; threads;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> t = <span class="number">0</span>; t &lt; num_threads; ++t) &#123;</span><br><span class="line">        threads.<span class="built_in">emplace_back</span>([num_allocations]() &#123;</span><br><span class="line">            std::vector&lt;<span class="type">void</span>*&gt; ptrs;</span><br><span class="line">            ptrs.<span class="built_in">reserve</span>(num_allocations);</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; num_allocations; ++i) &#123;</span><br><span class="line">                <span class="type">size_t</span> size = <span class="number">16</span> + (i % <span class="number">1000</span>) * <span class="number">8</span>;</span><br><span class="line">                ptrs.<span class="built_in">push_back</span>(<span class="built_in">malloc</span>(size));</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">void</span>* ptr : ptrs) &#123;</span><br><span class="line">                <span class="built_in">free</span>(ptr);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; thread : threads) &#123;</span><br><span class="line">        thread.<span class="built_in">join</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">auto</span> end = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line">    <span class="keyword">auto</span> duration = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::milliseconds&gt;(end - start);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Allocation benchmark completed in %lld ms\n&quot;</span>, duration.<span class="built_in">count</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="8-最佳实践"><a href="#8-最佳实践" class="headerlink" title="8. 最佳实践"></a>8. 最佳实践</h2><h3 id="8-1-内存分配模式"><a href="#8-1-内存分配模式" class="headerlink" title="8.1 内存分配模式"></a>8.1 内存分配模式</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 好的实践：批量分配</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BatchAllocator</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::vector&lt;<span class="type">void</span>*&gt; batch_;</span><br><span class="line">    <span class="type">size_t</span> batch_size_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">BatchAllocator</span>(<span class="type">size_t</span> batch_size = <span class="number">1000</span>) : <span class="built_in">batch_size_</span>(batch_size) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span>* <span class="title">allocate</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (batch_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="comment">// 批量预分配</span></span><br><span class="line">            batch_.<span class="built_in">reserve</span>(batch_size_);</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; batch_size_; ++i) &#123;</span><br><span class="line">                batch_.<span class="built_in">push_back</span>(<span class="built_in">malloc</span>(size));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="type">void</span>* ptr = batch_.<span class="built_in">back</span>();</span><br><span class="line">        batch_.<span class="built_in">pop_back</span>();</span><br><span class="line">        <span class="keyword">return</span> ptr;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">        batch_.<span class="built_in">push_back</span>(ptr);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (batch_.<span class="built_in">size</span>() &gt; batch_size_ * <span class="number">2</span>) &#123;</span><br><span class="line">            <span class="comment">// 清理多余的缓存</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">size_t</span> i = batch_size_; i &lt; batch_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">                <span class="built_in">free</span>(batch_[i]);</span><br><span class="line">            &#125;</span><br><span class="line">            batch_.<span class="built_in">resize</span>(batch_size_);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="8-2-内存对齐"><a href="#8-2-内存对齐" class="headerlink" title="8.2 内存对齐"></a>8.2 内存对齐</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 内存对齐分配</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlignedAllocator</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span>* <span class="title">allocate_aligned</span><span class="params">(<span class="type">size_t</span> size, <span class="type">size_t</span> alignment)</span> </span>&#123;</span><br><span class="line">        <span class="type">void</span>* ptr = <span class="literal">nullptr</span>;</span><br><span class="line">        <span class="type">int</span> result = <span class="built_in">posix_memalign</span>(&amp;ptr, alignment, size);</span><br><span class="line">        <span class="keyword">if</span> (result != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> std::<span class="built_in">bad_alloc</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ptr;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">deallocate_aligned</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">free</span>(ptr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用示例</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlignedBuffer</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">void</span>* data_;</span><br><span class="line">    <span class="type">size_t</span> size_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">AlignedBuffer</span>(<span class="type">size_t</span> size, <span class="type">size_t</span> alignment = <span class="number">64</span>) </span><br><span class="line">        : <span class="built_in">size_</span>(size) &#123;</span><br><span class="line">        data_ = AlignedAllocator::<span class="built_in">allocate_aligned</span>(size, alignment);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ~<span class="built_in">AlignedBuffer</span>() &#123;</span><br><span class="line">        AlignedAllocator::<span class="built_in">deallocate_aligned</span>(data_);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span>* <span class="title">data</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> data_; &#125;</span><br><span class="line">    <span class="function"><span class="type">size_t</span> <span class="title">size</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> size_; &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="8-3-内存池设计"><a href="#8-3-内存池设计" class="headerlink" title="8.3 内存池设计"></a>8.3 内存池设计</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 固定大小内存池</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="type">size_t</span> BlockSize&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FixedSizePool</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">Block</span> &#123;</span><br><span class="line">        Block* next;</span><br><span class="line">        <span class="type">char</span> data[BlockSize];</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    Block* free_list_;</span><br><span class="line">    std::vector&lt;Block*&gt; allocated_blocks_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">FixedSizePool</span>() : <span class="built_in">free_list_</span>(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span>* <span class="title">allocate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!free_list_) &#123;</span><br><span class="line">            <span class="built_in">allocate_new_block</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        Block* block = free_list_;</span><br><span class="line">        free_list_ = block-&gt;next;</span><br><span class="line">        allocated_blocks_.<span class="built_in">push_back</span>(block);</span><br><span class="line">        <span class="keyword">return</span> block-&gt;data;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">        Block* block = <span class="built_in">reinterpret_cast</span>&lt;Block*&gt;(</span><br><span class="line">            <span class="built_in">reinterpret_cast</span>&lt;<span class="type">char</span>*&gt;(ptr) - <span class="built_in">offsetof</span>(Block, data));</span><br><span class="line">        </span><br><span class="line">        block-&gt;next = free_list_;</span><br><span class="line">        free_list_ = block;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 从已分配列表中移除</span></span><br><span class="line">        <span class="keyword">auto</span> it = std::<span class="built_in">find</span>(allocated_blocks_.<span class="built_in">begin</span>(), </span><br><span class="line">                           allocated_blocks_.<span class="built_in">end</span>(), block);</span><br><span class="line">        <span class="keyword">if</span> (it != allocated_blocks_.<span class="built_in">end</span>()) &#123;</span><br><span class="line">            allocated_blocks_.<span class="built_in">erase</span>(it);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">allocate_new_block</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">size_t</span> blocks_per_chunk = <span class="number">1024</span>;</span><br><span class="line">        Block* chunk = <span class="built_in">reinterpret_cast</span>&lt;Block*&gt;(</span><br><span class="line">            <span class="built_in">malloc</span>(blocks_per_chunk * <span class="built_in">sizeof</span>(Block)));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 构建空闲链表</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; blocks_per_chunk - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">            chunk[i].next = &amp;chunk[i + <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        chunk[blocks_per_chunk - <span class="number">1</span>].next = <span class="literal">nullptr</span>;</span><br><span class="line">        </span><br><span class="line">        free_list_ = &amp;chunk[<span class="number">1</span>];</span><br><span class="line">        allocated_blocks_.<span class="built_in">push_back</span>(&amp;chunk[<span class="number">0</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="9-监控和调试"><a href="#9-监控和调试" class="headerlink" title="9. 监控和调试"></a>9. 监控和调试</h2><h3 id="9-1-内存使用监控"><a href="#9-1-内存使用监控" class="headerlink" title="9.1 内存使用监控"></a>9.1 内存使用监控</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 内存使用监控器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemoryMonitor</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::chrono::steady_clock::time_point last_check_;</span><br><span class="line">    <span class="type">size_t</span> last_allocated_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MemoryMonitor</span>() : <span class="built_in">last_allocated_</span>(<span class="number">0</span>) &#123;</span><br><span class="line">        last_check_ = std::chrono::steady_clock::<span class="built_in">now</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">check_memory_usage</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="type">size_t</span> allocated, active, metadata;</span><br><span class="line">        <span class="type">size_t</span> len = <span class="built_in">sizeof</span>(<span class="type">size_t</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.allocated&quot;</span>, &amp;allocated, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.active&quot;</span>, &amp;active, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">mallctl</span>(<span class="string">&quot;stats.metadata&quot;</span>, &amp;metadata, &amp;len, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">auto</span> now = std::chrono::steady_clock::<span class="built_in">now</span>();</span><br><span class="line">        <span class="keyword">auto</span> duration = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::seconds&gt;(</span><br><span class="line">            now - last_check_).<span class="built_in">count</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (duration &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="type">size_t</span> diff = allocated - last_allocated_;</span><br><span class="line">            <span class="type">double</span> rate = <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(diff) / duration;</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Memory usage: %zu bytes (%.2f bytes/sec)\n&quot;</span>, </span><br><span class="line">                   allocated, rate);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        last_allocated_ = allocated;</span><br><span class="line">        last_check_ = now;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="9-2-内存泄漏检测"><a href="#9-2-内存泄漏检测" class="headerlink" title="9.2 内存泄漏检测"></a>9.2 内存泄漏检测</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 内存泄漏检测器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeakDetector</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::unordered_set&lt;<span class="type">void</span>*&gt; allocated_ptrs_;</span><br><span class="line">    std::mutex mutex_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span>* <span class="title">track_allocation</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        allocated_ptrs_.<span class="built_in">insert</span>(ptr);</span><br><span class="line">        <span class="keyword">return</span> ptr;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">track_deallocation</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        allocated_ptrs_.<span class="built_in">erase</span>(ptr);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">report_leaks</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        <span class="keyword">if</span> (!allocated_ptrs_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Memory leak detected: %zu objects not freed\n&quot;</span>, </span><br><span class="line">                   allocated_ptrs_.<span class="built_in">size</span>());</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">void</span>* ptr : allocated_ptrs_) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;  Leaked pointer: %p\n&quot;</span>, ptr);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局泄漏检测器</span></span><br><span class="line"><span class="type">static</span> LeakDetector g_leak_detector;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 重载 new/delete 进行跟踪</span></span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="type">void</span>* ptr = <span class="built_in">malloc</span>(size);</span><br><span class="line">    g_leak_detector.<span class="built_in">track_allocation</span>(ptr);</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="type">void</span>* ptr)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    g_leak_detector.<span class="built_in">track_deallocation</span>(ptr);</span><br><span class="line">    <span class="built_in">free</span>(ptr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="10-总结"><a href="#10-总结" class="headerlink" title="10. 总结"></a>10. 总结</h2><p>jemalloc 是一个高性能的内存分配器，特别适合多线程环境和高性能应用。它的主要优势包括：</p>
<ol>
<li><strong>减少内存碎片</strong>：通过精心设计的内存布局和分配策略</li>
<li><strong>提高多线程性能</strong>：减少线程间的锁竞争</li>
<li><strong>可扩展性</strong>：支持大内存分配和多种分配模式</li>
<li><strong>可观测性</strong>：提供详细的内存使用统计信息</li>
</ol>
<h3 id="使用建议"><a href="#使用建议" class="headerlink" title="使用建议"></a>使用建议</h3><ol>
<li><strong>选择合适的场景</strong>：多线程、高并发应用</li>
<li><strong>正确配置</strong>：根据应用特点调整参数</li>
<li><strong>监控内存使用</strong>：及时发现和解决问题</li>
<li><strong>遵循最佳实践</strong>：避免常见的内存管理错误</li>
</ol>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ol>
<li><strong>可能暴露内存问题</strong>：jemalloc 的严格内存管理可能暴露原本存在的内存泄漏或越界访问</li>
<li><strong>学习成本</strong>：需要了解其工作原理和配置选项</li>
<li><strong>调试复杂性</strong>：内存问题的调试可能更加复杂</li>
</ol>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/jemalloc/jemalloc">jemalloc 官方文档</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bsdcan.org/2006/papers/jemalloc.pdf">jemalloc 论文：A Scalable Concurrent malloc(3) Implementation for FreeBSD</a></li>
<li><a target="_blank" rel="noopener" href="https://redis.io/topics/memory-optimization">Redis 内存优化实践</a></li>
<li><a target="_blank" rel="noopener" href="https://engineering.fb.com/2011/01/03/core-data/scalable-memory-allocation-using-jemalloc/">Facebook 内存分配器对比</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29216091">知乎：jemalloc 内存分配器详解</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhangyifei216/article/details/52247365">CSDN：jemalloc 源码分析</a></li>
<li><a target="_blank" rel="noopener" href="https://tech.meituan.com/2019/03/07/jemalloc-in-meituan.html">美团技术团队：jemalloc 在美团的实践</a></li>
<li><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1004367">腾讯技术工程：内存分配器对比分析</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/10/Programming/CPP/jemalloc/" data-id="cme17ov0q0033wnon4fukcqhq" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Programming/CPP/gRPC vs restful" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/07/Programming/CPP/gRPC%20vs%20restful/" class="article-date">
  <time class="dt-published" datetime="2025-07-07T02:17:45.805Z" itemprop="datePublished">2025-07-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/07/Programming/CPP/gRPC%20vs%20restful/" data-id="cme17ov0p002zwnon0f4q3aiw" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Programming/CPP/middle-layers for high performance cpp" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/07/Programming/CPP/middle-layers%20for%20high%20performance%20cpp/" class="article-date">
  <time class="dt-published" datetime="2025-07-07T02:12:35.768Z" itemprop="datePublished">2025-07-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>C++ 中间件（Middleware）是在应用程序与底层操作系统或网络之间提供通信、数据处理和分布式支持的组件。特别在高性能编程中，C++ 的中间件常用于 <strong>分布式系统、实时通信、消息传递、远程过程调用、共享内存、并发调度等场景</strong>。</p>
<p>以下是一些广泛使用、适用于高性能编程的 C++ 中间件，按功能分类整理：</p>
<hr>
<h3 id="🔁-消息队列-消息中间件"><a href="#🔁-消息队列-消息中间件" class="headerlink" title="🔁 消息队列 &#x2F; 消息中间件"></a>🔁 <strong>消息队列 &#x2F; 消息中间件</strong></h3><table>
<thead>
<tr>
<th>名称</th>
<th>特点</th>
<th>性能</th>
<th>协议支持</th>
</tr>
</thead>
<tbody><tr>
<td><strong>ZeroMQ</strong></td>
<td>轻量级消息传输库，极高性能，支持多种通信模式（PUB&#x2F;SUB, REQ&#x2F;REP 等）</td>
<td>非常高</td>
<td>TCP, IPC, inproc</td>
</tr>
<tr>
<td><strong>Nanomsg &#x2F; NNG</strong></td>
<td>ZeroMQ 的后续项目，更简洁 API、更好的线程模型</td>
<td>高</td>
<td>TCP, IPC</td>
</tr>
<tr>
<td><strong>RabbitMQ（C++客户端）</strong></td>
<td>强大的 AMQP 消息中间件，适合企业系统</td>
<td>较高</td>
<td>AMQP</td>
</tr>
<tr>
<td><strong>Kafka（cppkafka, librdkafka）</strong></td>
<td>高吞吐量的分布式日志系统，适合流式数据</td>
<td>极高</td>
<td>自定义二进制协议</td>
</tr>
<tr>
<td><strong>Redis（hiredis, redis-plus-plus）</strong></td>
<td>轻量 KV 消息中间件，可实现简单队列</td>
<td>高</td>
<td>RESP</td>
</tr>
</tbody></table>
<hr>
<h3 id="📦-RPC-服务框架（Remote-Procedure-Call）"><a href="#📦-RPC-服务框架（Remote-Procedure-Call）" class="headerlink" title="📦 RPC &#x2F; 服务框架（Remote Procedure Call）"></a>📦 <strong>RPC &#x2F; 服务框架（Remote Procedure Call）</strong></h3><table>
<thead>
<tr>
<th>名称</th>
<th>特点</th>
<th>性能</th>
<th>语言互通性</th>
</tr>
</thead>
<tbody><tr>
<td><strong>gRPC (C++ API)</strong></td>
<td>Google 开源，基于 HTTP&#x2F;2 + Protobuf</td>
<td>高</td>
<td>多语言</td>
</tr>
<tr>
<td><strong>Thrift（Apache）</strong></td>
<td>支持多语言，灵活高效的 RPC 框架</td>
<td>高</td>
<td>多语言</td>
</tr>
<tr>
<td><strong>Cap’n Proto</strong></td>
<td>比 Protobuf 更快的序列化 + RPC</td>
<td>极高</td>
<td>多语言</td>
</tr>
<tr>
<td><strong>brpc（百度）</strong></td>
<td>支持多协议（HTTP&#x2F;RPC）高并发 RPC 框架</td>
<td>极高（用于百度内部）</td>
<td>C++</td>
</tr>
<tr>
<td><strong>Tars（腾讯）</strong></td>
<td>微服务框架，内置服务发现、配置中心等</td>
<td>高</td>
<td>C++&#x2F;Java&#x2F;PHP 等</td>
</tr>
</tbody></table>
<hr>
<h3 id="🔀-共享内存-进程间通信（IPC）"><a href="#🔀-共享内存-进程间通信（IPC）" class="headerlink" title="🔀 共享内存 &#x2F; 进程间通信（IPC）"></a>🔀 <strong>共享内存 &#x2F; 进程间通信（IPC）</strong></h3><table>
<thead>
<tr>
<th>名称</th>
<th>特点</th>
<th>场景</th>
<th>性能</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Boost.Interprocess</strong></td>
<td>C++ 标准库风格的共享内存、信号量等</td>
<td>单机高效通信</td>
<td>高</td>
</tr>
<tr>
<td><strong>mmap + 自定义协议</strong></td>
<td>原始、灵活，需要自行管理</td>
<td>超低延迟需求</td>
<td>极高</td>
</tr>
<tr>
<td><strong>OpenSplice &#x2F; RTI Connext (DDS)</strong></td>
<td>数据分发服务（DDS）标准，实现实时通信</td>
<td>实时系统、航空、车载</td>
<td>高</td>
</tr>
</tbody></table>
<hr>
<h3 id="⛓️-协程-并发中间件"><a href="#⛓️-协程-并发中间件" class="headerlink" title="⛓️ 协程 &#x2F; 并发中间件"></a>⛓️ <strong>协程 &#x2F; 并发中间件</strong></h3><table>
<thead>
<tr>
<th>名称</th>
<th>特点</th>
<th>应用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>libgo（腾讯）</strong></td>
<td>基于C++协程调度器，兼容 Boost&#x2F;Go 风格 API</td>
<td>并发大量 IO 请求</td>
</tr>
<tr>
<td><strong>libtask</strong></td>
<td>协程库，模仿 Go 协程模型</td>
<td>高并发轻量服务</td>
</tr>
<tr>
<td><strong>folly（Facebook）</strong></td>
<td>包含协程、异步 IO、调度器等组件</td>
<td>高并发服务，配合 Wangle&#x2F;Proxygen</td>
</tr>
<tr>
<td><strong>asio &#x2F; Boost.Asio</strong></td>
<td>高性能异步 IO 框架，支持协程</td>
<td>网络编程基础设施</td>
</tr>
</tbody></table>
<hr>
<h3 id="🧱-组件化服务框架-微服务中间件"><a href="#🧱-组件化服务框架-微服务中间件" class="headerlink" title="🧱 组件化服务框架 &#x2F; 微服务中间件"></a>🧱 <strong>组件化服务框架 &#x2F; 微服务中间件</strong></h3><table>
<thead>
<tr>
<th>名称</th>
<th>特点</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Wangle（Facebook）</strong></td>
<td>C++ 网络服务框架，基于 Futures 和 Pipeline</td>
<td>用于构建高性能 C++ 网络服务</td>
</tr>
<tr>
<td><strong>Restbed</strong></td>
<td>RESTful API 服务框架</td>
<td>轻量 REST Server</td>
</tr>
<tr>
<td><strong>Seastar（ScyllaDB）</strong></td>
<td>基于 C++20 的异步框架，核心为未来式编程</td>
<td>超高并发服务器，如 ScyllaDB</td>
</tr>
</tbody></table>
<hr>
<h3 id="🔧-序列化框架（通常配合中间件使用）"><a href="#🔧-序列化框架（通常配合中间件使用）" class="headerlink" title="🔧 序列化框架（通常配合中间件使用）"></a>🔧 <strong>序列化框架（通常配合中间件使用）</strong></h3><table>
<thead>
<tr>
<th>名称</th>
<th>特点</th>
<th>性能</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Protobuf</strong></td>
<td>Google 标准，广泛使用</td>
<td>高</td>
</tr>
<tr>
<td><strong>FlatBuffers</strong></td>
<td>Zero-Copy，适合游戏&#x2F;实时应用</td>
<td>极高</td>
</tr>
<tr>
<td><strong>Cap’n Proto</strong></td>
<td>零拷贝设计，比 Protobuf 快</td>
<td>极高</td>
</tr>
<tr>
<td><strong>MessagePack</strong></td>
<td>紧凑二进制 JSON</td>
<td>高</td>
</tr>
</tbody></table>
<hr>
<h2 id="🎯-详细业务场景应用"><a href="#🎯-详细业务场景应用" class="headerlink" title="🎯 详细业务场景应用"></a>🎯 详细业务场景应用</h2><h3 id="🔁-消息队列-消息中间件应用场景"><a href="#🔁-消息队列-消息中间件应用场景" class="headerlink" title="🔁 消息队列&#x2F;消息中间件应用场景"></a>🔁 消息队列&#x2F;消息中间件应用场景</h3><h4 id="ZeroMQ-Nanomsg"><a href="#ZeroMQ-Nanomsg" class="headerlink" title="ZeroMQ &#x2F; Nanomsg"></a>ZeroMQ &#x2F; Nanomsg</h4><p><strong>适用场景：</strong></p>
<ul>
<li><strong>金融交易系统</strong>：高频交易中的订单路由，需要微秒级延迟</li>
<li><strong>游戏服务器</strong>：玩家状态同步、聊天系统</li>
<li><strong>IoT设备通信</strong>：传感器数据收集和指令下发</li>
<li><strong>实时监控系统</strong>：日志收集、性能指标传输</li>
</ul>
<p><strong>代码示例：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;zmq.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 发布-订阅模式，适用于广播场景</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MarketDataPublisher</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    zmq::<span class="type">context_t</span> context_;</span><br><span class="line">    zmq::<span class="type">socket_t</span> publisher_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MarketDataPublisher</span>() : <span class="built_in">context_</span>(<span class="number">1</span>), <span class="built_in">publisher_</span>(context_, ZMQ_PUB) &#123;</span><br><span class="line">        publisher_.<span class="built_in">bind</span>(<span class="string">&quot;tcp://*:5556&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">publish_market_data</span><span class="params">(<span class="type">const</span> std::string&amp; symbol, <span class="type">double</span> price)</span> </span>&#123;</span><br><span class="line">        std::string message = symbol + <span class="string">&quot;:&quot;</span> + std::<span class="built_in">to_string</span>(price);</span><br><span class="line">        publisher_.<span class="built_in">send</span>(zmq::<span class="built_in">buffer</span>(message));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 订阅者示例</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MarketDataSubscriber</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    zmq::<span class="type">context_t</span> context_;</span><br><span class="line">    zmq::<span class="type">socket_t</span> subscriber_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MarketDataSubscriber</span>() : <span class="built_in">context_</span>(<span class="number">1</span>), <span class="built_in">subscriber_</span>(context_, ZMQ_SUB) &#123;</span><br><span class="line">        subscriber_.<span class="built_in">connect</span>(<span class="string">&quot;tcp://localhost:5556&quot;</span>);</span><br><span class="line">        subscriber_.<span class="built_in">set</span>(zmq::sockopt::subscribe, <span class="string">&quot;AAPL&quot;</span>); <span class="comment">// 订阅特定股票</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">std::string <span class="title">receive_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        zmq::<span class="type">message_t</span> message;</span><br><span class="line">        subscriber_.<span class="built_in">recv</span>(&amp;message);</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">string</span>(<span class="built_in">static_cast</span>&lt;<span class="type">char</span>*&gt;(message.<span class="built_in">data</span>()), message.<span class="built_in">size</span>());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="Kafka-cppkafka"><a href="#Kafka-cppkafka" class="headerlink" title="Kafka (cppkafka)"></a>Kafka (cppkafka)</h4><p><strong>适用场景：</strong></p>
<ul>
<li><strong>大数据流处理</strong>：用户行为日志收集、点击流分析</li>
<li><strong>事件驱动架构</strong>：订单状态变更、库存变化通知</li>
<li><strong>数据管道</strong>：ETL过程中的数据传输</li>
<li><strong>微服务间通信</strong>：服务解耦、异步处理</li>
</ul>
<p><strong>业务案例：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cppkafka/cppkafka.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;nlohmann/json.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> json = nlohmann::json;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UserEventCollector</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    cppkafka::Configuration config_;</span><br><span class="line">    cppkafka::Producer producer_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">UserEventCollector</span>() : config_&#123;</span><br><span class="line">        &#123;<span class="string">&quot;metadata.broker.list&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;client.id&quot;</span>, <span class="string">&quot;user-event-collector&quot;</span>&#125;</span><br><span class="line">    &#125;, <span class="built_in">producer_</span>(config_) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">track_user_action</span><span class="params">(<span class="type">const</span> std::string&amp; user_id, </span></span></span><br><span class="line"><span class="params"><span class="function">                          <span class="type">const</span> std::string&amp; action,</span></span></span><br><span class="line"><span class="params"><span class="function">                          <span class="type">const</span> std::string&amp; page)</span> </span>&#123;</span><br><span class="line">        json event = &#123;</span><br><span class="line">            &#123;<span class="string">&quot;user_id&quot;</span>, user_id&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;action&quot;</span>, action&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;timestamp&quot;</span>, <span class="built_in">get_current_timestamp</span>()&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;page&quot;</span>, page&#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        </span><br><span class="line">        std::string message = event.<span class="built_in">dump</span>();</span><br><span class="line">        producer_.<span class="built_in">produce</span>(cppkafka::<span class="built_in">MessageBuilder</span>(<span class="string">&quot;user-events&quot;</span>)</span><br><span class="line">                         .<span class="built_in">payload</span>(message));</span><br><span class="line">        producer_.<span class="built_in">flush</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function">std::string <span class="title">get_current_timestamp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> now = std::chrono::system_clock::<span class="built_in">now</span>();</span><br><span class="line">        <span class="keyword">auto</span> <span class="type">time_t</span> = std::chrono::system_clock::<span class="built_in">to_time_t</span>(now);</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">ctime</span>(&amp;<span class="type">time_t</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="📦-RPC-服务框架应用场景"><a href="#📦-RPC-服务框架应用场景" class="headerlink" title="📦 RPC&#x2F;服务框架应用场景"></a>📦 RPC&#x2F;服务框架应用场景</h3><h4 id="gRPC"><a href="#gRPC" class="headerlink" title="gRPC"></a>gRPC</h4><p><strong>适用场景：</strong></p>
<ul>
<li><strong>微服务架构</strong>：服务间API调用</li>
<li><strong>移动应用后端</strong>：客户端与服务器通信</li>
<li><strong>云原生应用</strong>：容器化服务间通信</li>
<li><strong>API网关</strong>：统一的服务入口</li>
</ul>
<p><strong>实际应用：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// user_service.proto</span></span><br><span class="line">syntax = <span class="string">&quot;proto3&quot;</span>;</span><br><span class="line">package userservice;</span><br><span class="line"></span><br><span class="line">service UserService &#123;</span><br><span class="line">    <span class="function">rpc <span class="title">GetUser</span><span class="params">(GetUserRequest)</span> <span class="title">returns</span> <span class="params">(UserProfile)</span></span>;</span><br><span class="line">    <span class="function">rpc <span class="title">UpdateUser</span><span class="params">(UpdateUserRequest)</span> <span class="title">returns</span> <span class="params">(UserProfile)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message GetUserRequest &#123;</span><br><span class="line">    int32 user_id = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message UserProfile &#123;</span><br><span class="line">    int32 user_id = <span class="number">1</span>;</span><br><span class="line">    string name = <span class="number">2</span>;</span><br><span class="line">    string email = <span class="number">3</span>;</span><br><span class="line">    int64 created_at = <span class="number">4</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// C++ 客户端实现</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;grpcpp/grpcpp.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;user_service.grpc.pb.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UserServiceClient</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::unique_ptr&lt;UserService::Stub&gt; stub_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">UserServiceClient</span>(std::shared_ptr&lt;grpc::Channel&gt; channel)</span><br><span class="line">        : <span class="built_in">stub_</span>(UserService::<span class="built_in">NewStub</span>(channel)) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">UserProfile <span class="title">GetUserProfile</span><span class="params">(<span class="type">int</span> user_id)</span> </span>&#123;</span><br><span class="line">        GetUserRequest request;</span><br><span class="line">        request.<span class="built_in">set_user_id</span>(user_id);</span><br><span class="line">        </span><br><span class="line">        grpc::ClientContext context;</span><br><span class="line">        UserProfile response;</span><br><span class="line">        </span><br><span class="line">        grpc::Status status = stub_-&gt;<span class="built_in">GetUser</span>(&amp;context, request, &amp;response);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> response;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">throw</span> std::<span class="built_in">runtime_error</span>(<span class="string">&quot;RPC failed: &quot;</span> + status.<span class="built_in">error_message</span>());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">UpdateUserProfile</span><span class="params">(<span class="type">const</span> UserProfile&amp; profile)</span> </span>&#123;</span><br><span class="line">        UpdateUserRequest request;</span><br><span class="line">        request.<span class="built_in">mutable_user</span>()-&gt;<span class="built_in">CopyFrom</span>(profile);</span><br><span class="line">        </span><br><span class="line">        grpc::ClientContext context;</span><br><span class="line">        UserProfile response;</span><br><span class="line">        </span><br><span class="line">        grpc::Status status = stub_-&gt;<span class="built_in">UpdateUser</span>(&amp;context, request, &amp;response);</span><br><span class="line">        <span class="keyword">return</span> status.<span class="built_in">ok</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="brpc-百度"><a href="#brpc-百度" class="headerlink" title="brpc (百度)"></a>brpc (百度)</h4><p><strong>适用场景：</strong></p>
<ul>
<li><strong>搜索引擎</strong>：查询处理、索引更新</li>
<li><strong>推荐系统</strong>：特征计算、模型推理</li>
<li><strong>广告系统</strong>：实时竞价、广告投放</li>
<li><strong>高并发Web服务</strong>：API服务、数据处理</li>
</ul>
<p><strong>示例代码：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;brpc/server.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;brpc/restful.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义RPC服务</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SearchService</span> : <span class="keyword">public</span> SearchServiceBase &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Search</span><span class="params">(google::protobuf::RpcController* cntl_base,</span></span></span><br><span class="line"><span class="params"><span class="function">                <span class="type">const</span> SearchRequest* request,</span></span></span><br><span class="line"><span class="params"><span class="function">                SearchResponse* response,</span></span></span><br><span class="line"><span class="params"><span class="function">                google::protobuf::Closure* done)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">        <span class="function">brpc::ClosureGuard <span class="title">done_guard</span><span class="params">(done)</span></span>;</span><br><span class="line">        brpc::Controller* cntl = <span class="built_in">static_cast</span>&lt;brpc::Controller*&gt;(cntl_base);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 处理搜索请求</span></span><br><span class="line">        std::string query = request-&gt;<span class="built_in">query</span>();</span><br><span class="line">        <span class="keyword">auto</span> results = search_engine_.<span class="built_in">search</span>(query);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 填充响应</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; result : results) &#123;</span><br><span class="line">            <span class="keyword">auto</span>* item = response-&gt;<span class="built_in">add_results</span>();</span><br><span class="line">            item-&gt;<span class="built_in">set_title</span>(result.title);</span><br><span class="line">            item-&gt;<span class="built_in">set_url</span>(result.url);</span><br><span class="line">            item-&gt;<span class="built_in">set_snippet</span>(result.snippet);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    SearchEngine search_engine_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 启动服务器</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    brpc::Server server;</span><br><span class="line">    SearchService search_service;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (server.<span class="built_in">AddService</span>(&amp;search_service, brpc::SERVER_DOESNT_OWN_SERVICE) != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;Fail to add service&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    brpc::ServerOptions options;</span><br><span class="line">    <span class="keyword">if</span> (server.<span class="built_in">Start</span>(<span class="number">8000</span>, &amp;options) != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;Fail to start server&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    server.<span class="built_in">RunUntilAskedToQuit</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="🔀-共享内存-进程间通信应用场景"><a href="#🔀-共享内存-进程间通信应用场景" class="headerlink" title="🔀 共享内存&#x2F;进程间通信应用场景"></a>🔀 共享内存&#x2F;进程间通信应用场景</h3><h4 id="Boost-Interprocess"><a href="#Boost-Interprocess" class="headerlink" title="Boost.Interprocess"></a>Boost.Interprocess</h4><p><strong>适用场景：</strong></p>
<ul>
<li><strong>数据库系统</strong>：内存表、缓存层</li>
<li><strong>图像处理</strong>：大图像数据共享</li>
<li><strong>科学计算</strong>：大型矩阵运算</li>
<li><strong>实时系统</strong>：低延迟数据处理</li>
</ul>
<p><strong>示例：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/interprocess/shared_memory_object.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/interprocess/mapped_region.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/interprocess/sync/named_mutex.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> boost::interprocess;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SharedMemoryCache</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    shared_memory_object shm_;</span><br><span class="line">    mapped_region region_;</span><br><span class="line">    named_mutex mutex_;</span><br><span class="line">    <span class="type">char</span>* data_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">SharedMemoryCache</span>() </span><br><span class="line">        : <span class="built_in">shm_</span>(open_or_create, <span class="string">&quot;cache&quot;</span>, read_write)</span><br><span class="line">        , <span class="built_in">mutex_</span>(open_or_create, <span class="string">&quot;cache_mutex&quot;</span>) &#123;</span><br><span class="line">        </span><br><span class="line">        shm_.<span class="built_in">truncate</span>(<span class="number">1024</span>*<span class="number">1024</span>); <span class="comment">// 1MB</span></span><br><span class="line">        region_ = <span class="built_in">mapped_region</span>(shm_, read_write);</span><br><span class="line">        data_ = <span class="built_in">static_cast</span>&lt;<span class="type">char</span>*&gt;(region_.<span class="built_in">get_address</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">write_data</span><span class="params">(<span class="type">const</span> std::string&amp; key, <span class="type">const</span> std::string&amp; value)</span> </span>&#123;</span><br><span class="line">        <span class="function">scoped_lock&lt;named_mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 简单的键值存储实现</span></span><br><span class="line">        <span class="type">size_t</span> offset = <span class="built_in">hash_key</span>(key) % (<span class="number">1024</span>*<span class="number">1024</span> - <span class="number">100</span>);</span><br><span class="line">        std::string entry = key + <span class="string">&quot;:&quot;</span> + value + <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">        std::<span class="built_in">copy</span>(entry.<span class="built_in">begin</span>(), entry.<span class="built_in">end</span>(), data_ + offset);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">std::string <span class="title">read_data</span><span class="params">(<span class="type">const</span> std::string&amp; key)</span> </span>&#123;</span><br><span class="line">        <span class="function">scoped_lock&lt;named_mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 简单的查找实现</span></span><br><span class="line">        <span class="type">size_t</span> offset = <span class="built_in">hash_key</span>(key) % (<span class="number">1024</span>*<span class="number">1024</span> - <span class="number">100</span>);</span><br><span class="line">        <span class="function">std::string <span class="title">data</span><span class="params">(data_ + offset)</span></span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 解析键值对</span></span><br><span class="line">        <span class="type">size_t</span> pos = data.<span class="built_in">find</span>(<span class="string">&#x27;:&#x27;</span>);</span><br><span class="line">        <span class="keyword">if</span> (pos != std::string::npos) &#123;</span><br><span class="line">            std::string stored_key = data.<span class="built_in">substr</span>(<span class="number">0</span>, pos);</span><br><span class="line">            <span class="keyword">if</span> (stored_key == key) &#123;</span><br><span class="line">                <span class="type">size_t</span> end_pos = data.<span class="built_in">find</span>(<span class="string">&#x27;\n&#x27;</span>);</span><br><span class="line">                <span class="keyword">return</span> data.<span class="built_in">substr</span>(pos + <span class="number">1</span>, end_pos - pos - <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">size_t</span> <span class="title">hash_key</span><span class="params">(<span class="type">const</span> std::string&amp; key)</span> </span>&#123;</span><br><span class="line">        std::hash&lt;std::string&gt; hasher;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">hasher</span>(key);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="DDS-RTI-Connext"><a href="#DDS-RTI-Connext" class="headerlink" title="DDS (RTI Connext)"></a>DDS (RTI Connext)</h4><p><strong>适用场景：</strong></p>
<ul>
<li><strong>自动驾驶系统</strong>：传感器数据分发</li>
<li><strong>航空航天</strong>：飞行控制系统</li>
<li><strong>工业自动化</strong>：PLC通信</li>
<li><strong>医疗设备</strong>：实时监控系统</li>
</ul>
<p><strong>示例：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;dds/dds.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;dds/topic/Topic.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;dds/pub/Publisher.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;dds/sub/Subscriber.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义数据类型</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SensorData</span> &#123;</span><br><span class="line">    <span class="type">int</span> sensor_id;</span><br><span class="line">    <span class="type">double</span> temperature;</span><br><span class="line">    <span class="type">double</span> humidity;</span><br><span class="line">    <span class="type">long</span> timestamp;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SensorDataPublisher</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    dds::domain::DomainParticipant participant_;</span><br><span class="line">    dds::topic::Topic&lt;SensorData&gt; topic_;</span><br><span class="line">    dds::pub::Publisher publisher_;</span><br><span class="line">    dds::pub::DataWriter&lt;SensorData&gt; writer_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">SensorDataPublisher</span>() </span><br><span class="line">        : <span class="built_in">participant_</span>(<span class="number">0</span>)</span><br><span class="line">        , <span class="built_in">topic_</span>(participant_, <span class="string">&quot;SensorData&quot;</span>)</span><br><span class="line">        , <span class="built_in">publisher_</span>(participant_)</span><br><span class="line">        , <span class="built_in">writer_</span>(publisher_, topic_) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">publish_sensor_data</span><span class="params">(<span class="type">int</span> sensor_id, <span class="type">double</span> temp, <span class="type">double</span> humidity)</span> </span>&#123;</span><br><span class="line">        SensorData data;</span><br><span class="line">        data.sensor_id = sensor_id;</span><br><span class="line">        data.temperature = temp;</span><br><span class="line">        data.humidity = humidity;</span><br><span class="line">        data.timestamp = <span class="built_in">get_current_time</span>();</span><br><span class="line">        </span><br><span class="line">        writer_.<span class="built_in">write</span>(data);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">long</span> <span class="title">get_current_time</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::milliseconds&gt;(</span><br><span class="line">            std::chrono::system_clock::<span class="built_in">now</span>().<span class="built_in">time_since_epoch</span>()</span><br><span class="line">        ).<span class="built_in">count</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="⛓️-协程-并发中间件应用场景"><a href="#⛓️-协程-并发中间件应用场景" class="headerlink" title="⛓️ 协程&#x2F;并发中间件应用场景"></a>⛓️ 协程&#x2F;并发中间件应用场景</h3><h4 id="libgo"><a href="#libgo" class="headerlink" title="libgo"></a>libgo</h4><p><strong>适用场景：</strong></p>
<ul>
<li><strong>Web服务器</strong>：处理大量并发连接</li>
<li><strong>代理服务器</strong>：请求转发、负载均衡</li>
<li><strong>API网关</strong>：路由、认证、限流</li>
<li><strong>聊天应用</strong>：消息处理、用户会话管理</li>
</ul>
<p><strong>代码示例：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;libgo/libgo.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WebServer</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 启动协程处理HTTP请求</span></span><br><span class="line">        <span class="built_in">go</span>([<span class="keyword">this</span>]() &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">                <span class="built_in">go</span>([<span class="keyword">this</span>, i]() &#123;</span><br><span class="line">                    <span class="built_in">handle_request</span>(i);</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 启动协程处理WebSocket连接</span></span><br><span class="line">        <span class="built_in">go</span>([<span class="keyword">this</span>]() &#123;</span><br><span class="line">            <span class="built_in">handle_websocket_connections</span>();</span><br><span class="line">        &#125;);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 启动协程进行健康检查</span></span><br><span class="line">        <span class="built_in">go</span>([<span class="keyword">this</span>]() &#123;</span><br><span class="line">            <span class="built_in">health_check_loop</span>();</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">handle_request</span><span class="params">(<span class="type">int</span> request_id)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 模拟HTTP请求处理</span></span><br><span class="line">        std::string response = <span class="built_in">process_request</span>(request_id);</span><br><span class="line">        <span class="built_in">send_response</span>(response);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">handle_websocket_connections</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 处理WebSocket消息</span></span><br><span class="line">            std::string message = <span class="built_in">receive_websocket_message</span>();</span><br><span class="line">            <span class="built_in">go</span>([<span class="keyword">this</span>, message]() &#123;</span><br><span class="line">                <span class="built_in">process_websocket_message</span>(message);</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">health_check_loop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="built_in">co_sleep</span>(<span class="number">5000</span>); <span class="comment">// 5秒检查一次</span></span><br><span class="line">            <span class="built_in">check_system_health</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">std::string <span class="title">process_request</span><span class="params">(<span class="type">int</span> request_id)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 模拟请求处理逻辑</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Response for request &quot;</span> + std::<span class="built_in">to_string</span>(request_id);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">send_response</span><span class="params">(<span class="type">const</span> std::string&amp; response)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 发送HTTP响应</span></span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Sending response: &quot;</span> &lt;&lt; response &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">std::string <span class="title">receive_websocket_message</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 接收WebSocket消息</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;WebSocket message&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">process_websocket_message</span><span class="params">(<span class="type">const</span> std::string&amp; message)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 处理WebSocket消息</span></span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Processing WebSocket message: &quot;</span> &lt;&lt; message &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">check_system_health</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 系统健康检查</span></span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Performing health check...&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="Seastar"><a href="#Seastar" class="headerlink" title="Seastar"></a>Seastar</h4><p><strong>适用场景：</strong></p>
<ul>
<li><strong>NoSQL数据库</strong>：如ScyllaDB</li>
<li><strong>流处理引擎</strong>：实时数据处理</li>
<li><strong>缓存系统</strong>：高性能内存缓存</li>
<li><strong>CDN节点</strong>：内容分发网络</li>
</ul>
<p><strong>示例：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;seastar/core/app-template.hh&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;seastar/core/reactor.hh&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;seastar/http/httpd.hh&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;seastar/http/handlers.hh&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CacheService</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    seastar::httpd::http_server server_;</span><br><span class="line">    std::unordered_map&lt;std::string, std::string&gt; cache_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    seastar::future&lt;&gt; <span class="built_in">start</span>() &#123;</span><br><span class="line">        server_.<span class="built_in">set_routes</span>([<span class="keyword">this</span>](seastar::httpd::routes&amp; r) &#123;</span><br><span class="line">            r.<span class="built_in">add</span>(seastar::httpd::operation_type::GET, <span class="string">&quot;/cache/&#123;key&#125;&quot;</span>, </span><br><span class="line">                  [<span class="keyword">this</span>](seastar::httpd::const_req&amp; req) &#123;</span><br><span class="line">                      <span class="keyword">return</span> <span class="built_in">get_cache_value</span>(req.param[<span class="string">&quot;key&quot;</span>]);</span><br><span class="line">                  &#125;);</span><br><span class="line">            </span><br><span class="line">            r.<span class="built_in">add</span>(seastar::httpd::operation_type::PUT, <span class="string">&quot;/cache/&#123;key&#125;&quot;</span>, </span><br><span class="line">                  [<span class="keyword">this</span>](seastar::httpd::const_req&amp; req) &#123;</span><br><span class="line">                      <span class="keyword">return</span> <span class="built_in">set_cache_value</span>(req.param[<span class="string">&quot;key&quot;</span>], req.content);</span><br><span class="line">                  &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> server_.<span class="built_in">listen</span>(seastar::socket_address&#123;<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8080</span>&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function">std::string <span class="title">get_cache_value</span><span class="params">(<span class="type">const</span> std::string&amp; key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> it = cache_.<span class="built_in">find</span>(key);</span><br><span class="line">        <span class="keyword">if</span> (it != cache_.<span class="built_in">end</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> it-&gt;second;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Not found&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">std::string <span class="title">set_cache_value</span><span class="params">(<span class="type">const</span> std::string&amp; key, <span class="type">const</span> std::string&amp; value)</span> </span>&#123;</span><br><span class="line">        cache_[key] = value;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;OK&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    seastar::app_template app;</span><br><span class="line">    app.<span class="built_in">run</span>(argc, argv, []() &#123;</span><br><span class="line">        <span class="keyword">auto</span> cache_service = std::<span class="built_in">make_unique</span>&lt;CacheService&gt;();</span><br><span class="line">        <span class="keyword">return</span> cache_service-&gt;<span class="built_in">start</span>();</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="🧱-组件化服务框架应用场景"><a href="#🧱-组件化服务框架应用场景" class="headerlink" title="🧱 组件化服务框架应用场景"></a>🧱 组件化服务框架应用场景</h3><h4 id="Wangle-Facebook"><a href="#Wangle-Facebook" class="headerlink" title="Wangle (Facebook)"></a>Wangle (Facebook)</h4><p><strong>适用场景：</strong></p>
<ul>
<li><strong>社交网络后端</strong>：用户关系、内容分发</li>
<li><strong>广告投放系统</strong>：实时竞价、创意投放</li>
<li><strong>推荐引擎</strong>：个性化推荐服务</li>
<li><strong>API服务</strong>：RESTful API服务</li>
</ul>
<p><strong>示例：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;wangle/bootstrap/ServerBootstrap.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;wangle/channel/AsyncSocketHandler.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;wangle/codec/LineBasedFrameDecoder.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;wangle/codec/StringCodec.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EchoHandler</span> : <span class="keyword">public</span> wangle::HandlerAdapter&lt;std::string&gt; &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">read</span><span class="params">(wangle::Context* ctx, std::string msg)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 简单的echo服务</span></span><br><span class="line">        ctx-&gt;<span class="built_in">fireWrite</span>(msg + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EchoPipelineFactory</span> : <span class="keyword">public</span> wangle::PipelineFactory&lt;wangle::DefaultPipeline&gt; &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    wangle::<span class="function">DefaultPipeline::Ptr <span class="title">newPipeline</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        std::shared_ptr&lt;folly::AsyncSocket&gt; sock)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">auto</span> pipeline = wangle::DefaultPipeline::<span class="built_in">create</span>();</span><br><span class="line">        pipeline-&gt;<span class="built_in">addBack</span>(wangle::<span class="built_in">AsyncSocketHandler</span>(sock));</span><br><span class="line">        pipeline-&gt;<span class="built_in">addBack</span>(wangle::<span class="built_in">LineBasedFrameDecoder</span>(<span class="number">8192</span>));</span><br><span class="line">        pipeline-&gt;<span class="built_in">addBack</span>(wangle::<span class="built_in">StringCodec</span>());</span><br><span class="line">        pipeline-&gt;<span class="built_in">addBack</span>(<span class="built_in">EchoHandler</span>());</span><br><span class="line">        pipeline-&gt;<span class="built_in">finalize</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> pipeline;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    wangle::ServerBootstrap&lt;wangle::DefaultPipeline&gt; server;</span><br><span class="line">    server.<span class="built_in">childPipeline</span>(std::<span class="built_in">make_shared</span>&lt;EchoPipelineFactory&gt;());</span><br><span class="line">    server.<span class="built_in">bind</span>(<span class="number">8080</span>);</span><br><span class="line">    server.<span class="built_in">waitForStop</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="🔧-序列化框架应用场景"><a href="#🔧-序列化框架应用场景" class="headerlink" title="🔧 序列化框架应用场景"></a>🔧 序列化框架应用场景</h3><h4 id="FlatBuffers"><a href="#FlatBuffers" class="headerlink" title="FlatBuffers"></a>FlatBuffers</h4><p><strong>适用场景：</strong></p>
<ul>
<li><strong>游戏开发</strong>：网络协议、存档格式</li>
<li><strong>移动应用</strong>：客户端-服务器通信</li>
<li><strong>实时系统</strong>：低延迟数据传输</li>
<li><strong>嵌入式系统</strong>：资源受限环境</li>
</ul>
<p><strong>性能对比示例：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;flatbuffers/flatbuffers.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;google/protobuf/message.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// FlatBuffers schema (game_data.fbs)</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">table Player &#123;</span></span><br><span class="line"><span class="comment">    id:int;</span></span><br><span class="line"><span class="comment">    name:string;</span></span><br><span class="line"><span class="comment">    position:Vec3;</span></span><br><span class="line"><span class="comment">    health:int;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">table Vec3 &#123;</span></span><br><span class="line"><span class="comment">    x:float;</span></span><br><span class="line"><span class="comment">    y:float;</span></span><br><span class="line"><span class="comment">    z:float;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">root_type Player;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GameDataSerializer</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// FlatBuffers序列化 - 零拷贝，直接访问</span></span><br><span class="line">    <span class="function">std::vector&lt;<span class="type">uint8_t</span>&gt; <span class="title">serialize_with_flatbuffers</span><span class="params">(<span class="type">int</span> id, <span class="type">const</span> std::string&amp; name, </span></span></span><br><span class="line"><span class="params"><span class="function">                                                   <span class="type">float</span> x, <span class="type">float</span> y, <span class="type">float</span> z, <span class="type">int</span> health)</span> </span>&#123;</span><br><span class="line">        flatbuffers::FlatBufferBuilder builder;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">auto</span> name_fb = builder.<span class="built_in">CreateString</span>(name);</span><br><span class="line">        <span class="keyword">auto</span> position = <span class="built_in">CreateVec3</span>(builder, x, y, z);</span><br><span class="line">        <span class="keyword">auto</span> player = <span class="built_in">CreatePlayer</span>(builder, id, name_fb, position, health);</span><br><span class="line">        </span><br><span class="line">        builder.<span class="built_in">Finish</span>(player);</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">vector</span>&lt;<span class="type">uint8_t</span>&gt;(builder.<span class="built_in">GetBufferPointer</span>(), </span><br><span class="line">                                   builder.<span class="built_in">GetBufferPointer</span>() + builder.<span class="built_in">GetSize</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 反序列化 - 直接访问，无拷贝</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">deserialize_with_flatbuffers</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">uint8_t</span>&gt;&amp; data)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> player = flatbuffers::<span class="built_in">GetRoot</span>&lt;Player&gt;(data.<span class="built_in">data</span>());</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 直接访问，无拷贝</span></span><br><span class="line">        <span class="type">int</span> id = player-&gt;<span class="built_in">id</span>();</span><br><span class="line">        std::string name = player-&gt;<span class="built_in">name</span>()-&gt;<span class="built_in">str</span>(); <span class="comment">// 这里会有一次拷贝</span></span><br><span class="line">        <span class="type">float</span> x = player-&gt;<span class="built_in">position</span>()-&gt;<span class="built_in">x</span>();</span><br><span class="line">        <span class="type">float</span> y = player-&gt;<span class="built_in">position</span>()-&gt;<span class="built_in">y</span>();</span><br><span class="line">        <span class="type">float</span> z = player-&gt;<span class="built_in">position</span>()-&gt;<span class="built_in">z</span>();</span><br><span class="line">        <span class="type">int</span> health = player-&gt;<span class="built_in">health</span>();</span><br><span class="line">        </span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Player: &quot;</span> &lt;&lt; name &lt;&lt; <span class="string">&quot; at (&quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; y &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; z &lt;&lt; <span class="string">&quot;)&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Protobuf序列化 - 需要解析和拷贝</span></span><br><span class="line">    <span class="function">std::string <span class="title">serialize_with_protobuf</span><span class="params">(<span class="type">int</span> id, <span class="type">const</span> std::string&amp; name, </span></span></span><br><span class="line"><span class="params"><span class="function">                                       <span class="type">float</span> x, <span class="type">float</span> y, <span class="type">float</span> z, <span class="type">int</span> health)</span> </span>&#123;</span><br><span class="line">        PlayerProto player;</span><br><span class="line">        player.<span class="built_in">set_id</span>(id);</span><br><span class="line">        player.<span class="built_in">set_name</span>(name);</span><br><span class="line">        player.<span class="built_in">mutable_position</span>()-&gt;<span class="built_in">set_x</span>(x);</span><br><span class="line">        player.<span class="built_in">mutable_position</span>()-&gt;<span class="built_in">set_y</span>(y);</span><br><span class="line">        player.<span class="built_in">mutable_position</span>()-&gt;<span class="built_in">set_z</span>(z);</span><br><span class="line">        player.<span class="built_in">set_health</span>(health);</span><br><span class="line">        </span><br><span class="line">        std::string data;</span><br><span class="line">        player.<span class="built_in">SerializeToString</span>(&amp;data);</span><br><span class="line">        <span class="keyword">return</span> data;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">deserialize_with_protobuf</span><span class="params">(<span class="type">const</span> std::string&amp; data)</span> </span>&#123;</span><br><span class="line">        PlayerProto player;</span><br><span class="line">        player.<span class="built_in">ParseFromString</span>(data);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 涉及拷贝</span></span><br><span class="line">        <span class="type">int</span> id = player.<span class="built_in">id</span>();</span><br><span class="line">        std::string name = player.<span class="built_in">name</span>(); <span class="comment">// 拷贝</span></span><br><span class="line">        <span class="type">float</span> x = player.<span class="built_in">position</span>().<span class="built_in">x</span>();</span><br><span class="line">        <span class="type">float</span> y = player.<span class="built_in">position</span>().<span class="built_in">y</span>();</span><br><span class="line">        <span class="type">float</span> z = player.<span class="built_in">position</span>().<span class="built_in">z</span>();</span><br><span class="line">        <span class="type">int</span> health = player.<span class="built_in">health</span>();</span><br><span class="line">        </span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Player: &quot;</span> &lt;&lt; name &lt;&lt; <span class="string">&quot; at (&quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; y &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; z &lt;&lt; <span class="string">&quot;)&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="🏗️-具体业务场景架构组合"><a href="#🏗️-具体业务场景架构组合" class="headerlink" title="🏗️ 具体业务场景架构组合"></a>🏗️ 具体业务场景架构组合</h2><h3 id="1-电商系统架构"><a href="#1-电商系统架构" class="headerlink" title="1. 电商系统架构"></a>1. 电商系统架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">前端 -&gt; API网关(Wangle) -&gt; 用户服务(gRPC) -&gt; 数据库</span><br><span class="line">                ↓</span><br><span class="line">        订单服务(gRPC) -&gt; 库存服务(gRPC)</span><br><span class="line">                ↓</span><br><span class="line">        支付服务(gRPC) -&gt; 消息队列(Kafka) -&gt; 物流系统</span><br></pre></td></tr></table></figure>

<p><strong>实现要点：</strong></p>
<ul>
<li><strong>API网关</strong>：使用Wangle处理路由、认证、限流</li>
<li><strong>服务间通信</strong>：gRPC + Protobuf确保高性能</li>
<li><strong>异步处理</strong>：Kafka处理订单状态变更、库存更新</li>
<li><strong>数据一致性</strong>：通过消息队列保证最终一致性</li>
</ul>
<h3 id="2-金融交易系统架构"><a href="#2-金融交易系统架构" class="headerlink" title="2. 金融交易系统架构"></a>2. 金融交易系统架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">交易终端 -&gt; 订单路由(ZeroMQ) -&gt; 风控系统(gRPC)</span><br><span class="line">                ↓</span><br><span class="line">        执行引擎(共享内存) -&gt; 清算系统(Kafka)</span><br></pre></td></tr></table></figure>

<p><strong>实现要点：</strong></p>
<ul>
<li><strong>低延迟</strong>：ZeroMQ提供微秒级延迟</li>
<li><strong>实时风控</strong>：gRPC确保风控检查的实时性</li>
<li><strong>高性能执行</strong>：共享内存减少序列化开销</li>
<li><strong>数据持久化</strong>：Kafka保证交易数据不丢失</li>
</ul>
<h3 id="3-游戏服务器架构"><a href="#3-游戏服务器架构" class="headerlink" title="3. 游戏服务器架构"></a>3. 游戏服务器架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">游戏客户端 -&gt; 网关服务器(libgo) -&gt; 游戏逻辑服务器</span><br><span class="line">                ↓</span><br><span class="line">        聊天系统(ZeroMQ) -&gt; 数据库</span><br><span class="line">                ↓</span><br><span class="line">        排行榜系统(Redis) -&gt; 数据分析(Kafka)</span><br></pre></td></tr></table></figure>

<p><strong>实现要点：</strong></p>
<ul>
<li><strong>高并发</strong>：libgo协程处理大量连接</li>
<li><strong>实时通信</strong>：ZeroMQ处理聊天和状态同步</li>
<li><strong>排行榜</strong>：Redis提供高性能缓存</li>
<li><strong>数据分析</strong>：Kafka收集玩家行为数据</li>
</ul>
<h3 id="4-IoT平台架构"><a href="#4-IoT平台架构" class="headerlink" title="4. IoT平台架构"></a>4. IoT平台架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">传感器 -&gt; 边缘计算(DDS) -&gt; 云端处理(Kafka)</span><br><span class="line">                ↓</span><br><span class="line">        数据分析(gRPC) -&gt; 存储系统</span><br><span class="line">                ↓</span><br><span class="line">        告警系统(ZeroMQ) -&gt; 通知服务</span><br></pre></td></tr></table></figure>

<p><strong>实现要点：</strong></p>
<ul>
<li><strong>实时通信</strong>：DDS处理传感器数据分发</li>
<li><strong>数据收集</strong>：Kafka处理大量IoT数据</li>
<li><strong>分析处理</strong>：gRPC调用机器学习模型</li>
<li><strong>告警通知</strong>：ZeroMQ确保告警及时送达</li>
</ul>
<hr>
<h2 id="💡-中间件选择指南"><a href="#💡-中间件选择指南" class="headerlink" title="💡 中间件选择指南"></a>💡 中间件选择指南</h2><h3 id="性能需求导向"><a href="#性能需求导向" class="headerlink" title="性能需求导向"></a>性能需求导向</h3><ol>
<li><strong>高吞吐量场景</strong>：Kafka + gRPC</li>
<li><strong>低延迟场景</strong>：ZeroMQ + FlatBuffers</li>
<li><strong>实时系统</strong>：DDS + 共享内存</li>
<li><strong>微服务架构</strong>：gRPC + Protobuf</li>
<li><strong>高并发Web</strong>：libgo + Restbed</li>
<li><strong>大数据处理</strong>：Kafka + 自定义序列化</li>
</ol>
<h3 id="技术栈考虑"><a href="#技术栈考虑" class="headerlink" title="技术栈考虑"></a>技术栈考虑</h3><ul>
<li><strong>团队熟悉度</strong>：选择团队熟悉的中间件</li>
<li><strong>生态系统</strong>：考虑周边工具和社区支持</li>
<li><strong>维护成本</strong>：评估运维和监控复杂度</li>
<li><strong>扩展性</strong>：考虑未来业务增长需求</li>
</ul>
<h3 id="成本效益分析"><a href="#成本效益分析" class="headerlink" title="成本效益分析"></a>成本效益分析</h3><ul>
<li><strong>开发成本</strong>：学习曲线和开发时间</li>
<li><strong>运维成本</strong>：部署、监控、维护</li>
<li><strong>性能收益</strong>：延迟降低、吞吐量提升</li>
<li><strong>业务价值</strong>：用户体验改善、成本节约</li>
</ul>
<hr>
<h2 id="🔧-性能优化最佳实践"><a href="#🔧-性能优化最佳实践" class="headerlink" title="🔧 性能优化最佳实践"></a>🔧 性能优化最佳实践</h2><h3 id="1-网络优化"><a href="#1-网络优化" class="headerlink" title="1. 网络优化"></a>1. 网络优化</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用连接池</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConnectionPool</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::queue&lt;std::shared_ptr&lt;grpc::Channel&gt;&gt; connections_;</span><br><span class="line">    std::mutex mutex_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">std::shared_ptr&lt;grpc::Channel&gt; <span class="title">get_connection</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        <span class="keyword">if</span> (connections_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> grpc::<span class="built_in">CreateChannel</span>(<span class="string">&quot;localhost:50051&quot;</span>, </span><br><span class="line">                                     grpc::<span class="built_in">InsecureChannelCredentials</span>());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">auto</span> conn = connections_.<span class="built_in">front</span>();</span><br><span class="line">        connections_.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="keyword">return</span> conn;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">return_connection</span><span class="params">(std::shared_ptr&lt;grpc::Channel&gt; conn)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        connections_.<span class="built_in">push</span>(conn);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="2-内存优化"><a href="#2-内存优化" class="headerlink" title="2. 内存优化"></a>2. 内存优化</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对象池模式</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ObjectPool</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::queue&lt;std::unique_ptr&lt;T&gt;&gt; pool_;</span><br><span class="line">    std::mutex mutex_;</span><br><span class="line">    std::function&lt;std::unique_ptr&lt;T&gt;()&gt; factory_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span>... Args&gt;</span></span><br><span class="line"><span class="function">    <span class="title">ObjectPool</span><span class="params">(<span class="type">size_t</span> initial_size, Args&amp;&amp;... args)</span> </span>&#123;</span><br><span class="line">        factory_ = [args...]() &#123;</span><br><span class="line">            <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;T&gt;(std::forward&lt;Args&gt;(args)...);</span><br><span class="line">        &#125;;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; initial_size; ++i) &#123;</span><br><span class="line">            pool_.<span class="built_in">push</span>(<span class="built_in">factory_</span>());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">std::unique_ptr&lt;T&gt; <span class="title">acquire</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        <span class="keyword">if</span> (pool_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">factory_</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">auto</span> obj = std::<span class="built_in">move</span>(pool_.<span class="built_in">front</span>());</span><br><span class="line">        pool_.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">release</span><span class="params">(std::unique_ptr&lt;T&gt; obj)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        pool_.<span class="built_in">push</span>(std::<span class="built_in">move</span>(obj));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="3-并发优化"><a href="#3-并发优化" class="headerlink" title="3. 并发优化"></a>3. 并发优化</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 无锁环形缓冲区</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="type">size_t</span> Size&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LockFreeRingBuffer</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::array&lt;T, Size&gt; buffer_;</span><br><span class="line">    std::atomic&lt;<span class="type">size_t</span>&gt; head_&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    std::atomic&lt;<span class="type">size_t</span>&gt; tail_&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">push</span><span class="params">(<span class="type">const</span> T&amp; item)</span> </span>&#123;</span><br><span class="line">        <span class="type">size_t</span> current_tail = tail_.<span class="built_in">load</span>(std::memory_order_relaxed);</span><br><span class="line">        <span class="type">size_t</span> next_tail = (current_tail + <span class="number">1</span>) % Size;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (next_tail == head_.<span class="built_in">load</span>(std::memory_order_acquire)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 缓冲区满</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        buffer_[current_tail] = item;</span><br><span class="line">        tail_.<span class="built_in">store</span>(next_tail, std::memory_order_release);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">pop</span><span class="params">(T&amp; item)</span> </span>&#123;</span><br><span class="line">        <span class="type">size_t</span> current_head = head_.<span class="built_in">load</span>(std::memory_order_relaxed);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (current_head == tail_.<span class="built_in">load</span>(std::memory_order_acquire)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 缓冲区空</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        item = buffer_[current_head];</span><br><span class="line">        head_.<span class="built_in">store</span>((current_head + <span class="number">1</span>) % Size, std::memory_order_release);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="📊-性能基准测试"><a href="#📊-性能基准测试" class="headerlink" title="📊 性能基准测试"></a>📊 性能基准测试</h2><h3 id="延迟对比"><a href="#延迟对比" class="headerlink" title="延迟对比"></a>延迟对比</h3><table>
<thead>
<tr>
<th>中间件</th>
<th>平均延迟</th>
<th>99%延迟</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>ZeroMQ</td>
<td>10-50μs</td>
<td>100μs</td>
<td>实时通信</td>
</tr>
<tr>
<td>gRPC</td>
<td>100-500μs</td>
<td>1ms</td>
<td>微服务调用</td>
</tr>
<tr>
<td>Kafka</td>
<td>1-5ms</td>
<td>10ms</td>
<td>消息队列</td>
</tr>
<tr>
<td>Redis</td>
<td>50-200μs</td>
<td>500μs</td>
<td>缓存</td>
</tr>
</tbody></table>
<h3 id="吞吐量对比"><a href="#吞吐量对比" class="headerlink" title="吞吐量对比"></a>吞吐量对比</h3><table>
<thead>
<tr>
<th>中间件</th>
<th>单机吞吐量</th>
<th>集群吞吐量</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>ZeroMQ</td>
<td>1M msg&#x2F;s</td>
<td>10M msg&#x2F;s</td>
<td>高频交易</td>
</tr>
<tr>
<td>gRPC</td>
<td>100K req&#x2F;s</td>
<td>1M req&#x2F;s</td>
<td>API服务</td>
</tr>
<tr>
<td>Kafka</td>
<td>1M msg&#x2F;s</td>
<td>100M msg&#x2F;s</td>
<td>流处理</td>
</tr>
<tr>
<td>Redis</td>
<td>100K ops&#x2F;s</td>
<td>1M ops&#x2F;s</td>
<td>缓存服务</td>
</tr>
</tbody></table>
<hr>
<h2 id="🎯-高性能编程推荐组合示例："><a href="#🎯-高性能编程推荐组合示例：" class="headerlink" title="🎯 高性能编程推荐组合示例："></a>🎯 高性能编程推荐组合示例：</h2><ul>
<li><p>✅ 高吞吐 RPC：<code>brpc</code> + <code>Protobuf</code></p>
</li>
<li><p>✅ 微服务通信：<code>gRPC</code> + <code>Protobuf/FlatBuffers</code></p>
</li>
<li><p>✅ 超低延迟通信：<code>ZeroMQ</code> + <code>FlatBuffers</code></p>
</li>
<li><p>✅ 实时系统（车载&#x2F;军工）：<code>DDS（RTI/Opensplice）</code></p>
</li>
<li><p>✅ 本地高性能进程通信：<code>mmap</code> + 自定义 ring buffer</p>
</li>
<li><p>✅ 高并发协程框架：<code>libgo</code> 或 <code>Seastar</code></p>
</li>
</ul>
<hr>
<h2 id="🚀-部署和运维指南"><a href="#🚀-部署和运维指南" class="headerlink" title="🚀 部署和运维指南"></a>🚀 部署和运维指南</h2><h3 id="1-容器化部署"><a href="#1-容器化部署" class="headerlink" title="1. 容器化部署"></a>1. 容器化部署</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Dockerfile for C++ middleware application</span></span><br><span class="line"><span class="keyword">FROM</span> ubuntu:<span class="number">20.04</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Install dependencies</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get update &amp;&amp; apt-get install -y \</span></span><br><span class="line"><span class="language-bash">    build-essential \</span></span><br><span class="line"><span class="language-bash">    cmake \</span></span><br><span class="line"><span class="language-bash">    libboost-all-dev \</span></span><br><span class="line"><span class="language-bash">    libgrpc++-dev \</span></span><br><span class="line"><span class="language-bash">    libprotobuf-dev \</span></span><br><span class="line"><span class="language-bash">    libzmq3-dev \</span></span><br><span class="line"><span class="language-bash">    libcppkafka-dev \</span></span><br><span class="line"><span class="language-bash">    &amp;&amp; <span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy source code</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> . /app</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /app</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Build application</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build \</span></span><br><span class="line"><span class="language-bash">    &amp;&amp; cmake .. \</span></span><br><span class="line"><span class="language-bash">    &amp;&amp; make -j$(<span class="built_in">nproc</span>)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run application</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;./build/myapp&quot;</span>]</span></span><br></pre></td></tr></table></figure>

<h3 id="2-监控和指标"><a href="#2-监控和指标" class="headerlink" title="2. 监控和指标"></a>2. 监控和指标</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 性能指标收集</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MetricsCollector</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::atomic&lt;<span class="type">uint64_t</span>&gt; request_count_&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    std::atomic&lt;<span class="type">uint64_t</span>&gt; error_count_&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    std::atomic&lt;<span class="type">uint64_t</span>&gt; total_latency_&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">record_request</span><span class="params">(<span class="type">uint64_t</span> latency_ns)</span> </span>&#123;</span><br><span class="line">        request_count_.<span class="built_in">fetch_add</span>(<span class="number">1</span>);</span><br><span class="line">        total_latency_.<span class="built_in">fetch_add</span>(latency_ns);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">record_error</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        error_count_.<span class="built_in">fetch_add</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">double</span> <span class="title">get_avg_latency_ms</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="type">uint64_t</span> count = request_count_.<span class="built_in">load</span>();</span><br><span class="line">        <span class="keyword">if</span> (count == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0.0</span>;</span><br><span class="line">        <span class="keyword">return</span> (total_latency_.<span class="built_in">load</span>() / count) / <span class="number">1000000.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">double</span> <span class="title">get_error_rate</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="type">uint64_t</span> requests = request_count_.<span class="built_in">load</span>();</span><br><span class="line">        <span class="type">uint64_t</span> errors = error_count_.<span class="built_in">load</span>();</span><br><span class="line">        <span class="keyword">if</span> (requests == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0.0</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">static_cast</span>&lt;<span class="type">double</span>&gt;(errors) / requests;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="3-配置管理"><a href="#3-配置管理" class="headerlink" title="3. 配置管理"></a>3. 配置管理</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 配置管理类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConfigManager</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::unordered_map&lt;std::string, std::string&gt; config_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">load_from_file</span><span class="params">(<span class="type">const</span> std::string&amp; filename)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::ifstream <span class="title">file</span><span class="params">(filename)</span></span>;</span><br><span class="line">        std::string line;</span><br><span class="line">        <span class="keyword">while</span> (std::<span class="built_in">getline</span>(file, line)) &#123;</span><br><span class="line">            <span class="type">size_t</span> pos = line.<span class="built_in">find</span>(<span class="string">&#x27;=&#x27;</span>);</span><br><span class="line">            <span class="keyword">if</span> (pos != std::string::npos) &#123;</span><br><span class="line">                std::string key = line.<span class="built_in">substr</span>(<span class="number">0</span>, pos);</span><br><span class="line">                std::string value = line.<span class="built_in">substr</span>(pos + <span class="number">1</span>);</span><br><span class="line">                config_[key] = value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function">    T <span class="title">get</span><span class="params">(<span class="type">const</span> std::string&amp; key, <span class="type">const</span> T&amp; default_value = T&#123;&#125;)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> it = config_.<span class="built_in">find</span>(key);</span><br><span class="line">        <span class="keyword">if</span> (it == config_.<span class="built_in">end</span>()) <span class="keyword">return</span> default_value;</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;T, <span class="type">int</span>&gt;)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> std::<span class="built_in">stoi</span>(it-&gt;second);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;T, <span class="type">double</span>&gt;) &#123;</span><br><span class="line">            <span class="keyword">return</span> std::<span class="built_in">stod</span>(it-&gt;second);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">static_cast</span>&lt;T&gt;(it-&gt;second);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="🔍-故障排查和调试"><a href="#🔍-故障排查和调试" class="headerlink" title="🔍 故障排查和调试"></a>🔍 故障排查和调试</h2><h3 id="1-常见问题及解决方案"><a href="#1-常见问题及解决方案" class="headerlink" title="1. 常见问题及解决方案"></a>1. 常见问题及解决方案</h3><h4 id="内存泄漏"><a href="#内存泄漏" class="headerlink" title="内存泄漏"></a>内存泄漏</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用智能指针和RAII</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResourceManager</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::unique_ptr&lt;zmq::<span class="type">context_t</span>&gt; context_;</span><br><span class="line">    std::unique_ptr&lt;zmq::<span class="type">socket_t</span>&gt; socket_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">ResourceManager</span>() : <span class="built_in">context_</span>(std::<span class="built_in">make_unique</span>&lt;zmq::<span class="type">context_t</span>&gt;(<span class="number">1</span>)) &#123;</span><br><span class="line">        socket_ = std::<span class="built_in">make_unique</span>&lt;zmq::<span class="type">socket_t</span>&gt;(*context_, ZMQ_REQ);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 自动清理资源</span></span><br><span class="line">    ~<span class="built_in">ResourceManager</span>() = <span class="keyword">default</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="死锁检测"><a href="#死锁检测" class="headerlink" title="死锁检测"></a>死锁检测</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 死锁检测工具</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DeadlockDetector</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::unordered_map&lt;std::thread::id, std::vector&lt;std::string&gt;&gt; thread_locks_;</span><br><span class="line">    std::mutex detector_mutex_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">record_lock_attempt</span><span class="params">(<span class="type">const</span> std::string&amp; lock_name)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(detector_mutex_)</span></span>;</span><br><span class="line">        <span class="keyword">auto</span> thread_id = std::this_thread::<span class="built_in">get_id</span>();</span><br><span class="line">        thread_locks_[thread_id].<span class="built_in">push_back</span>(lock_name);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 检测死锁</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">detect_deadlock</span>()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> std::<span class="built_in">runtime_error</span>(<span class="string">&quot;Potential deadlock detected!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">detect_deadlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 简化的死锁检测算法</span></span><br><span class="line">        <span class="comment">// 实际实现需要更复杂的图算法</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="2-性能调优技巧"><a href="#2-性能调优技巧" class="headerlink" title="2. 性能调优技巧"></a>2. 性能调优技巧</h3><h4 id="编译优化"><a href="#编译优化" class="headerlink" title="编译优化"></a>编译优化</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译优化脚本</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="built_in">export</span> CXXFLAGS=<span class="string">&quot;-O3 -march=native -mtune=native -flto -DNDEBUG&quot;</span></span><br><span class="line"><span class="built_in">export</span> LDFLAGS=<span class="string">&quot;-flto&quot;</span></span><br><span class="line"></span><br><span class="line">cmake -DCMAKE_BUILD_TYPE=Release \</span><br><span class="line">      -DCMAKE_CXX_FLAGS=<span class="string">&quot;<span class="variable">$CXXFLAGS</span>&quot;</span> \</span><br><span class="line">      -DCMAKE_EXE_LINKER_FLAGS=<span class="string">&quot;<span class="variable">$LDFLAGS</span>&quot;</span> \</span><br><span class="line">      ..</span><br><span class="line">make -j$(<span class="built_in">nproc</span>)</span><br></pre></td></tr></table></figure>

<h4 id="运行时优化"><a href="#运行时优化" class="headerlink" title="运行时优化"></a>运行时优化</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 线程亲和性设置</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">set_thread_affinity</span><span class="params">(<span class="type">int</span> cpu_id)</span> </span>&#123;</span><br><span class="line">    <span class="type">cpu_set_t</span> cpuset;</span><br><span class="line">    <span class="built_in">CPU_ZERO</span>(&amp;cpuset);</span><br><span class="line">    <span class="built_in">CPU_SET</span>(cpu_id, &amp;cpuset);</span><br><span class="line">    <span class="built_in">pthread_setaffinity_np</span>(<span class="built_in">pthread_self</span>(), <span class="built_in">sizeof</span>(<span class="type">cpu_set_t</span>), &amp;cpuset);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// NUMA感知内存分配</span></span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="title">numa_alloc</span><span class="params">(<span class="type">size_t</span> size, <span class="type">int</span> numa_node)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">numa_alloc_onnode</span>(size, numa_node);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="📚-学习资源推荐"><a href="#📚-学习资源推荐" class="headerlink" title="📚 学习资源推荐"></a>📚 学习资源推荐</h2><h3 id="1-官方文档"><a href="#1-官方文档" class="headerlink" title="1. 官方文档"></a>1. 官方文档</h3><ul>
<li><a target="_blank" rel="noopener" href="http://zguide.zeromq.org/">ZeroMQ Guide</a></li>
<li><a target="_blank" rel="noopener" href="https://grpc.io/docs/">gRPC Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://kafka.apache.org/documentation/">Apache Kafka Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://www.boost.org/doc/libs/master/doc/html/boost_asio.html">Boost.Asio Documentation</a></li>
</ul>
<h3 id="2-书籍推荐"><a href="#2-书籍推荐" class="headerlink" title="2. 书籍推荐"></a>2. 书籍推荐</h3><ul>
<li>《ZeroMQ: Messaging for Many Applications》</li>
<li>《gRPC: Up and Running》</li>
<li>《High Performance Browser Networking》</li>
<li>《C++ Concurrency in Action》</li>
</ul>
<h3 id="3-开源项目学习"><a href="#3-开源项目学习" class="headerlink" title="3. 开源项目学习"></a>3. 开源项目学习</h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/scylladb/scylla">ScyllaDB</a> - 基于Seastar的NoSQL数据库</li>
<li><a target="_blank" rel="noopener" href="https://github.com/apache/brpc">brpc</a> - 百度RPC框架</li>
<li><a target="_blank" rel="noopener" href="https://github.com/yyzybb537/libgo">libgo</a> - 腾讯协程库</li>
</ul>
<h2 id="🎯-总结"><a href="#🎯-总结" class="headerlink" title="🎯 总结"></a>🎯 总结</h2><p>选择合适的C++中间件需要考虑以下因素：</p>
<ol>
<li><strong>性能需求</strong>：延迟、吞吐量、并发量</li>
<li><strong>业务场景</strong>：实时性、可靠性、扩展性</li>
<li><strong>技术栈</strong>：团队技能、维护成本</li>
<li><strong>生态系统</strong>：社区支持、工具链完善度</li>
</ol>
<p>记住，<strong>过早优化是万恶之源</strong>。应该先确保系统正确性和可维护性，然后通过profiling找到真正的性能瓶颈，再有针对性地选择和使用中间件。</p>
<hr>
<p>如果你有具体场景（如：<strong>多线程处理、网络通信、分布式调度、微服务调用等</strong>），我可以进一步推荐适配的中间件组合。需要的话可以详细说明。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/07/Programming/CPP/middle-layers%20for%20high%20performance%20cpp/" data-id="cme17ov0r0035wnonee051ebz" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Programming/CPP/high performance programming" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/07/Programming/CPP/high%20performance%20programming/" class="article-date">
  <time class="dt-published" datetime="2025-07-07T02:05:14.198Z" itemprop="datePublished">2025-07-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="C-高性能编程指南"><a href="#C-高性能编程指南" class="headerlink" title="C++ 高性能编程指南"></a>C++ 高性能编程指南</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>C++高性能编程是一个综合性的主题，需要从多个层面进行优化。本文将从三个主要方面来探讨如何实现高性能的C++程序：</p>
<ol>
<li><strong>中间件优化</strong> - 结合常见业务场景</li>
<li><strong>编程习惯</strong> - 锁的粒度控制和无锁编程</li>
<li><strong>性能分析</strong> - Profiling工具和技巧</li>
</ol>
<hr>
<h2 id="1-中间件优化"><a href="#1-中间件优化" class="headerlink" title="1. 中间件优化"></a>1. 中间件优化</h2><h3 id="1-1-内存管理优化"><a href="#1-1-内存管理优化" class="headerlink" title="1.1 内存管理优化"></a>1.1 内存管理优化</h3><h4 id="内存池技术"><a href="#内存池技术" class="headerlink" title="内存池技术"></a>内存池技术</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemoryPool</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">Block</span> &#123;</span><br><span class="line">        Block* next;</span><br><span class="line">        T data;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    Block* free_list_;</span><br><span class="line">    std::vector&lt;std::unique_ptr&lt;Block[]&gt;&gt; blocks_;</span><br><span class="line">    <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">size_t</span> BLOCK_SIZE = <span class="number">1024</span>;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MemoryPool</span>() : <span class="built_in">free_list_</span>(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">T* <span class="title">allocate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!free_list_) &#123;</span><br><span class="line">            <span class="built_in">allocateBlock</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        Block* block = free_list_;</span><br><span class="line">        free_list_ = block-&gt;next;</span><br><span class="line">        <span class="keyword">return</span> &amp;block-&gt;data;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(T* ptr)</span> </span>&#123;</span><br><span class="line">        Block* block = <span class="built_in">reinterpret_cast</span>&lt;Block*&gt;(ptr);</span><br><span class="line">        block-&gt;next = free_list_;</span><br><span class="line">        free_list_ = block;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">allocateBlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> block = std::<span class="built_in">make_unique</span>&lt;Block[]&gt;(BLOCK_SIZE);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; BLOCK_SIZE - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">            block[i].next = &amp;block[i + <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        block[BLOCK_SIZE - <span class="number">1</span>].next = <span class="literal">nullptr</span>;</span><br><span class="line">        free_list_ = &amp;block[<span class="number">1</span>];</span><br><span class="line">        blocks_.<span class="built_in">push_back</span>(std::<span class="built_in">move</span>(block));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="智能指针优化"><a href="#智能指针优化" class="headerlink" title="智能指针优化"></a>智能指针优化</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用make_unique/make_shared避免额外的内存分配</span></span><br><span class="line"><span class="keyword">auto</span> ptr1 = std::<span class="built_in">make_unique</span>&lt;MyClass&gt;(args);  <span class="comment">// 推荐</span></span><br><span class="line"><span class="keyword">auto</span> ptr2 = std::<span class="built_in">unique_ptr</span>&lt;MyClass&gt;(<span class="keyword">new</span> <span class="built_in">MyClass</span>(args));  <span class="comment">// 不推荐</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用weak_ptr避免循环引用</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Observer</span> &#123;</span><br><span class="line">    std::weak_ptr&lt;Subject&gt; subject_;  <span class="comment">// 避免循环引用</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="1-2-容器优化"><a href="#1-2-容器优化" class="headerlink" title="1.2 容器优化"></a>1.2 容器优化</h3><h4 id="选择合适的容器"><a href="#选择合适的容器" class="headerlink" title="选择合适的容器"></a>选择合适的容器</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 频繁插入删除 - 使用list或unordered_map</span></span><br><span class="line">std::list&lt;<span class="type">int</span>&gt; frequent_modify_list;</span><br><span class="line">std::unordered_map&lt;<span class="type">int</span>, std::string&gt; frequent_modify_map;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 频繁查找 - 使用set或map</span></span><br><span class="line">std::set&lt;<span class="type">int</span>&gt; frequent_search_set;</span><br><span class="line">std::map&lt;<span class="type">int</span>, std::string&gt; frequent_search_map;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 随机访问 - 使用vector</span></span><br><span class="line">std::vector&lt;<span class="type">int</span>&gt; random_access_vector;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 预分配容量避免重新分配</span></span><br><span class="line">std::vector&lt;<span class="type">int</span>&gt; vec;</span><br><span class="line">vec.<span class="built_in">reserve</span>(<span class="number">1000</span>);  <span class="comment">// 预分配1000个元素的空间</span></span><br></pre></td></tr></table></figure>

<h4 id="移动语义优化"><a href="#移动语义优化" class="headerlink" title="移动语义优化"></a>移动语义优化</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 移动构造函数</span></span><br><span class="line">    <span class="built_in">MyClass</span>(MyClass&amp;&amp; other) <span class="keyword">noexcept</span> </span><br><span class="line">        : <span class="built_in">data_</span>(std::<span class="built_in">move</span>(other.data_)) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 移动赋值操作符</span></span><br><span class="line">    MyClass&amp; <span class="keyword">operator</span>=(MyClass&amp;&amp; other) <span class="keyword">noexcept</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span> != &amp;other) &#123;</span><br><span class="line">            data_ = std::<span class="built_in">move</span>(other.data_);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; data_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="1-3-网络I-O优化"><a href="#1-3-网络I-O优化" class="headerlink" title="1.3 网络I&#x2F;O优化"></a>1.3 网络I&#x2F;O优化</h3><h4 id="异步I-O"><a href="#异步I-O" class="headerlink" title="异步I&#x2F;O"></a>异步I&#x2F;O</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;asio.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AsyncServer</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        acceptor_.<span class="built_in">async_accept</span>(</span><br><span class="line">            [<span class="keyword">this</span>](std::error_code ec, asio::ip::tcp::socket socket) &#123;</span><br><span class="line">                <span class="keyword">if</span> (!ec) &#123;</span><br><span class="line">                    <span class="built_in">handle_connection</span>(std::<span class="built_in">move</span>(socket));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="built_in">start</span>();  <span class="comment">// 继续接受下一个连接</span></span><br><span class="line">            &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    asio::io_context io_context_;</span><br><span class="line">    asio::ip::tcp::acceptor acceptor_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="2-编程习惯优化"><a href="#2-编程习惯优化" class="headerlink" title="2. 编程习惯优化"></a>2. 编程习惯优化</h2><h3 id="2-1-锁的粒度控制"><a href="#2-1-锁的粒度控制" class="headerlink" title="2.1 锁的粒度控制"></a>2.1 锁的粒度控制</h3><h4 id="细粒度锁"><a href="#细粒度锁" class="headerlink" title="细粒度锁"></a>细粒度锁</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ThreadSafeCounter</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">mutable</span> std::shared_mutex mutex_;</span><br><span class="line">    <span class="type">int</span> value_ = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 读操作使用共享锁</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="function">std::shared_lock&lt;std::shared_mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        <span class="keyword">return</span> value_;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 写操作使用独占锁</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">increment</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="function">std::unique_lock&lt;std::shared_mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">        ++value_;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="分段锁"><a href="#分段锁" class="headerlink" title="分段锁"></a>分段锁</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SegmentedHashTable</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">size_t</span> SEGMENTS = <span class="number">16</span>;</span><br><span class="line">    std::array&lt;std::mutex, SEGMENTS&gt; mutexes_;</span><br><span class="line">    std::array&lt;std::unordered_map&lt;<span class="type">int</span>, T&gt;, SEGMENTS&gt; segments_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">insert</span><span class="params">(<span class="type">int</span> key, <span class="type">const</span> T&amp; value)</span> </span>&#123;</span><br><span class="line">        <span class="type">size_t</span> segment = key % SEGMENTS;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutexes_[segment])</span></span>;</span><br><span class="line">        segments_[segment][key] = value;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">T <span class="title">get</span><span class="params">(<span class="type">int</span> key)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="type">size_t</span> segment = key % SEGMENTS;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mutexes_[segment])</span></span>;</span><br><span class="line">        <span class="keyword">auto</span> it = segments_[segment].<span class="built_in">find</span>(key);</span><br><span class="line">        <span class="keyword">return</span> it != segments_[segment].<span class="built_in">end</span>() ? it-&gt;second : T&#123;&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="2-2-无锁编程"><a href="#2-2-无锁编程" class="headerlink" title="2.2 无锁编程"></a>2.2 无锁编程</h3><h4 id="原子操作"><a href="#原子操作" class="headerlink" title="原子操作"></a>原子操作</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;atomic&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LockFreeCounter</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::atomic&lt;<span class="type">int</span>&gt; counter_&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">increment</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        counter_.<span class="built_in">fetch_add</span>(<span class="number">1</span>, std::memory_order_relaxed);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> counter_.<span class="built_in">load</span>(std::memory_order_acquire);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="无锁队列"><a href="#无锁队列" class="headerlink" title="无锁队列"></a>无锁队列</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LockFreeQueue</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">        T data;</span><br><span class="line">        std::atomic&lt;Node*&gt; next&#123;<span class="literal">nullptr</span>&#125;;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    std::atomic&lt;Node*&gt; head_&#123;<span class="literal">nullptr</span>&#125;;</span><br><span class="line">    std::atomic&lt;Node*&gt; tail_&#123;<span class="literal">nullptr</span>&#125;;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(<span class="type">const</span> T&amp; value)</span> </span>&#123;</span><br><span class="line">        Node* new_node = <span class="keyword">new</span> Node&#123;value&#125;;</span><br><span class="line">        Node* old_tail = tail_.<span class="built_in">exchange</span>(new_node);</span><br><span class="line">        <span class="keyword">if</span> (old_tail) &#123;</span><br><span class="line">            old_tail-&gt;next.<span class="built_in">store</span>(new_node);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            head_.<span class="built_in">store</span>(new_node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">pop</span><span class="params">(T&amp; value)</span> </span>&#123;</span><br><span class="line">        Node* old_head = head_.<span class="built_in">load</span>();</span><br><span class="line">        <span class="keyword">if</span> (!old_head) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        </span><br><span class="line">        Node* new_head = old_head-&gt;next.<span class="built_in">load</span>();</span><br><span class="line">        <span class="keyword">if</span> (head_.<span class="built_in">compare_exchange_strong</span>(old_head, new_head)) &#123;</span><br><span class="line">            value = old_head-&gt;data;</span><br><span class="line">            <span class="keyword">delete</span> old_head;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-缓存友好的编程"><a href="#2-3-缓存友好的编程" class="headerlink" title="2.3 缓存友好的编程"></a>2.3 缓存友好的编程</h3><h4 id="数据局部性"><a href="#数据局部性" class="headerlink" title="数据局部性"></a>数据局部性</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 好的设计 - 数据局部性好</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CacheFriendly</span> &#123;</span><br><span class="line">    <span class="type">int</span> id;</span><br><span class="line">    <span class="type">double</span> value;</span><br><span class="line">    <span class="type">char</span> name[<span class="number">32</span>];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">std::vector&lt;CacheFriendly&gt; cache_friendly_data;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 不好的设计 - 指针跳转多</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CacheUnfriendly</span> &#123;</span><br><span class="line">    <span class="type">int</span> id;</span><br><span class="line">    <span class="type">double</span>* value_ptr;</span><br><span class="line">    std::string* name_ptr;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">std::vector&lt;CacheUnfriendly&gt; cache_unfriendly_data;</span><br></pre></td></tr></table></figure>

<h4 id="循环优化"><a href="#循环优化" class="headerlink" title="循环优化"></a>循环优化</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 优化前 - 缓存不友好</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; M; ++j) &#123;</span><br><span class="line">        matrix[i][j] = <span class="built_in">compute</span>(i, j);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 优化后 - 缓存友好</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; M; ++j) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">        matrix[i][j] = <span class="built_in">compute</span>(i, j);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="3-性能分析-Profiling"><a href="#3-性能分析-Profiling" class="headerlink" title="3. 性能分析 (Profiling)"></a>3. 性能分析 (Profiling)</h2><h3 id="3-1-编译时优化"><a href="#3-1-编译时优化" class="headerlink" title="3.1 编译时优化"></a>3.1 编译时优化</h3><h4 id="编译器优化选项"><a href="#编译器优化选项" class="headerlink" title="编译器优化选项"></a>编译器优化选项</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GCC优化选项</span></span><br><span class="line">g++ -O3 -march=native -mtune=native -flto source.cpp -o program</span><br><span class="line"></span><br><span class="line"><span class="comment"># Clang优化选项</span></span><br><span class="line">clang++ -O3 -march=native -flto source.cpp -o program</span><br></pre></td></tr></table></figure>

<h4 id="内联优化"><a href="#内联优化" class="headerlink" title="内联优化"></a>内联优化</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 强制内联</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">fast_add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 编译器内联提示</span></span><br><span class="line">__attribute__((always_inline)) <span class="function"><span class="type">int</span> <span class="title">always_inline_func</span><span class="params">(<span class="type">int</span> x)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> x * <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-运行时分析工具"><a href="#3-2-运行时分析工具" class="headerlink" title="3.2 运行时分析工具"></a>3.2 运行时分析工具</h3><h4 id="使用gprof"><a href="#使用gprof" class="headerlink" title="使用gprof"></a>使用gprof</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;gprof.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 开始性能分析</span></span><br><span class="line">    <span class="built_in">monstartup</span>(<span class="string">&quot;program_name&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 你的程序代码</span></span><br><span class="line">    <span class="built_in">perform_work</span>();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 结束性能分析</span></span><br><span class="line">    <span class="built_in">moncleanup</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="使用perf"><a href="#使用perf" class="headerlink" title="使用perf"></a>使用perf</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 性能分析</span></span><br><span class="line">perf record ./your_program</span><br><span class="line">perf report</span><br><span class="line"></span><br><span class="line"><span class="comment"># 热点分析</span></span><br><span class="line">perf top -p &lt;pid&gt;</span><br></pre></td></tr></table></figure>

<h3 id="3-3-内存分析"><a href="#3-3-内存分析" class="headerlink" title="3.3 内存分析"></a>3.3 内存分析</h3><h4 id="Valgrind内存检查"><a href="#Valgrind内存检查" class="headerlink" title="Valgrind内存检查"></a>Valgrind内存检查</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 内存泄漏检查</span></span><br><span class="line">valgrind --leak-check=full ./your_program</span><br><span class="line"></span><br><span class="line"><span class="comment"># 内存使用分析</span></span><br><span class="line">valgrind --tool=massif ./your_program</span><br><span class="line">ms_print massif.out.*</span><br></pre></td></tr></table></figure>

<h4 id="自定义内存追踪"><a href="#自定义内存追踪" class="headerlink" title="自定义内存追踪"></a>自定义内存追踪</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;new&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 重载new操作符进行内存追踪</span></span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="type">void</span>* ptr = <span class="built_in">malloc</span>(size);</span><br><span class="line">    <span class="comment">// 记录内存分配</span></span><br><span class="line">    <span class="built_in">track_allocation</span>(ptr, size);</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="type">void</span>* ptr)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 记录内存释放</span></span><br><span class="line">    <span class="built_in">track_deallocation</span>(ptr);</span><br><span class="line">    <span class="built_in">free</span>(ptr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="4-实际应用场景"><a href="#4-实际应用场景" class="headerlink" title="4. 实际应用场景"></a>4. 实际应用场景</h2><h3 id="4-1-高并发服务器"><a href="#4-1-高并发服务器" class="headerlink" title="4.1 高并发服务器"></a>4.1 高并发服务器</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">HighPerformanceServer</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    asio::io_context io_context_;</span><br><span class="line">    std::vector&lt;std::thread&gt; worker_threads_;</span><br><span class="line">    ThreadPool task_pool_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">start</span><span class="params">(<span class="type">size_t</span> thread_count = std::thread::hardware_concurrency())</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 创建工作线程</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; thread_count; ++i) &#123;</span><br><span class="line">            worker_threads_.<span class="built_in">emplace_back</span>([<span class="keyword">this</span>]() &#123;</span><br><span class="line">                io_context_.<span class="built_in">run</span>();</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="4-2-数据处理管道"><a href="#4-2-数据处理管道" class="headerlink" title="4.2 数据处理管道"></a>4.2 数据处理管道</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Input, <span class="keyword">typename</span> Output&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DataPipeline</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::vector&lt;std::function&lt;Output(Input)&gt;&gt; stages_;</span><br><span class="line">    LockFreeQueue&lt;Input&gt; input_queue_;</span><br><span class="line">    LockFreeQueue&lt;Output&gt; output_queue_;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">add_stage</span><span class="params">(std::function&lt;Output(Input)&gt; stage)</span> </span>&#123;</span><br><span class="line">        stages_.<span class="built_in">push_back</span>(std::<span class="built_in">move</span>(stage));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 并行处理各个阶段</span></span><br><span class="line">        std::vector&lt;std::thread&gt; workers;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; stages_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            workers.<span class="built_in">emplace_back</span>([<span class="keyword">this</span>, i]() &#123;</span><br><span class="line">                <span class="built_in">process_stage</span>(i);</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>C++高性能编程需要综合考虑：</p>
<ol>
<li><strong>算法优化</strong> - 选择合适的数据结构和算法</li>
<li><strong>内存管理</strong> - 减少内存分配，提高缓存命中率</li>
<li><strong>并发控制</strong> - 合理使用锁和无锁编程</li>
<li><strong>系统调优</strong> - 利用编译器和系统级优化</li>
<li><strong>持续监控</strong> - 使用profiling工具持续优化</li>
</ol>
<p>记住，过早优化是万恶之源。应该先确保程序正确性，然后通过profiling找到真正的性能瓶颈，再有针对性地进行优化。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/07/Programming/CPP/high%20performance%20programming/" data-id="cme17ov0s003awnondxgdg0fx" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Programming/CPP/手撕线程池" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/07/01/Programming/CPP/%E6%89%8B%E6%92%95%E7%BA%BF%E7%A8%8B%E6%B1%A0/" class="article-date">
  <time class="dt-published" datetime="2025-07-01T08:54:50.315Z" itemprop="datePublished">2025-07-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/07/01/Programming/CPP/%E6%89%8B%E6%92%95%E7%BA%BF%E7%A8%8B%E6%B1%A0/" data-id="cme17ov11003swnoncrlvexjr" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/3/">&laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/5/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/System/">System</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Test/">Test</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AI/" rel="tag">AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Attention/" rel="tag">Attention</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Communication/" rel="tag">Communication</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Compiler/" rel="tag">Compiler</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Computational-Graph/" rel="tag">Computational Graph</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DeepSeek/" rel="tag">DeepSeek</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Distributed/" rel="tag">Distributed</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MoE/" rel="tag">MoE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Optimization/" rel="tag">Optimization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Performance/" rel="tag">Performance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SGLang/" rel="tag">SGLang</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/System/" rel="tag">System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blog/" rel="tag">blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blues/" rel="tag">blues</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/career/" rel="tag">career</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/charts/" rel="tag">charts</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/consensus/" rel="tag">consensus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-parallelism/" rel="tag">data-parallelism</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/distributed-systems/" rel="tag">distributed-systems</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/experience/" rel="tag">experience</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/expert-parallelism/" rel="tag">expert-parallelism</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/guitar/" rel="tag">guitar</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/harmony/" rel="tag">harmony</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/licks/" rel="tag">licks</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/life/" rel="tag">life</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/llm/" rel="tag">llm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mermaid/" rel="tag">mermaid</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/raft/" rel="tag">raft</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rhythm/" rel="tag">rhythm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/test/" rel="tag">test</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/AI/" style="font-size: 10px;">AI</a> <a href="/tags/Attention/" style="font-size: 10px;">Attention</a> <a href="/tags/Communication/" style="font-size: 10px;">Communication</a> <a href="/tags/Compiler/" style="font-size: 10px;">Compiler</a> <a href="/tags/Computational-Graph/" style="font-size: 10px;">Computational Graph</a> <a href="/tags/DeepSeek/" style="font-size: 10px;">DeepSeek</a> <a href="/tags/Distributed/" style="font-size: 10px;">Distributed</a> <a href="/tags/LLM/" style="font-size: 10px;">LLM</a> <a href="/tags/MoE/" style="font-size: 10px;">MoE</a> <a href="/tags/Optimization/" style="font-size: 10px;">Optimization</a> <a href="/tags/Performance/" style="font-size: 10px;">Performance</a> <a href="/tags/SGLang/" style="font-size: 10px;">SGLang</a> <a href="/tags/System/" style="font-size: 15px;">System</a> <a href="/tags/blog/" style="font-size: 10px;">blog</a> <a href="/tags/blues/" style="font-size: 20px;">blues</a> <a href="/tags/career/" style="font-size: 10px;">career</a> <a href="/tags/charts/" style="font-size: 10px;">charts</a> <a href="/tags/consensus/" style="font-size: 10px;">consensus</a> <a href="/tags/data-parallelism/" style="font-size: 10px;">data-parallelism</a> <a href="/tags/distributed-systems/" style="font-size: 20px;">distributed-systems</a> <a href="/tags/experience/" style="font-size: 10px;">experience</a> <a href="/tags/expert-parallelism/" style="font-size: 10px;">expert-parallelism</a> <a href="/tags/guitar/" style="font-size: 20px;">guitar</a> <a href="/tags/harmony/" style="font-size: 10px;">harmony</a> <a href="/tags/licks/" style="font-size: 10px;">licks</a> <a href="/tags/life/" style="font-size: 10px;">life</a> <a href="/tags/llm/" style="font-size: 15px;">llm</a> <a href="/tags/mermaid/" style="font-size: 10px;">mermaid</a> <a href="/tags/raft/" style="font-size: 10px;">raft</a> <a href="/tags/rhythm/" style="font-size: 10px;">rhythm</a> <a href="/tags/test/" style="font-size: 10px;">test</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/08/">August 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/07/">July 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/05/">May 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/04/">April 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">March 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/08/03/Plans/%E5%B7%A5%E4%BD%9C%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%9A%BE%E9%A2%98/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/08/02/System/LLM%20Serving%20Configs/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/07/31/System/cuda-kernel/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/07/31/Programming/CPP/constexpr/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/07/30/System/%E5%B9%B6%E8%A1%8C%E7%AD%96%E7%95%A5/%E5%BA%8F%E5%88%97%E5%B9%B6%E8%A1%8C/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>






<!-- Mermaid Support -->
<script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
<script>
  mermaid.initialize({
    startOnLoad: true,
    theme: 'default',
    securityLevel: 'loose',
    themeVariables: {
      primaryColor: '#0f4c75',
      primaryTextColor: '#fff',
      primaryBorderColor: '#0f4c75',
      lineColor: '#0f4c75',
      secondaryColor: '#006ba6',
      tertiaryColor: '#fff'
    }
  });
</script>
  </div>
</body>
</html>